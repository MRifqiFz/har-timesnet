{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import time\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.fft\n",
    "import optuna\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from torchmetrics.classification import (\n",
    "    MulticlassAccuracy, MulticlassF1Score, MulticlassPrecision, MulticlassRecall,\n",
    "    MulticlassConfusionMatrix, MulticlassROC\n",
    ")\n",
    "\n",
    "\n",
    "curPath = os.path.abspath(os.path.dirname('models'))\n",
    "rootPath = os.path.split(curPath)[0]\n",
    "sys.path.append(rootPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_labels(labels):\n",
    "    indicies = np.unique(labels)\n",
    "    num_samples = labels.shape[0]\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        new_label = np.argwhere(labels[i] == indicies)[0][0]\n",
    "        labels[i] = new_label\n",
    "\n",
    "    return labels\n",
    "\n",
    "def collate_fn(data, device, max_len=None):\n",
    "    \"\"\"Build mini-batch tensors from a list of (X, mask) tuples. Mask input. Create\n",
    "    Args:\n",
    "        data: len(batch_size) list of tuples (X, y).\n",
    "            - X: torch tensor of shape (seq_length, feat_dim); variable seq_length.\n",
    "            - y: torch tensor of shape (num_labels,) : class indices or numerical targets\n",
    "                (for classification or regression, respectively). num_labels > 1 for multi-task models\n",
    "        max_len: global fixed sequence length. Used for architectures requiring fixed length input,\n",
    "            where the batch length cannot vary dynamically. Longer sequences are clipped, shorter are padded with 0s\n",
    "    Returns:\n",
    "        X: (batch_size, padded_length, feat_dim) torch tensor of masked features (input)\n",
    "        targets: (batch_size, padded_length, feat_dim) torch tensor of unmasked features (output)\n",
    "        target_masks: (batch_size, padded_length, feat_dim) boolean torch tensor\n",
    "            0 indicates masked values to be predicted, 1 indicates unaffected/\"active\" feature values\n",
    "        padding_masks: (batch_size, padded_length) boolean tensor, 1 means keep vector at this position, 0 means padding\n",
    "    \"\"\"\n",
    "\n",
    "    batch_size = len(data)\n",
    "    features, labels = zip(*data)\n",
    "\n",
    "    # Stack and pad features and masks (convert 2D to 3D tensors, i.e. add batch dimension)\n",
    "    lengths = [X.shape[0] for X in features]  # original sequence length for each time series\n",
    "    if max_len is None:\n",
    "        max_len = max(lengths)\n",
    "\n",
    "    X = torch.zeros(batch_size, max_len, features[0].shape[-1])  # (batch_size, padded_length, feat_dim)\n",
    "    for i in range(batch_size):\n",
    "        end = min(lengths[i], max_len)\n",
    "        X[i, :end, :] = features[i][:end, :]\n",
    "\n",
    "    targets = torch.stack(labels, dim=0)  # (batch_size, num_labels)\n",
    "\n",
    "    padding_masks = padding_mask(torch.tensor(lengths, dtype=torch.int16),\n",
    "                                 max_len=max_len)  # (batch_size, padded_length) boolean tensor, \"1\" means keep\n",
    "\n",
    "    return X.to(device), targets.to(device), padding_masks.to(device)\n",
    "\n",
    "\n",
    "def padding_mask(lengths, max_len=None):\n",
    "    \"\"\"\n",
    "    Used to mask padded positions: creates a (batch_size, max_len) boolean mask from a tensor of sequence lengths,\n",
    "    where 1 means keep element at this position (time step)\n",
    "    \"\"\"\n",
    "    batch_size = lengths.numel()\n",
    "    max_len = max_len or lengths.max_val()  # trick works because of overloading of 'or' operator for non-boolean types\n",
    "    return (torch.arange(0, max_len, device=lengths.device)\n",
    "            .type_as(lengths)\n",
    "            .repeat(batch_size, 1)\n",
    "            .lt(lengths.unsqueeze(1)))\n",
    "\n",
    "def set_seed(args):\n",
    "    random.seed(args.random_seed)\n",
    "    np.random.seed(args.random_seed)\n",
    "    torch.manual_seed(args.random_seed)\n",
    "    torch.cuda.manual_seed(args.random_seed)\n",
    "    torch.cuda.manual_seed_all(args.random_seed)\n",
    "\n",
    "\n",
    "class HARDataset(Dataset):\n",
    "    def __init__(self, dataset, target):\n",
    "        # (num_size, num_dimensions, series_length)\n",
    "        self.dataset = dataset.permute(0, 2, 1)\n",
    "        self.target = target\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.dataset[index], self.target[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target)\n",
    "    \n",
    "def normalize(data_set):\n",
    "    '''\n",
    "    The function is the same as normalize_per_series, but can be used for multiple variables.\n",
    "    '''\n",
    "    return TimeSeriesScalerMeanVariance().fit_transform(data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(backbone='fcn', random_seed=42, num_classes=0, normalize_way='single', input_size=1, target_points=96, patch_len=8, stride=8, labeled_ratio=0.1, task_name='classification', freq='h', seq_len=96, label_len=48, pred_len=0, seasonal_patterns='Monthly', inverse=False, top_k=3, num_kernels=6, enc_in=7, dec_in=7, c_out=7, d_model=64, n_heads=8, e_layers=3, d_layers=1, d_ff=64, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, use_gpu=True, gpu=1, loss='cross_entropy', optimizer='adam', lr=0.001, weight_decay=0.0, batch_size=8, epoch=15, cuda='cuda:1', save_dir='/SSD/lz/time_series_label_noise/result', save_csv_name='timesnet_ucr_supervised_0801_', classifier='linear', classifier_input=128)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Base setup\n",
    "parser.add_argument('--backbone', type=str, default='fcn', help='encoder backbone, fcn')\n",
    "parser.add_argument('--random_seed', type=int, default=42, help='shuffle seed')\n",
    "\n",
    "# Dataset setup\n",
    "parser.add_argument('--num_classes', type=int, default=0, help='number of class')\n",
    "parser.add_argument('--normalize_way', type=str, default='single', help='single or train_set')\n",
    "# parser.add_argument('--seq_len', type=int, default=46, help='seq_len')\n",
    "parser.add_argument('--input_size', type=int, default=1, help='input_size')\n",
    "\n",
    "# parser.add_argument('--patch_size', type=int, default=8, help='patch_size')\n",
    "# parser.add_argument('--stride', type=int, default=8, help='stride')\n",
    "\n",
    "parser.add_argument('--target_points', type=int, default=96, help='forecast horizon')\n",
    "\n",
    "# Patch\n",
    "parser.add_argument('--patch_len', type=int, default=8, help='patch length')\n",
    "parser.add_argument('--stride', type=int, default=8, help='stride between patch')\n",
    "\n",
    "# Semi training\n",
    "parser.add_argument('--labeled_ratio', type=float, default='0.1', help='0.1, 0.2, 0.4')\n",
    "\n",
    "# basic config\n",
    "parser.add_argument('--task_name', type=str, required=False, default='classification',\n",
    "                    help='task name, options:[long_term_forecast, short_term_forecast, imputation, classification, anomaly_detection]')\n",
    "parser.add_argument('--freq', type=str, default='h',\n",
    "                    help='freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h')\n",
    "\n",
    "# forecasting task\n",
    "parser.add_argument('--seq_len', type=int, default=96, help='input sequence length')\n",
    "parser.add_argument('--label_len', type=int, default=48, help='start token length')\n",
    "parser.add_argument('--pred_len', type=int, default=0, help='prediction sequence length')\n",
    "parser.add_argument('--seasonal_patterns', type=str, default='Monthly', help='subset for M4')\n",
    "parser.add_argument('--inverse', action='store_true', help='inverse output data', default=False)\n",
    "\n",
    "# model define\n",
    "parser.add_argument('--top_k', type=int, default=3, help='for TimesBlock')\n",
    "parser.add_argument('--num_kernels', type=int, default=6, help='for Inception')\n",
    "parser.add_argument('--enc_in', type=int, default=7, help='encoder input size')\n",
    "parser.add_argument('--dec_in', type=int, default=7, help='decoder input size')\n",
    "parser.add_argument('--c_out', type=int, default=7, help='output size')\n",
    "parser.add_argument('--d_model', type=int, default=64, help='dimension of model')   ###\n",
    "parser.add_argument('--n_heads', type=int, default=8, help='num of heads')\n",
    "parser.add_argument('--e_layers', type=int, default=3, help='num of encoder layers')\n",
    "parser.add_argument('--d_layers', type=int, default=1, help='num of decoder layers')\n",
    "parser.add_argument('--d_ff', type=int, default=64, help='dimension of fcn')\n",
    "parser.add_argument('--moving_avg', type=int, default=25, help='window size of moving average')\n",
    "parser.add_argument('--factor', type=int, default=1, help='attn factor')\n",
    "parser.add_argument('--distil', action='store_false',\n",
    "                    help='whether to use distilling in encoder, using this argument means not using distilling',\n",
    "                    default=True)\n",
    "parser.add_argument('--dropout', type=float, default=0.1, help='dropout')\n",
    "parser.add_argument('--embed', type=str, default='timeF',\n",
    "                    help='time features encoding, options:[timeF, fixed, learned]')\n",
    "parser.add_argument('--activation', type=str, default='gelu', help='activation')\n",
    "parser.add_argument('--output_attention', action='store_true', help='whether to output attention in ecoder')\n",
    "\n",
    "# GPU\n",
    "parser.add_argument('--use_gpu', type=bool, default=True, help='use gpu')\n",
    "parser.add_argument('--gpu', type=int, default=1, help='gpu')\n",
    "\n",
    "\n",
    "# training setup\n",
    "parser.add_argument('--loss', type=str, default='cross_entropy', help='loss function')\n",
    "parser.add_argument('--optimizer', type=str, default='adam', help='optimizer')\n",
    "parser.add_argument('--lr', type=float, default=0.001, help='learning rate')\n",
    "parser.add_argument('--weight_decay', type=float, default=0.0, help='weight decay')\n",
    "parser.add_argument('--batch_size', type=int, default=8, help='')\n",
    "parser.add_argument('--epoch', type=int, default=15, help='training epoch')\n",
    "parser.add_argument('--cuda', type=str, default='cuda:1')\n",
    "\n",
    "parser.add_argument('--save_dir', type=str, default='/SSD/lz/time_series_label_noise/result')\n",
    "parser.add_argument('--save_csv_name', type=str, default='timesnet_ucr_supervised_0801_')\n",
    "\n",
    "# classifier setup\n",
    "parser.add_argument('--classifier', type=str, default='linear', help='type of classifier(linear or nonlinear)')\n",
    "parser.add_argument('--classifier_input', type=int, default=128, help='input dim of the classifiers')\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "device = torch.device(args.cuda if torch.cuda.is_available() else \"cpu\")\n",
    "set_seed(args)\n",
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('dataset/UCI-HAR-Dataset/train.csv')\n",
    "test = pd.read_csv('dataset/UCI-HAR-Dataset/test.csv')\n",
    "\n",
    "train = train.drop('subject', axis=1)\n",
    "test = test.drop('subject', axis=1)\n",
    "\n",
    "labelNames = list(np.unique(train['Activity']))\n",
    "labelNames.sort()\n",
    "train['Activity'] = train['Activity'].apply(lambda x: labelNames.index(x))\n",
    "test['Activity'] = test['Activity'].apply(lambda x: labelNames.index(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tBodyAcc-mean()-X</th>\n",
       "      <th>tBodyAcc-mean()-Y</th>\n",
       "      <th>tBodyAcc-mean()-Z</th>\n",
       "      <th>tBodyAcc-std()-X</th>\n",
       "      <th>tBodyAcc-std()-Y</th>\n",
       "      <th>tBodyAcc-std()-Z</th>\n",
       "      <th>tBodyAcc-mad()-X</th>\n",
       "      <th>tBodyAcc-mad()-Y</th>\n",
       "      <th>tBodyAcc-mad()-Z</th>\n",
       "      <th>tBodyAcc-max()-X</th>\n",
       "      <th>...</th>\n",
       "      <th>fBodyBodyGyroJerkMag-skewness()</th>\n",
       "      <th>fBodyBodyGyroJerkMag-kurtosis()</th>\n",
       "      <th>angle(tBodyAccMean,gravity)</th>\n",
       "      <th>angle(tBodyAccJerkMean),gravityMean)</th>\n",
       "      <th>angle(tBodyGyroMean,gravityMean)</th>\n",
       "      <th>angle(tBodyGyroJerkMean,gravityMean)</th>\n",
       "      <th>angle(X,gravityMean)</th>\n",
       "      <th>angle(Y,gravityMean)</th>\n",
       "      <th>angle(Z,gravityMean)</th>\n",
       "      <th>Activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.288585</td>\n",
       "      <td>-0.020294</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.995279</td>\n",
       "      <td>-0.983111</td>\n",
       "      <td>-0.913526</td>\n",
       "      <td>-0.995112</td>\n",
       "      <td>-0.983185</td>\n",
       "      <td>-0.923527</td>\n",
       "      <td>-0.934724</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.298676</td>\n",
       "      <td>-0.710304</td>\n",
       "      <td>-0.112754</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>-0.464761</td>\n",
       "      <td>-0.018446</td>\n",
       "      <td>-0.841247</td>\n",
       "      <td>0.179941</td>\n",
       "      <td>-0.058627</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.278419</td>\n",
       "      <td>-0.016411</td>\n",
       "      <td>-0.123520</td>\n",
       "      <td>-0.998245</td>\n",
       "      <td>-0.975300</td>\n",
       "      <td>-0.960322</td>\n",
       "      <td>-0.998807</td>\n",
       "      <td>-0.974914</td>\n",
       "      <td>-0.957686</td>\n",
       "      <td>-0.943068</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.595051</td>\n",
       "      <td>-0.861499</td>\n",
       "      <td>0.053477</td>\n",
       "      <td>-0.007435</td>\n",
       "      <td>-0.732626</td>\n",
       "      <td>0.703511</td>\n",
       "      <td>-0.844788</td>\n",
       "      <td>0.180289</td>\n",
       "      <td>-0.054317</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.279653</td>\n",
       "      <td>-0.019467</td>\n",
       "      <td>-0.113462</td>\n",
       "      <td>-0.995380</td>\n",
       "      <td>-0.967187</td>\n",
       "      <td>-0.978944</td>\n",
       "      <td>-0.996520</td>\n",
       "      <td>-0.963668</td>\n",
       "      <td>-0.977469</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.390748</td>\n",
       "      <td>-0.760104</td>\n",
       "      <td>-0.118559</td>\n",
       "      <td>0.177899</td>\n",
       "      <td>0.100699</td>\n",
       "      <td>0.808529</td>\n",
       "      <td>-0.848933</td>\n",
       "      <td>0.180637</td>\n",
       "      <td>-0.049118</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.279174</td>\n",
       "      <td>-0.026201</td>\n",
       "      <td>-0.123283</td>\n",
       "      <td>-0.996091</td>\n",
       "      <td>-0.983403</td>\n",
       "      <td>-0.990675</td>\n",
       "      <td>-0.997099</td>\n",
       "      <td>-0.982750</td>\n",
       "      <td>-0.989302</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.117290</td>\n",
       "      <td>-0.482845</td>\n",
       "      <td>-0.036788</td>\n",
       "      <td>-0.012892</td>\n",
       "      <td>0.640011</td>\n",
       "      <td>-0.485366</td>\n",
       "      <td>-0.848649</td>\n",
       "      <td>0.181935</td>\n",
       "      <td>-0.047663</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.276629</td>\n",
       "      <td>-0.016570</td>\n",
       "      <td>-0.115362</td>\n",
       "      <td>-0.998139</td>\n",
       "      <td>-0.980817</td>\n",
       "      <td>-0.990482</td>\n",
       "      <td>-0.998321</td>\n",
       "      <td>-0.979672</td>\n",
       "      <td>-0.990441</td>\n",
       "      <td>-0.942469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.351471</td>\n",
       "      <td>-0.699205</td>\n",
       "      <td>0.123320</td>\n",
       "      <td>0.122542</td>\n",
       "      <td>0.693578</td>\n",
       "      <td>-0.615971</td>\n",
       "      <td>-0.847865</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>-0.043892</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 562 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tBodyAcc-mean()-X  tBodyAcc-mean()-Y  tBodyAcc-mean()-Z  tBodyAcc-std()-X  \\\n",
       "0           0.288585          -0.020294          -0.132905         -0.995279   \n",
       "1           0.278419          -0.016411          -0.123520         -0.998245   \n",
       "2           0.279653          -0.019467          -0.113462         -0.995380   \n",
       "3           0.279174          -0.026201          -0.123283         -0.996091   \n",
       "4           0.276629          -0.016570          -0.115362         -0.998139   \n",
       "\n",
       "   tBodyAcc-std()-Y  tBodyAcc-std()-Z  tBodyAcc-mad()-X  tBodyAcc-mad()-Y  \\\n",
       "0         -0.983111         -0.913526         -0.995112         -0.983185   \n",
       "1         -0.975300         -0.960322         -0.998807         -0.974914   \n",
       "2         -0.967187         -0.978944         -0.996520         -0.963668   \n",
       "3         -0.983403         -0.990675         -0.997099         -0.982750   \n",
       "4         -0.980817         -0.990482         -0.998321         -0.979672   \n",
       "\n",
       "   tBodyAcc-mad()-Z  tBodyAcc-max()-X  ...  fBodyBodyGyroJerkMag-skewness()  \\\n",
       "0         -0.923527         -0.934724  ...                        -0.298676   \n",
       "1         -0.957686         -0.943068  ...                        -0.595051   \n",
       "2         -0.977469         -0.938692  ...                        -0.390748   \n",
       "3         -0.989302         -0.938692  ...                        -0.117290   \n",
       "4         -0.990441         -0.942469  ...                        -0.351471   \n",
       "\n",
       "   fBodyBodyGyroJerkMag-kurtosis()  angle(tBodyAccMean,gravity)  \\\n",
       "0                        -0.710304                    -0.112754   \n",
       "1                        -0.861499                     0.053477   \n",
       "2                        -0.760104                    -0.118559   \n",
       "3                        -0.482845                    -0.036788   \n",
       "4                        -0.699205                     0.123320   \n",
       "\n",
       "   angle(tBodyAccJerkMean),gravityMean)  angle(tBodyGyroMean,gravityMean)  \\\n",
       "0                              0.030400                         -0.464761   \n",
       "1                             -0.007435                         -0.732626   \n",
       "2                              0.177899                          0.100699   \n",
       "3                             -0.012892                          0.640011   \n",
       "4                              0.122542                          0.693578   \n",
       "\n",
       "   angle(tBodyGyroJerkMean,gravityMean)  angle(X,gravityMean)  \\\n",
       "0                             -0.018446             -0.841247   \n",
       "1                              0.703511             -0.844788   \n",
       "2                              0.808529             -0.848933   \n",
       "3                             -0.485366             -0.848649   \n",
       "4                             -0.615971             -0.847865   \n",
       "\n",
       "   angle(Y,gravityMean)  angle(Z,gravityMean)  Activity  \n",
       "0              0.179941             -0.058627         2  \n",
       "1              0.180289             -0.054317         2  \n",
       "2              0.180637             -0.049118         2  \n",
       "3              0.181935             -0.047663         2  \n",
       "4              0.185151             -0.043892         2  \n",
       "\n",
       "[5 rows x 562 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tBodyAcc-mean()-X</th>\n",
       "      <th>tBodyAcc-mean()-Y</th>\n",
       "      <th>tBodyAcc-mean()-Z</th>\n",
       "      <th>tBodyAcc-std()-X</th>\n",
       "      <th>tBodyAcc-std()-Y</th>\n",
       "      <th>tBodyAcc-std()-Z</th>\n",
       "      <th>tBodyAcc-mad()-X</th>\n",
       "      <th>tBodyAcc-mad()-Y</th>\n",
       "      <th>tBodyAcc-mad()-Z</th>\n",
       "      <th>tBodyAcc-max()-X</th>\n",
       "      <th>...</th>\n",
       "      <th>fBodyBodyGyroJerkMag-skewness()</th>\n",
       "      <th>fBodyBodyGyroJerkMag-kurtosis()</th>\n",
       "      <th>angle(tBodyAccMean,gravity)</th>\n",
       "      <th>angle(tBodyAccJerkMean),gravityMean)</th>\n",
       "      <th>angle(tBodyGyroMean,gravityMean)</th>\n",
       "      <th>angle(tBodyGyroJerkMean,gravityMean)</th>\n",
       "      <th>angle(X,gravityMean)</th>\n",
       "      <th>angle(Y,gravityMean)</th>\n",
       "      <th>angle(Z,gravityMean)</th>\n",
       "      <th>Activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.257178</td>\n",
       "      <td>-0.023285</td>\n",
       "      <td>-0.014654</td>\n",
       "      <td>-0.938404</td>\n",
       "      <td>-0.920091</td>\n",
       "      <td>-0.667683</td>\n",
       "      <td>-0.952501</td>\n",
       "      <td>-0.925249</td>\n",
       "      <td>-0.674302</td>\n",
       "      <td>-0.894088</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.330370</td>\n",
       "      <td>-0.705974</td>\n",
       "      <td>0.006462</td>\n",
       "      <td>0.162920</td>\n",
       "      <td>-0.825886</td>\n",
       "      <td>0.271151</td>\n",
       "      <td>-0.720009</td>\n",
       "      <td>0.276801</td>\n",
       "      <td>-0.057978</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.286027</td>\n",
       "      <td>-0.013163</td>\n",
       "      <td>-0.119083</td>\n",
       "      <td>-0.975415</td>\n",
       "      <td>-0.967458</td>\n",
       "      <td>-0.944958</td>\n",
       "      <td>-0.986799</td>\n",
       "      <td>-0.968401</td>\n",
       "      <td>-0.945823</td>\n",
       "      <td>-0.894088</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121845</td>\n",
       "      <td>-0.594944</td>\n",
       "      <td>-0.083495</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>-0.434375</td>\n",
       "      <td>0.920593</td>\n",
       "      <td>-0.698091</td>\n",
       "      <td>0.281343</td>\n",
       "      <td>-0.083898</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.275485</td>\n",
       "      <td>-0.026050</td>\n",
       "      <td>-0.118152</td>\n",
       "      <td>-0.993819</td>\n",
       "      <td>-0.969926</td>\n",
       "      <td>-0.962748</td>\n",
       "      <td>-0.994403</td>\n",
       "      <td>-0.970735</td>\n",
       "      <td>-0.963483</td>\n",
       "      <td>-0.939260</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.190422</td>\n",
       "      <td>-0.640736</td>\n",
       "      <td>-0.034956</td>\n",
       "      <td>0.202302</td>\n",
       "      <td>0.064103</td>\n",
       "      <td>0.145068</td>\n",
       "      <td>-0.702771</td>\n",
       "      <td>0.280083</td>\n",
       "      <td>-0.079346</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.270298</td>\n",
       "      <td>-0.032614</td>\n",
       "      <td>-0.117520</td>\n",
       "      <td>-0.994743</td>\n",
       "      <td>-0.973268</td>\n",
       "      <td>-0.967091</td>\n",
       "      <td>-0.995274</td>\n",
       "      <td>-0.974471</td>\n",
       "      <td>-0.968897</td>\n",
       "      <td>-0.938610</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.344418</td>\n",
       "      <td>-0.736124</td>\n",
       "      <td>-0.017067</td>\n",
       "      <td>0.154438</td>\n",
       "      <td>0.340134</td>\n",
       "      <td>0.296407</td>\n",
       "      <td>-0.698954</td>\n",
       "      <td>0.284114</td>\n",
       "      <td>-0.077108</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.274833</td>\n",
       "      <td>-0.027848</td>\n",
       "      <td>-0.129527</td>\n",
       "      <td>-0.993852</td>\n",
       "      <td>-0.967445</td>\n",
       "      <td>-0.978295</td>\n",
       "      <td>-0.994111</td>\n",
       "      <td>-0.965953</td>\n",
       "      <td>-0.977346</td>\n",
       "      <td>-0.938610</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.534685</td>\n",
       "      <td>-0.846595</td>\n",
       "      <td>-0.002223</td>\n",
       "      <td>-0.040046</td>\n",
       "      <td>0.736715</td>\n",
       "      <td>-0.118545</td>\n",
       "      <td>-0.692245</td>\n",
       "      <td>0.290722</td>\n",
       "      <td>-0.073857</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 562 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tBodyAcc-mean()-X  tBodyAcc-mean()-Y  tBodyAcc-mean()-Z  tBodyAcc-std()-X  \\\n",
       "0           0.257178          -0.023285          -0.014654         -0.938404   \n",
       "1           0.286027          -0.013163          -0.119083         -0.975415   \n",
       "2           0.275485          -0.026050          -0.118152         -0.993819   \n",
       "3           0.270298          -0.032614          -0.117520         -0.994743   \n",
       "4           0.274833          -0.027848          -0.129527         -0.993852   \n",
       "\n",
       "   tBodyAcc-std()-Y  tBodyAcc-std()-Z  tBodyAcc-mad()-X  tBodyAcc-mad()-Y  \\\n",
       "0         -0.920091         -0.667683         -0.952501         -0.925249   \n",
       "1         -0.967458         -0.944958         -0.986799         -0.968401   \n",
       "2         -0.969926         -0.962748         -0.994403         -0.970735   \n",
       "3         -0.973268         -0.967091         -0.995274         -0.974471   \n",
       "4         -0.967445         -0.978295         -0.994111         -0.965953   \n",
       "\n",
       "   tBodyAcc-mad()-Z  tBodyAcc-max()-X  ...  fBodyBodyGyroJerkMag-skewness()  \\\n",
       "0         -0.674302         -0.894088  ...                        -0.330370   \n",
       "1         -0.945823         -0.894088  ...                        -0.121845   \n",
       "2         -0.963483         -0.939260  ...                        -0.190422   \n",
       "3         -0.968897         -0.938610  ...                        -0.344418   \n",
       "4         -0.977346         -0.938610  ...                        -0.534685   \n",
       "\n",
       "   fBodyBodyGyroJerkMag-kurtosis()  angle(tBodyAccMean,gravity)  \\\n",
       "0                        -0.705974                     0.006462   \n",
       "1                        -0.594944                    -0.083495   \n",
       "2                        -0.640736                    -0.034956   \n",
       "3                        -0.736124                    -0.017067   \n",
       "4                        -0.846595                    -0.002223   \n",
       "\n",
       "   angle(tBodyAccJerkMean),gravityMean)  angle(tBodyGyroMean,gravityMean)  \\\n",
       "0                              0.162920                         -0.825886   \n",
       "1                              0.017500                         -0.434375   \n",
       "2                              0.202302                          0.064103   \n",
       "3                              0.154438                          0.340134   \n",
       "4                             -0.040046                          0.736715   \n",
       "\n",
       "   angle(tBodyGyroJerkMean,gravityMean)  angle(X,gravityMean)  \\\n",
       "0                              0.271151             -0.720009   \n",
       "1                              0.920593             -0.698091   \n",
       "2                              0.145068             -0.702771   \n",
       "3                              0.296407             -0.698954   \n",
       "4                             -0.118545             -0.692245   \n",
       "\n",
       "   angle(Y,gravityMean)  angle(Z,gravityMean)  Activity  \n",
       "0              0.276801             -0.057978         2  \n",
       "1              0.281343             -0.083898         2  \n",
       "2              0.280083             -0.079346         2  \n",
       "3              0.284114             -0.077108         2  \n",
       "4              0.290722             -0.073857         2  \n",
       "\n",
       "[5 rows x 562 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Existing training and test data\n",
    "x_train = train.iloc[:, :-1].to_numpy(dtype=np.float32)\n",
    "y_train = train.iloc[:, -1].to_numpy(dtype=np.float32)\n",
    "\n",
    "x_test = test.iloc[:, :-1].to_numpy(dtype=np.float32)\n",
    "y_test = test.iloc[:, -1].to_numpy(dtype=np.float32)\n",
    "\n",
    "# Define the number of classes\n",
    "num_classes = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[:, :, np.newaxis]\n",
    "x_test = x_test[:, :, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args.batch_size =  8 , x_train.shape =  (7352, 561, 1) , x_test.shape =  (2947, 561, 1)\n"
     ]
    }
   ],
   "source": [
    "args.num_classes = num_classes\n",
    "args.seq_len = x_train.shape[1]\n",
    "args.input_size = x_train.shape[2]\n",
    "\n",
    "args.enc_in = x_train.shape[2]\n",
    "\n",
    "while x_train.shape[0] * 0.6 < args.batch_size:\n",
    "    args.batch_size = args.batch_size // 2\n",
    "\n",
    "print(\"args.batch_size = \", args.batch_size, \", x_train.shape = \", x_train.shape, \", x_test.shape = \", x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Inception_Block_V1(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_kernels=6, init_weight=True):\n",
    "        super(Inception_Block_V1, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.num_kernels = num_kernels\n",
    "        kernels = []\n",
    "        for i in range(self.num_kernels):\n",
    "            kernels.append(nn.Conv2d(in_channels, out_channels, kernel_size=2 * i + 1, padding=i))\n",
    "        self.kernels = nn.ModuleList(kernels)\n",
    "        if init_weight:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res_list = []\n",
    "        for i in range(self.num_kernels):\n",
    "            res_list.append(self.kernels[i](x))\n",
    "        res = torch.stack(res_list, dim=-1).mean(-1)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=25000):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)]\n",
    "\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        padding = 1 if torch.__version__ >= '1.5.0' else 2\n",
    "        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model,\n",
    "                                   kernel_size=3, padding=padding, padding_mode='circular', bias=False)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FixedEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(FixedEmbedding, self).__init__()\n",
    "\n",
    "        w = torch.zeros(c_in, d_model).float()\n",
    "        w.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, c_in).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        w[:, 0::2] = torch.sin(position * div_term)\n",
    "        w[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.emb = nn.Embedding(c_in, d_model)\n",
    "        self.emb.weight = nn.Parameter(w, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.emb(x).detach()\n",
    "\n",
    "\n",
    "class TemporalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='fixed', freq='h'):\n",
    "        super(TemporalEmbedding, self).__init__()\n",
    "\n",
    "        minute_size = 4\n",
    "        hour_size = 24\n",
    "        weekday_size = 7\n",
    "        day_size = 32\n",
    "        month_size = 13\n",
    "\n",
    "        Embed = FixedEmbedding if embed_type == 'fixed' else nn.Embedding\n",
    "        if freq == 't':\n",
    "            self.minute_embed = Embed(minute_size, d_model)\n",
    "        self.hour_embed = Embed(hour_size, d_model)\n",
    "        self.weekday_embed = Embed(weekday_size, d_model)\n",
    "        self.day_embed = Embed(day_size, d_model)\n",
    "        self.month_embed = Embed(month_size, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.long()\n",
    "        minute_x = self.minute_embed(x[:, :, 4]) if hasattr(\n",
    "            self, 'minute_embed') else 0.\n",
    "        hour_x = self.hour_embed(x[:, :, 3])\n",
    "        weekday_x = self.weekday_embed(x[:, :, 2])\n",
    "        day_x = self.day_embed(x[:, :, 1])\n",
    "        month_x = self.month_embed(x[:, :, 0])\n",
    "\n",
    "        return hour_x + weekday_x + day_x + month_x + minute_x\n",
    "\n",
    "\n",
    "class TimeFeatureEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='timeF', freq='h'):\n",
    "        super(TimeFeatureEmbedding, self).__init__()\n",
    "\n",
    "        freq_map = {'h': 4, 't': 5, 's': 6,\n",
    "                    'm': 1, 'a': 1, 'w': 2, 'd': 3, 'b': 3}\n",
    "        d_inp = freq_map[freq]\n",
    "        self.embed = nn.Linear(d_inp, d_model, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)\n",
    "\n",
    "\n",
    "class DataEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
    "        super(DataEmbedding, self).__init__()\n",
    "\n",
    "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
    "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
    "        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n",
    "                                                    freq=freq) if embed_type != 'timeF' else TimeFeatureEmbedding(\n",
    "            d_model=d_model, embed_type=embed_type, freq=freq)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, x_mark):\n",
    "        if x_mark is None:\n",
    "            x = self.value_embedding(x) + self.position_embedding(x)\n",
    "        else:\n",
    "            x = self.value_embedding(\n",
    "                x) + self.temporal_embedding(x_mark) + self.position_embedding(x)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TimesBlock + Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimesBlock(nn.Module):\n",
    "    def __init__(self, configs):\n",
    "        super(TimesBlock, self).__init__()\n",
    "        self.seq_len = configs.seq_len\n",
    "        self.pred_len = configs.pred_len\n",
    "        self.k = configs.top_k\n",
    "        self.d_model = configs.d_model\n",
    "        self.num_heads = configs.n_heads\n",
    "\n",
    "        # Parameter-efficient design\n",
    "        self.conv = nn.Sequential(\n",
    "            Inception_Block_V1(configs.d_model, configs.d_ff,\n",
    "                               num_kernels=configs.num_kernels),\n",
    "            nn.GELU(),\n",
    "            Inception_Block_V1(configs.d_ff, configs.d_model,\n",
    "                               num_kernels=configs.num_kernels)\n",
    "        )\n",
    "\n",
    "        # Self-attention layer\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=self.d_model, num_heads=self.num_heads, dropout=configs.dropout)\n",
    "        self.layer_norm = nn.LayerNorm(self.d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, N = x.size()\n",
    "        period_list, period_weight = FFT_for_Period(x, self.k)\n",
    "\n",
    "        res = []\n",
    "        for i in range(self.k):\n",
    "            period = period_list[i]\n",
    "            # Padding\n",
    "            if (self.seq_len + self.pred_len) % period != 0:\n",
    "                length = (\n",
    "                    ((self.seq_len + self.pred_len) // period) + 1) * period\n",
    "                padding = torch.zeros([x.shape[0], (length - (self.seq_len + self.pred_len)), x.shape[2]]).to(x.device)\n",
    "                out = torch.cat([x, padding], dim=1)\n",
    "            else:\n",
    "                length = (self.seq_len + self.pred_len)\n",
    "                out = x\n",
    "\n",
    "            # Reshape\n",
    "            out = out.reshape(B, length // period, period,\n",
    "                              N).permute(0, 3, 1, 2).contiguous()\n",
    "            out = self.conv(out)\n",
    "\n",
    "            # Reshape back\n",
    "            out = out.permute(0, 2, 3, 1).reshape(B, -1, N)\n",
    "            res.append(out[:, :(self.seq_len + self.pred_len), :])\n",
    "\n",
    "        res = torch.stack(res, dim=-1)\n",
    "\n",
    "        # Adaptive aggregation\n",
    "        period_weight = F.softmax(period_weight, dim=1)\n",
    "        period_weight = period_weight.unsqueeze(1).unsqueeze(1).repeat(1, T, N, 1)\n",
    "        res = torch.sum(res * period_weight, -1)\n",
    "\n",
    "        # Self-attention\n",
    "        res = res.permute(1, 0, 2)  # Prepare for attention [T, B, N]\n",
    "        attn_out, _ = self.attention(res, res, res)\n",
    "        res = self.layer_norm(res + attn_out)  # Residual connection + LayerNorm\n",
    "        res = res.permute(1, 0, 2)  # Back to [B, T, N]\n",
    "\n",
    "        # Residual connection\n",
    "        res = res + x\n",
    "        return res\n",
    "\n",
    "\n",
    "class TimesNetModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Paper link: https://openreview.net/pdf?id=ju_Uqw384Oq\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, configs):\n",
    "        super(TimesNetModel, self).__init__()\n",
    "        self.configs = configs\n",
    "        self.model = nn.ModuleList([TimesBlock(configs) for _ in range(configs.e_layers)])\n",
    "        self.enc_embedding = DataEmbedding(configs.enc_in, configs.d_model, configs.embed, configs.freq, configs.dropout)\n",
    "        self.layer = configs.e_layers\n",
    "        self.layer_norm = nn.LayerNorm(configs.d_model)\n",
    "        self.act = nn.GELU()\n",
    "        self.dropout = nn.Dropout(configs.dropout)\n",
    "\n",
    "        # Output projection layer\n",
    "        self.projection = nn.Linear(configs.d_model * configs.seq_len, configs.num_classes)\n",
    "\n",
    "    def classification(self, x_enc, x_mark_enc):\n",
    "        # Embedding\n",
    "        enc_out = self.enc_embedding(x_enc, None)  # [B, T, C]\n",
    "\n",
    "        # TimesNet Blocks\n",
    "        for i in range(self.layer):\n",
    "            enc_out = self.layer_norm(self.model[i](enc_out))\n",
    "\n",
    "        # Output processing\n",
    "        output = self.act(enc_out)\n",
    "        output = self.dropout(output)\n",
    "        output = output * x_mark_enc.unsqueeze(-1)\n",
    "        output = output.reshape(output.shape[0], -1)\n",
    "        output = self.projection(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc, x_dec=None, x_mark_dec=None, mask=None):\n",
    "        dec_out = self.classification(x_enc, x_mark_enc)\n",
    "        return dec_out  # [B, N]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TimesNet + Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FFT_for_Period(x, k=2):\n",
    "    # [B, T, C]\n",
    "    xf = torch.fft.rfft(x, dim=1)\n",
    "    # find period by amplitudes\n",
    "    frequency_list = abs(xf).mean(0).mean(-1)\n",
    "    frequency_list[0] = 0\n",
    "    _, top_list = torch.topk(frequency_list, k)\n",
    "    top_list = top_list.detach().cpu().numpy()\n",
    "    period = x.shape[1] // top_list\n",
    "\n",
    "    # print(\"period.shape = \", period.shape, top_list.shape, top_list, period)\n",
    "    return period, abs(xf).mean(-1)[:, top_list]\n",
    "\n",
    "\n",
    "class TimesBlock(nn.Module):\n",
    "    def __init__(self, configs):\n",
    "        super(TimesBlock, self).__init__()\n",
    "        self.seq_len = configs.seq_len\n",
    "        self.pred_len = configs.pred_len\n",
    "        self.k = configs.top_k\n",
    "        # parameter-efficient design\n",
    "        self.conv = nn.Sequential(\n",
    "            Inception_Block_V1(configs.d_model, configs.d_ff,\n",
    "                               num_kernels=configs.num_kernels),\n",
    "            nn.GELU(),\n",
    "            Inception_Block_V1(configs.d_ff, configs.d_model,\n",
    "                               num_kernels=configs.num_kernels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(\"Input shape:\", x.shape)\n",
    "        B, T, N = x.size()\n",
    "        period_list, period_weight = FFT_for_Period(x, self.k)\n",
    "\n",
    "        # print(\"period_list shape = \", period_list.shape, period_list)\n",
    "\n",
    "        # print(\"period_list period_weight shape:\", period_list.shape, period_weight.shape, self.k, self.seq_len, self.pred_len)\n",
    "\n",
    "        res = []\n",
    "        for i in range(self.k):\n",
    "            period = period_list[i]\n",
    "            # padding\n",
    "            if (self.seq_len + self.pred_len) % period != 0:\n",
    "                length = (\n",
    "                                 ((self.seq_len + self.pred_len) // period) + 1) * period\n",
    "\n",
    "                # print(\"length = \", length, self.seq_len, self.pred_len, period)\n",
    "                padding = torch.zeros([x.shape[0], (length - (self.seq_len + self.pred_len)), x.shape[2]]).to(x.device)\n",
    "\n",
    "                # print(\"padding x shape = \", padding.shape, x.shape)\n",
    "                out = torch.cat([x, padding], dim=1)\n",
    "                # print(\"padding out shape = \", out.shape)\n",
    "            else:\n",
    "                length = (self.seq_len + self.pred_len)\n",
    "                out = x\n",
    "\n",
    "            # print(\"out.shape = \", out.shape, length, period, length // period, N )\n",
    "            # reshape\n",
    "            out = out.reshape(B, length // period, period,\n",
    "                              N).permute(0, 3, 1, 2).contiguous()\n",
    "            # 2D conv: from 1d Variation to 2d Variation\n",
    "            out = self.conv(out)\n",
    "            # reshape back\n",
    "            out = out.permute(0, 2, 3, 1).reshape(B, -1, N)\n",
    "            res.append(out[:, :(self.seq_len + self.pred_len), :])\n",
    "        res = torch.stack(res, dim=-1)\n",
    "        # adaptive aggregation\n",
    "        period_weight = F.softmax(period_weight, dim=1)\n",
    "        period_weight = period_weight.unsqueeze(\n",
    "            1).unsqueeze(1).repeat(1, T, N, 1)\n",
    "        res = torch.sum(res * period_weight, -1)\n",
    "        # residual connection\n",
    "        res = res + x\n",
    "        return res\n",
    "\n",
    "\n",
    "class TimesNetModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Paper link: https://openreview.net/pdf?id=ju_Uqw384Oq\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, configs):\n",
    "        super(TimesNetModel, self).__init__()\n",
    "        self.configs = configs\n",
    "        self.model = nn.ModuleList([TimesBlock(configs) for _ in range(configs.e_layers)])\n",
    "        self.enc_embedding = DataEmbedding(configs.enc_in, configs.d_model, configs.embed, configs.freq, configs.dropout)\n",
    "        self.layer = configs.e_layers\n",
    "        self.layer_norm = nn.LayerNorm(configs.d_model)\n",
    "        self.act = nn.GELU()\n",
    "        self.dropout = nn.Dropout(configs.dropout)\n",
    "\n",
    "        # Define self-attention layer\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=configs.d_model, num_heads=configs.n_heads, dropout=configs.dropout)\n",
    "\n",
    "        self.projection = nn.Linear(configs.d_model * configs.seq_len, configs.num_classes)\n",
    "\n",
    "\n",
    "    def classification(self, x_enc, x_mark_enc):\n",
    "        # Embedding\n",
    "        enc_out = self.enc_embedding(x_enc, None)  # [B, T, C]\n",
    "\n",
    "        # TimesNet Blocks\n",
    "        for i in range(self.layer):\n",
    "            enc_out = self.layer_norm(self.model[i](enc_out))\n",
    "\n",
    "        # Prepare for attention: [T, B, C]\n",
    "        enc_out = enc_out.permute(1, 0, 2)\n",
    "\n",
    "        # Apply self-attention\n",
    "        attn_out, _ = self.attention(enc_out, enc_out, enc_out)\n",
    "\n",
    "        # Residual connection and layer normalization\n",
    "        enc_out = self.layer_norm(enc_out + attn_out)\n",
    "\n",
    "        # Reshape back: [B, T, C]\n",
    "        enc_out = enc_out.permute(1, 0, 2)\n",
    "\n",
    "        # Output processing remains the same\n",
    "        output = self.act(enc_out)\n",
    "        output = self.dropout(output)\n",
    "        output = output * x_mark_enc.unsqueeze(-1)\n",
    "        output = output.reshape(output.shape[0], -1)\n",
    "        output = self.projection(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc, x_dec=None, x_mark_dec=None, mask=None):\n",
    "        dec_out = self.classification(x_enc, x_mark_enc)\n",
    "        return dec_out  # [B, N]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import mlflow.data\n",
    "# import torch\n",
    "# from tqdm import tqdm\n",
    "# import mlflow\n",
    "# import mlflow.pytorch\n",
    "# from torchmetrics.classification import MulticlassAccuracy\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# model = TimesNetModel(configs=args)\n",
    "# device = 'cuda'\n",
    "# model = model.to(device)\n",
    "# loss = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "# model_init_state = model.state_dict()\n",
    "\n",
    "# losses = []\n",
    "# test_accuracies = []\n",
    "# train_time = 0.0\n",
    "# end_val_epochs = []\n",
    "\n",
    "# # Initialize MLflow\n",
    "# if not mlflow.active_run():\n",
    "#     mlflow.start_run()\n",
    "# else:\n",
    "#     mlflow.end_run()\n",
    "#     mlflow.start_run()\n",
    "\n",
    "# args.learning_rate = 0.0011\n",
    "# args.batch_size = 256\n",
    "# args.epoch = 100\n",
    "# early_stopping_patience = 5  # Number of epochs to wait for improvement\n",
    "# early_stopping_counter = 0\n",
    "# min_train_loss = float('inf')\n",
    "\n",
    "# # Set training data\n",
    "# dataset = mlflow.data.from_pandas(\n",
    "#     train, targets='Activity', name=\"UCI-HAR\"\n",
    "# )\n",
    "# mlflow.log_input(dataset, \"dataset\")\n",
    "\n",
    "# model.load_state_dict(model_init_state)\n",
    "\n",
    "# # Define optimizer and CosineAnnealingLR scheduler\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "# # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epoch, eta_min=1e-5)\n",
    "\n",
    "# train_loss = []\n",
    "# train_accuracy = []\n",
    "# num_steps = train_set.__len__() // args.batch_size\n",
    "\n",
    "# # Initialize torchmetrics accuracy\n",
    "# accuracy_metric = MulticlassAccuracy(num_classes=args.num_classes).to(device)  # Ensure it’s on the same device as the model\n",
    "\n",
    "# # Log initial parameters and model\n",
    "# mlflow.log_param(\"learning_rate\", args.learning_rate)\n",
    "# mlflow.log_param(\"batch_size\", args.batch_size)\n",
    "# mlflow.log_param(\"num_epochs\", args.epoch)\n",
    "# mlflow.pytorch.log_model(model, \"initial_model\")\n",
    "\n",
    "# for epoch in range(args.epoch):\n",
    "#     print('Epoch {}/{}'.format(epoch + 1, args.epoch))\n",
    "\n",
    "#     epoch_train_loss = 0\n",
    "#     model.train()\n",
    "#     accuracy_metric.reset()  # Reset accuracy for each epoch\n",
    "\n",
    "#     with tqdm(total=len(train_loader), desc=f\"Epoch {epoch+1}/{args.epoch}\", unit=\"batch\") as pbar:\n",
    "#         for x, y, padding_x_mask in train_loader:\n",
    "#             optimizer.zero_grad()\n",
    "\n",
    "#             # Forward pass\n",
    "#             pred = model(x, padding_x_mask)\n",
    "#             step_loss = loss(pred, y)\n",
    "\n",
    "#             # Backward pass and optimize\n",
    "#             step_loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             # Accumulate training loss\n",
    "#             epoch_train_loss += step_loss.item()\n",
    "\n",
    "#             # Update accuracy\n",
    "#             accuracy_metric.update(pred, y)\n",
    "#             pbar.update(1)\n",
    "\n",
    "#     # Calculate average training loss and accuracy\n",
    "#     epoch_train_loss /= num_steps\n",
    "#     epoch_train_acc = accuracy_metric.compute().item()  # Get the final accuracy for the epoch\n",
    "\n",
    "#     # Adjust learning rate using CosineAnnealingLR\n",
    "#     # scheduler.step()\n",
    "\n",
    "#     # Early stopping based on training loss\n",
    "#     if epoch_train_loss < min_train_loss:\n",
    "#         min_train_loss = epoch_train_loss\n",
    "#         early_stopping_counter = 0  # Reset counter if training loss improves\n",
    "#         mlflow.pytorch.log_model(model, \"best_model\")  # Save the best model to MLflow\n",
    "#     else:\n",
    "#         early_stopping_counter += 1\n",
    "#         if early_stopping_counter >= early_stopping_patience:\n",
    "#             print(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
    "#             break\n",
    "\n",
    "#     # Log metrics to MLflow\n",
    "#     mlflow.log_metric(\"train_loss\", epoch_train_loss, step=epoch)\n",
    "#     mlflow.log_metric(\"train_accuracy\", epoch_train_acc, step=epoch)\n",
    "#     mlflow.log_metric(\"learning_rate\", optimizer.param_groups[0]['lr'], step=epoch)\n",
    "\n",
    "#     print(f\"Train loss: {epoch_train_loss:.4f}, Train accuracy: {epoch_train_acc:.4f}\")\n",
    "#     print(f\"Learning rate after epoch {epoch + 1}: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "# # Log the final model\n",
    "# mlflow.pytorch.log_model(model, \"final_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-01 00:03:50,814] A new study created in memory with name: no-name-e3378f7d-7513-46fc-b3ac-1e65de05624f\n",
      "C:\\Users\\Muhammad Rifqi Fauzi\\AppData\\Local\\Temp\\ipykernel_19220\\276120702.py:21: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  args.learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "C:\\Users\\Muhammad Rifqi Fauzi\\AppData\\Local\\Temp\\ipykernel_19220\\276120702.py:31: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  args.dropout = trial.suggest_uniform('dropout', 0.0, 0.5)      # Dropout rate\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import torch\n",
    "from torchmetrics.classification import (\n",
    "    MulticlassAccuracy, MulticlassF1Score, MulticlassPrecision, MulticlassRecall,\n",
    "    MulticlassConfusionMatrix, MulticlassROC\n",
    ")\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define your model classes (TimesBlock, TimesNetModel) here\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Objective function for Optuna hyperparameter optimization.\n",
    "    This function will be called by Optuna to perform the hyperparameter search.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Optuna hyperparameter search space for model parameters and training\n",
    "    args.learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
    "    args.batch_size = trial.suggest_int('batch_size', 32, 512, step=32)\n",
    "    args.num_epochs = trial.suggest_int('num_epochs', 10, 100)\n",
    "    \n",
    "    # Model hyperparameters\n",
    "    args.n_heads = trial.suggest_int('n_heads', 4, 16, step=2)  # Number of attention heads\n",
    "    # Ensure d_model is divisible by n_heads\n",
    "    args.d_model = trial.suggest_int('d_model', 64, 512, step=64)\n",
    "    while args.d_model % args.n_heads != 0:\n",
    "        args.d_model += 1  # Ensure divisibility by n_heads\n",
    "    \n",
    "    args.num_kernels = trial.suggest_int('num_kernels', 16, 128, step=16)  # Number of kernels for Inception block\n",
    "    args.dropout = trial.suggest_uniform('dropout', 0.0, 0.5)      # Dropout rate\n",
    "    args.e_layers = trial.suggest_int('e_layers', 2, 6)              # Number of TimesNet blocks\n",
    "\n",
    "    # Choose optimizer based on Optuna's suggestion\n",
    "    optimizer_choice = trial.suggest_categorical('optimizer', ['Adam', 'SGD', 'RMSprop', 'Adagrad'])\n",
    "\n",
    "    # Normalize the training, validation, and test data if specified\n",
    "    if args.normalize_way == 'single':\n",
    "        x_train = normalize(x_train)\n",
    "        x_test = normalize(x_test)\n",
    "\n",
    "    # Convert numpy arrays to tensors and create the datasets\n",
    "    train_set = HARDataset(torch.from_numpy(x_train).type(torch.FloatTensor).to(device).permute(0,2,1),\n",
    "                        torch.from_numpy(y_train).type(torch.FloatTensor).to(device).to(torch.int64))\n",
    "    test_set = HARDataset(torch.from_numpy(x_test).type(torch.FloatTensor).to(device).permute(0,2,1),\n",
    "                        torch.from_numpy(y_test).type(torch.FloatTensor).to(device).to(torch.int64))\n",
    "\n",
    "    # Create DataLoaders for training, validation, and testing sets\n",
    "    train_loader = DataLoader(train_set, batch_size=args.batch_size, num_workers=0, drop_last=True, \n",
    "                            collate_fn=lambda x: collate_fn(x, device, max_len=args.seq_len))\n",
    "    test_loader = DataLoader(test_set, batch_size=args.batch_size, num_workers=0, \n",
    "                            collate_fn=lambda x: collate_fn(x, device, max_len=args.seq_len))\n",
    "\n",
    "    \n",
    "    model = TimesNetModel(configs=args)\n",
    "    model = model.to(device)\n",
    "    model_init_state = model.state_dict()\n",
    "    model.load_state_dict(model_init_state)\n",
    "\n",
    "    if optimizer_choice == 'Adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "    elif optimizer_choice == 'SGD':\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=args.learning_rate, momentum=0.9)\n",
    "    elif optimizer_choice == 'RMSprop':\n",
    "        optimizer = torch.optim.RMSprop(model.parameters(), lr=args.learning_rate, alpha=0.99)\n",
    "    elif optimizer_choice == 'Adagrad':\n",
    "        optimizer = torch.optim.Adagrad(model.parameters(), lr=args.learning_rate)\n",
    "\n",
    "    # Log hyperparameters and model configuration\n",
    "    mlflow.log_params({\n",
    "        'learning_rate': args.learning_rate,\n",
    "        'batch_size': args.batch_size,\n",
    "        'num_epochs': args.num_epochs,\n",
    "        'd_model': args.d_model,\n",
    "        'n_heads': args.n_heads,\n",
    "        'num_kernels': args.num_kernels,\n",
    "        'dropout': args.dropout,\n",
    "        'e_layers': args.e_layers,\n",
    "        'optimizer': optimizer_choice,\n",
    "        'dataset': 'UCI-HAR'\n",
    "    })\n",
    "\n",
    "    # Initialize metrics and loss\n",
    "    accuracy_metric = MulticlassAccuracy(num_classes=args.num_classes).to(device)\n",
    "    f1_score_metric = MulticlassF1Score(average='macro', num_classes=args.num_classes).to(device)\n",
    "    precision_metric = MulticlassPrecision(average='macro', num_classes=args.num_classes).to(device)\n",
    "    recall_metric = MulticlassRecall(average='macro', num_classes=args.num_classes).to(device)\n",
    "    confusion_matrix_metric = MulticlassConfusionMatrix(num_classes=args.num_classes).to(device)\n",
    "    roc_metric = MulticlassROC(num_classes=args.num_classes).to(device)\n",
    "\n",
    "    loss_func = nn.CrossEntropyLoss().to(device)\n",
    "    \n",
    "    # Training loop\n",
    "    min_train_loss = float('inf')\n",
    "    early_stopping_counter = 0\n",
    "    early_stopping_patience = 5\n",
    "    num_steps = len(train_loader) // args.batch_size\n",
    "\n",
    "    for epoch in range(args.num_epochs):\n",
    "        epoch_train_loss = 0\n",
    "        model.train()\n",
    "        accuracy_metric.reset()  # Reset accuracy for each epoch\n",
    "\n",
    "        with tqdm(total=len(train_loader), desc=f\"Epoch {epoch+1}/{args.num_epochs}\", unit=\"batch\") as pbar:\n",
    "            for x, y, padding_x_mask in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                pred = model(x, padding_x_mask)\n",
    "                step_loss = loss_func(pred, y)\n",
    "\n",
    "                # Backward pass and optimize\n",
    "                step_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Accumulate training loss\n",
    "                epoch_train_loss += step_loss.item()\n",
    "\n",
    "                # Update accuracy\n",
    "                accuracy_metric.update(pred, y)\n",
    "                pbar.update(1)\n",
    "\n",
    "        # Calculate average training loss and accuracy\n",
    "        epoch_train_loss /= num_steps\n",
    "        epoch_train_acc = accuracy_metric.compute().item()  # Get the final accuracy for the epoch\n",
    "\n",
    "        # Early stopping based on training loss\n",
    "        if epoch_train_loss < min_train_loss:\n",
    "            min_train_loss = epoch_train_loss\n",
    "            early_stopping_counter = 0  # Reset counter if training loss improves\n",
    "            mlflow.pytorch.log_model(model, \"best_model\")  # Save the best model to MLflow\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "            if early_stopping_counter >= early_stopping_patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
    "                break\n",
    "\n",
    "        # Log metrics to MLflow\n",
    "        mlflow.log_metric(\"train_loss\", epoch_train_loss, step=epoch)\n",
    "        mlflow.log_metric(\"train_accuracy\", epoch_train_acc, step=epoch)\n",
    "\n",
    "    # Evaluate the model on the test set after training\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    test_loss = 0\n",
    "    test_accuracy = 0\n",
    "    test_f1_score = 0\n",
    "    test_precision = 0\n",
    "    test_recall = 0\n",
    "    confusion_matrix = None\n",
    "    roc_curves = None\n",
    "    num_steps_test = len(test_loader) // args.batch_size\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation for testing\n",
    "        for x_test, y_test, padding_x_mask in test_loader:\n",
    "            x_test, y_test, padding_x_mask = x_test.to(device), y_test.to(device), padding_x_mask.to(device)\n",
    "            # Forward pass\n",
    "            pred_test = model(x_test, padding_x_mask)\n",
    "            step_test_loss = loss_func(pred_test, y_test)\n",
    "\n",
    "            # Accumulate test loss and metrics\n",
    "            test_loss += step_test_loss.item()\n",
    "\n",
    "            # Update metrics\n",
    "            accuracy_metric.update(pred_test, y_test)\n",
    "            f1_score_metric.update(pred_test, y_test)\n",
    "            precision_metric.update(pred_test, y_test)\n",
    "            recall_metric.update(pred_test, y_test)\n",
    "            confusion_matrix_metric.update(pred_test, y_test)\n",
    "            roc_metric.update(pred_test, y_test)\n",
    "\n",
    "    # Compute average test loss and finalize metrics\n",
    "    test_loss /= num_steps_test\n",
    "    test_accuracy = accuracy_metric.compute().item()\n",
    "    test_f1_score = f1_score_metric.compute().item()\n",
    "    test_precision = precision_metric.compute().item()\n",
    "    test_recall = recall_metric.compute().item()\n",
    "    confusion_matrix = confusion_matrix_metric.compute()\n",
    "    roc_curves = roc_metric.compute()  # This provides the ROC for each class\n",
    "\n",
    "    # Log test metrics to MLflow\n",
    "    mlflow.log_metric(\"test_loss\", test_loss)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "    mlflow.log_metric(\"test_f1_score\", test_f1_score)\n",
    "    mlflow.log_metric(\"test_precision\", test_precision)\n",
    "    mlflow.log_metric(\"test_recall\", test_recall)\n",
    "\n",
    "    # Log confusion matrix and ROC curve (if desired)\n",
    "    mlflow.log_artifact(confusion_matrix, \"confusion_matrix.json\")\n",
    "    mlflow.log_artifact(roc_curves, \"roc_curves.json\")\n",
    "\n",
    "    # Print test results\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}, \"\n",
    "          f\"Test F1 Score: {test_f1_score:.4f}, Test Precision: {test_precision:.4f}, \"\n",
    "          f\"Test Recall: {test_recall:.4f}\")\n",
    "\n",
    "    # End the MLflow run\n",
    "    mlflow.end_run()\n",
    "\n",
    "    # Return the evaluation metric (e.g., train loss) for Optuna to minimize\n",
    "    return min_train_loss\n",
    "\n",
    "# Optuna study for hyperparameter optimization\n",
    "study = optuna.create_study(direction='minimize')  # Minimize the training loss\n",
    "study.optimize(objective, n_trials=20)  # n_trials is the number of hyperparameter search trials\n",
    "\n",
    "# Log the best hyperparameters found by Optuna\n",
    "print(\"Best trial:\")\n",
    "best_trial = study.best_trial\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Optionally, log the best model and hyperparameters to MLflow\n",
    "mlflow.log_params(best_trial.params)\n",
    "\n",
    "# You can save the best model as well\n",
    "best_model = model  # Assume the model state is updated to the\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ray Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-12-01 00:57:35</td></tr>\n",
       "<tr><td>Running for: </td><td>00:01:46.07        </td></tr>\n",
       "<tr><td>Memory:      </td><td>11.4/15.8 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: None | Iter 5.000: None<br>Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  d_model</th><th style=\"text-align: right;\">  dropout</th><th style=\"text-align: right;\">  epoch</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  n_heads</th><th style=\"text-align: right;\">  num_kernels</th><th>optimizer  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>objective_5524a_00000</td><td>RUNNING </td><td>127.0.0.1:22316</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">       64</td><td style=\"text-align: right;\">0.0780093</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.000132929</td><td style=\"text-align: right;\">       16</td><td style=\"text-align: right;\">           16</td><td>RMSprop    </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 00:55:49,540\tWARNING trial.py:647 -- The path to the trial log directory is too long (max length: 260. Consider using `trial_dirname_creator` to shorten the path. Path: C:\\Users\\MUHAMM~1\\AppData\\Local\\Temp\\ray\\session_2024-12-01_00-55-44_765482_22596\\artifacts\\2024-12-01_00-55-49\\objective_2024-12-01_00-55-49\\driver_artifacts\\objective_5524a_00000_0_batch_size=128,d_model=64,dropout=0.0780,epoch=20,lr=0.0001,n_heads=16,num_kernels=16,optimizer=RMSprop_2024-12-01_00-55-49\n",
      "2024-12-01 00:55:49,690\tWARNING trial.py:647 -- The path to the trial log directory is too long (max length: 260. Consider using `trial_dirname_creator` to shorten the path. Path: C:\\Users\\MUHAMM~1\\AppData\\Local\\Temp\\ray\\session_2024-12-01_00-55-44_765482_22596\\artifacts\\2024-12-01_00-55-49\\objective_2024-12-01_00-55-49\\driver_artifacts\\objective_5524a_00000_0_batch_size=128,d_model=64,dropout=0.0780,epoch=20,lr=0.0001,n_heads=16,num_kernels=16,optimizer=RMSprop_2024-12-01_00-55-49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m Warning: The actor ImplicitFunc is very large (22 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(pid=22316)\u001b[0m f:\\Program Files\\Anaconda\\envs\\py310\\lib\\site-packages\\torch\\storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(pid=22316)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "2024-12-01 00:55:58,250\tWARNING trial.py:647 -- The path to the trial log directory is too long (max length: 260. Consider using `trial_dirname_creator` to shorten the path. Path: C:\\Users\\MUHAMM~1\\AppData\\Local\\Temp\\ray\\session_2024-12-01_00-55-44_765482_22596\\artifacts\\2024-12-01_00-55-49\\objective_2024-12-01_00-55-49\\driver_artifacts\\objective_5524a_00000_0_batch_size=128,d_model=64,dropout=0.0780,epoch=20,lr=0.0001,n_heads=16,num_kernels=16,optimizer=RMSprop_2024-12-01_00-55-49\n",
      "2024-12-01 00:55:58,252\tWARNING trial.py:647 -- The path to the trial log directory is too long (max length: 260. Consider using `trial_dirname_creator` to shorten the path. Path: C:\\Users\\MUHAMM~1\\AppData\\Local\\Temp\\ray\\session_2024-12-01_00-55-44_765482_22596\\artifacts\\2024-12-01_00-55-49\\objective_2024-12-01_00-55-49\\driver_artifacts\\objective_5524a_00000_0_batch_size=128,d_model=64,dropout=0.0780,epoch=20,lr=0.0001,n_heads=16,num_kernels=16,optimizer=RMSprop_2024-12-01_00-55-49\n",
      "\u001b[36m(objective pid=22316)\u001b[0m 2024/12/01 00:56:00 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "\u001b[36m(objective pid=22316)\u001b[0m The git executable must be specified in one of the following ways:\n",
      "\u001b[36m(objective pid=22316)\u001b[0m     - be included in your $PATH\n",
      "\u001b[36m(objective pid=22316)\u001b[0m     - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "\u001b[36m(objective pid=22316)\u001b[0m     - explicitly set via git.refresh(<full-path-to-git-executable>)\n",
      "\u001b[36m(objective pid=22316)\u001b[0m \n",
      "\u001b[36m(objective pid=22316)\u001b[0m All git commands will error until this is rectified.\n",
      "\u001b[36m(objective pid=22316)\u001b[0m \n",
      "\u001b[36m(objective pid=22316)\u001b[0m This initial message can be silenced or aggravated in the future by setting the\n",
      "\u001b[36m(objective pid=22316)\u001b[0m $GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "\u001b[36m(objective pid=22316)\u001b[0m     - quiet|q|silence|s|silent|none|n|0: for no message or exception\n",
      "\u001b[36m(objective pid=22316)\u001b[0m     - warn|w|warning|log|l|1: for a warning message (logging level CRITICAL, displayed by default)\n",
      "\u001b[36m(objective pid=22316)\u001b[0m     - error|e|exception|raise|r|2: for a raised exception\n",
      "\u001b[36m(objective pid=22316)\u001b[0m \n",
      "\u001b[36m(objective pid=22316)\u001b[0m Example:\n",
      "\u001b[36m(objective pid=22316)\u001b[0m     export GIT_PYTHON_REFRESH=quiet\n",
      "\u001b[36m(objective pid=22316)\u001b[0m \n",
      "Epoch 1/20:   0%|          | 0/919 [00:00<?, ?batch/s]\n",
      "Epoch 1/20:   0%|          | 1/919 [00:02<40:52,  2.67s/batch]\n",
      "Epoch 1/20:   0%|          | 2/919 [00:04<34:36,  2.26s/batch]\n",
      "Epoch 1/20:   0%|          | 3/919 [00:06<32:33,  2.13s/batch]\n",
      "Epoch 1/20:   0%|          | 4/919 [00:08<31:35,  2.07s/batch]\n",
      "Epoch 1/20:   1%|          | 5/919 [00:10<31:05,  2.04s/batch]\n",
      "Epoch 1/20:   1%|          | 6/919 [00:12<30:45,  2.02s/batch]\n",
      "Epoch 1/20:   1%|          | 7/919 [00:14<30:30,  2.01s/batch]\n",
      "Epoch 1/20:   1%|          | 8/919 [00:16<30:25,  2.00s/batch]\n",
      "Epoch 1/20:   1%|          | 9/919 [00:18<30:08,  1.99s/batch]\n",
      "Epoch 1/20:   1%|          | 10/919 [00:20<30:06,  1.99s/batch]\n",
      "Epoch 1/20:   1%|          | 11/919 [00:22<29:38,  1.96s/batch]\n",
      "Epoch 1/20:   1%|▏         | 12/919 [00:24<29:00,  1.92s/batch]\n",
      "Epoch 1/20:   1%|▏         | 13/919 [00:26<28:34,  1.89s/batch]\n",
      "Epoch 1/20:   2%|▏         | 14/919 [00:27<28:15,  1.87s/batch]\n",
      "Epoch 1/20:   2%|▏         | 15/919 [00:29<28:27,  1.89s/batch]\n",
      "Epoch 1/20:   2%|▏         | 16/919 [00:31<28:34,  1.90s/batch]\n",
      "Epoch 1/20:   2%|▏         | 17/919 [00:33<28:06,  1.87s/batch]\n",
      "Epoch 1/20:   2%|▏         | 18/919 [00:35<27:22,  1.82s/batch]\n",
      "Epoch 1/20:   2%|▏         | 19/919 [00:37<27:14,  1.82s/batch]\n",
      "Epoch 1/20:   2%|▏         | 20/919 [00:38<27:45,  1.85s/batch]\n",
      "Epoch 1/20:   2%|▏         | 21/919 [00:40<28:05,  1.88s/batch]\n",
      "Epoch 1/20:   2%|▏         | 22/919 [00:42<28:09,  1.88s/batch]\n",
      "Epoch 1/20:   3%|▎         | 23/919 [00:44<28:42,  1.92s/batch]\n",
      "Epoch 1/20:   3%|▎         | 24/919 [00:46<29:04,  1.95s/batch]\n",
      "Epoch 1/20:   3%|▎         | 25/919 [00:48<29:18,  1.97s/batch]\n",
      "Epoch 1/20:   3%|▎         | 26/919 [00:50<29:28,  1.98s/batch]\n",
      "Epoch 1/20:   3%|▎         | 27/919 [00:52<29:33,  1.99s/batch]\n",
      "Epoch 1/20:   3%|▎         | 28/919 [00:54<29:36,  1.99s/batch]\n",
      "Epoch 1/20:   3%|▎         | 29/919 [00:56<29:39,  2.00s/batch]\n",
      "Epoch 1/20:   3%|▎         | 30/919 [00:58<29:29,  1.99s/batch]\n",
      "Epoch 1/20:   3%|▎         | 31/919 [01:00<29:22,  1.99s/batch]\n",
      "Epoch 1/20:   3%|▎         | 32/919 [01:02<28:59,  1.96s/batch]\n",
      "Epoch 1/20:   4%|▎         | 33/919 [01:04<28:27,  1.93s/batch]\n",
      "Epoch 1/20:   4%|▎         | 34/919 [01:06<28:08,  1.91s/batch]\n",
      "Epoch 1/20:   4%|▍         | 35/919 [01:08<27:50,  1.89s/batch]\n",
      "Epoch 1/20:   4%|▍         | 36/919 [01:10<27:38,  1.88s/batch]\n",
      "Epoch 1/20:   4%|▍         | 37/919 [01:11<27:16,  1.86s/batch]\n",
      "Epoch 1/20:   4%|▍         | 38/919 [01:13<27:08,  1.85s/batch]\n",
      "Epoch 1/20:   4%|▍         | 39/919 [01:15<27:30,  1.88s/batch]\n",
      "Epoch 1/20:   4%|▍         | 40/919 [01:17<27:47,  1.90s/batch]\n",
      "Epoch 1/20:   4%|▍         | 41/919 [01:19<27:58,  1.91s/batch]\n",
      "Epoch 1/20:   5%|▍         | 42/919 [01:21<27:31,  1.88s/batch]\n",
      "Epoch 1/20:   5%|▍         | 43/919 [01:23<26:56,  1.85s/batch]\n",
      "Epoch 1/20:   5%|▍         | 44/919 [01:25<27:54,  1.91s/batch]\n",
      "Epoch 1/20:   5%|▍         | 45/919 [01:27<28:34,  1.96s/batch]\n",
      "Epoch 1/20:   5%|▌         | 46/919 [01:29<29:01,  1.99s/batch]\n",
      "Epoch 1/20:   5%|▌         | 47/919 [01:31<29:27,  2.03s/batch]\n",
      "Epoch 1/20:   5%|▌         | 48/919 [01:33<29:45,  2.05s/batch]\n",
      "Epoch 1/20:   5%|▌         | 49/919 [01:35<29:20,  2.02s/batch]\n",
      "Epoch 1/20:   5%|▌         | 50/919 [01:37<29:08,  2.01s/batch]\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from torchmetrics.classification import (\n",
    "    MulticlassAccuracy, MulticlassF1Score, MulticlassPrecision, MulticlassRecall,\n",
    "    MulticlassConfusionMatrix, MulticlassROC\n",
    ")\n",
    "from torch import nn\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define your model classes (TimesBlock, TimesNetModel) here\n",
    "\n",
    "def objective(config):\n",
    "    \"\"\"\n",
    "    Objective function for Ray Tune hyperparameter optimization.\n",
    "    This function will be called by Ray Tune to perform the hyperparameter search.\n",
    "    \"\"\"\n",
    "\n",
    "    # Update the existing args object with values from Ray Tune's config\n",
    "    for key, value in config.items():\n",
    "        setattr(args, key, value)\n",
    "\n",
    "    model = TimesNetModel(configs=args)\n",
    "    model = model.to(device)\n",
    "\n",
    "    if args.optimizer == 'Adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "    elif args.optimizer == 'SGD':\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, momentum=0.9)\n",
    "    elif args.optimizer == 'RMSprop':\n",
    "        optimizer = torch.optim.RMSprop(model.parameters(), lr=args.lr, alpha=0.99)\n",
    "    elif args.optimizer == 'Adagrad':\n",
    "        optimizer = torch.optim.Adagrad(model.parameters(), lr=args.lr)\n",
    "\n",
    "    # Log hyperparameters and model configuration\n",
    "    mlflow.log_params(vars(args))\n",
    "\n",
    "    # Initialize metrics and loss\n",
    "    accuracy_metric = MulticlassAccuracy(num_classes=args.num_classes).to(device)\n",
    "    f1_score_metric = MulticlassF1Score(average='macro', num_classes=args.num_classes).to(device)\n",
    "    precision_metric = MulticlassPrecision(average='macro', num_classes=args.num_classes).to(device)\n",
    "    recall_metric = MulticlassRecall(average='macro', num_classes=args.num_classes).to(device)\n",
    "    confusion_matrix_metric = MulticlassConfusionMatrix(num_classes=args.num_classes).to(device)\n",
    "    roc_metric = MulticlassROC(num_classes=args.num_classes).to(device)\n",
    "\n",
    "    loss_func = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    # Training loop\n",
    "    min_train_loss = float('inf')\n",
    "    num_steps = len(train_loader) // args.batch_size\n",
    "\n",
    "    for epoch in range(args.epoch):\n",
    "        epoch_train_loss = 0\n",
    "        model.train()\n",
    "        accuracy_metric.reset()  # Reset accuracy for each epoch\n",
    "\n",
    "        with tqdm(total=len(train_loader), desc=f\"Epoch {epoch+1}/{args.epoch}\", unit=\"batch\") as pbar:\n",
    "            for x, y, padding_x_mask in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                pred = model(x, padding_x_mask)\n",
    "                step_loss = loss_func(pred, y)\n",
    "\n",
    "                # Backward pass and optimize\n",
    "                step_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Accumulate training loss\n",
    "                epoch_train_loss += step_loss.item()\n",
    "\n",
    "                # Update accuracy\n",
    "                accuracy_metric.update(pred, y)\n",
    "                pbar.update(1)\n",
    "\n",
    "        # Calculate average training loss and accuracy\n",
    "        epoch_train_loss /= num_steps\n",
    "        epoch_train_acc = accuracy_metric.compute().item()\n",
    "\n",
    "        # Early stopping based on training loss\n",
    "        if epoch_train_loss < min_train_loss:\n",
    "            min_train_loss = epoch_train_loss\n",
    "            mlflow.pytorch.log_model(model, \"best_model\")  # Save the best model to MLflow\n",
    "\n",
    "        # Log metrics to MLflow\n",
    "        mlflow.log_metric(\"train_loss\", epoch_train_loss, step=epoch)\n",
    "        mlflow.log_metric(\"train_accuracy\", epoch_train_acc, step=epoch)\n",
    "\n",
    "        # Report intermediate results to Ray Tune\n",
    "        tune.report(train_loss=epoch_train_loss, train_accuracy=epoch_train_acc)\n",
    "\n",
    "    # Evaluate the model on the test set after training\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    test_loss = 0\n",
    "    test_accuracy = 0\n",
    "    test_f1_score = 0\n",
    "    test_precision = 0\n",
    "    test_recall = 0\n",
    "    confusion_matrix = None\n",
    "    roc_curves = None\n",
    "    num_steps_test = len(test_loader) // args.batch_size\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation for testing\n",
    "        for x_test, y_test, padding_x_mask in test_loader:\n",
    "            x_test, y_test = x_test.to(device), y_test.to(device)\n",
    "            padding_x_mask = padding_x_mask.to(device)\n",
    "            # Forward pass\n",
    "            pred_test = model(x_test, padding_x_mask)\n",
    "            step_test_loss = loss_func(pred_test, y_test)\n",
    "\n",
    "            # Accumulate test loss and metrics\n",
    "            test_loss += step_test_loss.item()\n",
    "\n",
    "            # Update metrics\n",
    "            accuracy_metric.update(pred_test, y_test)\n",
    "            f1_score_metric.update(pred_test, y_test)\n",
    "            precision_metric.update(pred_test, y_test)\n",
    "            recall_metric.update(pred_test, y_test)\n",
    "            confusion_matrix_metric.update(pred_test, y_test)\n",
    "            roc_metric.update(pred_test, y_test)\n",
    "\n",
    "    # Compute average test loss and finalize metrics\n",
    "    test_loss /= num_steps_test\n",
    "    test_accuracy = accuracy_metric.compute().item()\n",
    "    test_f1_score = f1_score_metric.compute().item()\n",
    "    test_precision = precision_metric.compute().item()\n",
    "    test_recall = recall_metric.compute().item()\n",
    "    confusion_matrix = confusion_matrix_metric.compute()\n",
    "    roc_curves = roc_metric.compute()\n",
    "\n",
    "    # Log test metrics to MLflow\n",
    "    mlflow.log_metric(\"test_loss\", test_loss)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "    mlflow.log_metric(\"test_f1_score\", test_f1_score)\n",
    "    mlflow.log_metric(\"test_precision\", test_precision)\n",
    "    mlflow.log_metric(\"test_recall\", test_recall)\n",
    "\n",
    "    # Log confusion matrix and ROC curve (if desired)\n",
    "    mlflow.log_artifact(confusion_matrix, \"confusion_matrix.json\")\n",
    "    mlflow.log_artifact(roc_curves, \"roc_curves.json\")\n",
    "\n",
    "    # Print test results\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}, \"\n",
    "          f\"Test F1 Score: {test_f1_score:.4f}, Test Precision: {test_precision:.4f}, \"\n",
    "          f\"Test Recall: {test_recall:.4f}\")\n",
    "\n",
    "    # End the MLflow run\n",
    "    mlflow.end_run()\n",
    "\n",
    "    # Return the evaluation metric (e.g., train loss) for Ray Tune to minimize\n",
    "    return min_train_loss\n",
    "\n",
    "# Ray Tune hyperparameter search space\n",
    "search_space = {\n",
    "    'lr': tune.loguniform(1e-5, 1e-2),\n",
    "    'batch_size': tune.choice([8, 16, 32, 64, 128]),\n",
    "    'epoch': tune.choice([10, 15, 20]),\n",
    "    'n_heads': tune.choice([4, 8, 16, 32]),\n",
    "    'd_model': tune.choice([64, 128, 256]),\n",
    "    'num_kernels': tune.choice([16, 32, 64]),\n",
    "    'dropout': tune.uniform(0.0, 0.5),\n",
    "    'optimizer': tune.choice(['Adam', 'SGD', 'RMSprop', 'Adagrad']),\n",
    "    'num_classes': 7  # Assuming you are working with a 7-class dataset\n",
    "}\n",
    "\n",
    "# Ray Tune's scheduler\n",
    "scheduler = ASHAScheduler(\n",
    "    metric=\"train_loss\",\n",
    "    mode=\"min\",\n",
    "    max_t=100,\n",
    "    grace_period=5,\n",
    "    reduction_factor=2\n",
    ")\n",
    "\n",
    "# Ray Tune's execution\n",
    "tune.run(\n",
    "    objective,\n",
    "    config=search_space,\n",
    "    scheduler=scheduler,\n",
    "    max_concurrent_trials=1,\n",
    "    num_samples=10,  # Number of trials\n",
    "    resources_per_trial={\"cpu\": 1, \"gpu\": 1},  # Resource allocation\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2166, Test Accuracy: 0.9504, Test F1 Score: 0.9502, Test Precision: 0.9510, Test Recall: 0.9504\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchmetrics.classification import (\n",
    "    MulticlassAccuracy, MulticlassF1Score, MulticlassPrecision, MulticlassRecall,\n",
    "    MulticlassConfusionMatrix, MulticlassROC\n",
    ")\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "# Initialize metrics\n",
    "accuracy_metric = MulticlassAccuracy(num_classes=args.num_classes).to(device)\n",
    "f1_score_metric = MulticlassF1Score(average='macro', num_classes=args.num_classes).to(device)\n",
    "precision_metric = MulticlassPrecision(average='macro', num_classes=args.num_classes).to(device)\n",
    "recall_metric = MulticlassRecall(average='macro', num_classes=args.num_classes).to(device)\n",
    "confusion_matrix_metric = MulticlassConfusionMatrix(num_classes=args.num_classes).to(device)\n",
    "roc_metric = MulticlassROC(num_classes=args.num_classes).to(device)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "loss_func = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "# No need to compute gradients for evaluation\n",
    "with torch.no_grad():\n",
    "    for x, y, padding_x_mask in test_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred = model(x, padding_x_mask)\n",
    "        loss = loss_func(pred, y)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Update metrics\n",
    "        accuracy_metric.update(pred, y)\n",
    "        f1_score_metric.update(pred, y)\n",
    "        precision_metric.update(pred, y)\n",
    "        recall_metric.update(pred, y)\n",
    "        confusion_matrix_metric.update(pred, y)\n",
    "        roc_metric.update(pred, y)\n",
    "\n",
    "# Compute average test loss and finalize metrics\n",
    "test_loss /= len(test_loader)\n",
    "test_accuracy = accuracy_metric.compute().item()\n",
    "test_f1_score = f1_score_metric.compute().item()\n",
    "test_precision = precision_metric.compute().item()\n",
    "test_recall = recall_metric.compute().item()\n",
    "confusion_matrix = confusion_matrix_metric.compute()\n",
    "roc_curves = roc_metric.compute()  # This provides the ROC for each class\n",
    "\n",
    "# Log test metrics to MLflow\n",
    "mlflow.log_metric(\"test_loss\", test_loss)\n",
    "mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "mlflow.log_metric(\"test_f1_score\", test_f1_score)\n",
    "mlflow.log_metric(\"test_precision\", test_precision)\n",
    "mlflow.log_metric(\"test_recall\", test_recall)\n",
    "\n",
    "# Print test results\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}, \"\n",
    "      f\"Test F1 Score: {test_f1_score:.4f}, Test Precision: {test_precision:.4f}, \"\n",
    "      f\"Test Recall: {test_recall:.4f}\")\n",
    "\n",
    "# End the MLflow run\n",
    "mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "confusion_matrix = confusion_matrix_metric.compute().cpu().numpy()\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig_, ax_ = roc_metric.plot(score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timeseries",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
