{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import time\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance\n",
    "\n",
    "curPath = os.path.abspath(os.path.dirname('models'))\n",
    "rootPath = os.path.split(curPath)[0]\n",
    "sys.path.append(rootPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_labels(labels):\n",
    "    indicies = np.unique(labels)\n",
    "    num_samples = labels.shape[0]\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        new_label = np.argwhere(labels[i] == indicies)[0][0]\n",
    "        labels[i] = new_label\n",
    "\n",
    "    return labels\n",
    "\n",
    "def collate_fn(data, device, max_len=None):\n",
    "    \"\"\"Build mini-batch tensors from a list of (X, mask) tuples. Mask input. Create\n",
    "    Args:\n",
    "        data: len(batch_size) list of tuples (X, y).\n",
    "            - X: torch tensor of shape (seq_length, feat_dim); variable seq_length.\n",
    "            - y: torch tensor of shape (num_labels,) : class indices or numerical targets\n",
    "                (for classification or regression, respectively). num_labels > 1 for multi-task models\n",
    "        max_len: global fixed sequence length. Used for architectures requiring fixed length input,\n",
    "            where the batch length cannot vary dynamically. Longer sequences are clipped, shorter are padded with 0s\n",
    "    Returns:\n",
    "        X: (batch_size, padded_length, feat_dim) torch tensor of masked features (input)\n",
    "        targets: (batch_size, padded_length, feat_dim) torch tensor of unmasked features (output)\n",
    "        target_masks: (batch_size, padded_length, feat_dim) boolean torch tensor\n",
    "            0 indicates masked values to be predicted, 1 indicates unaffected/\"active\" feature values\n",
    "        padding_masks: (batch_size, padded_length) boolean tensor, 1 means keep vector at this position, 0 means padding\n",
    "    \"\"\"\n",
    "\n",
    "    batch_size = len(data)\n",
    "    features, labels = zip(*data)\n",
    "\n",
    "    # Stack and pad features and masks (convert 2D to 3D tensors, i.e. add batch dimension)\n",
    "    lengths = [X.shape[0] for X in features]  # original sequence length for each time series\n",
    "    if max_len is None:\n",
    "        max_len = max(lengths)\n",
    "\n",
    "    X = torch.zeros(batch_size, max_len, features[0].shape[-1])  # (batch_size, padded_length, feat_dim)\n",
    "    for i in range(batch_size):\n",
    "        end = min(lengths[i], max_len)\n",
    "        X[i, :end, :] = features[i][:end, :]\n",
    "\n",
    "    targets = torch.stack(labels, dim=0)  # (batch_size, num_labels)\n",
    "\n",
    "    padding_masks = padding_mask(torch.tensor(lengths, dtype=torch.int16),\n",
    "                                 max_len=max_len)  # (batch_size, padded_length) boolean tensor, \"1\" means keep\n",
    "\n",
    "    return X.to(device), targets.to(device), padding_masks.to(device)\n",
    "\n",
    "\n",
    "def padding_mask(lengths, max_len=None):\n",
    "    \"\"\"\n",
    "    Used to mask padded positions: creates a (batch_size, max_len) boolean mask from a tensor of sequence lengths,\n",
    "    where 1 means keep element at this position (time step)\n",
    "    \"\"\"\n",
    "    batch_size = lengths.numel()\n",
    "    max_len = max_len or lengths.max_val()  # trick works because of overloading of 'or' operator for non-boolean types\n",
    "    return (torch.arange(0, max_len, device=lengths.device)\n",
    "            .type_as(lengths)\n",
    "            .repeat(batch_size, 1)\n",
    "            .lt(lengths.unsqueeze(1)))\n",
    "\n",
    "def set_seed(args):\n",
    "    random.seed(args.random_seed)\n",
    "    np.random.seed(args.random_seed)\n",
    "    torch.manual_seed(args.random_seed)\n",
    "    torch.cuda.manual_seed(args.random_seed)\n",
    "    torch.cuda.manual_seed_all(args.random_seed)\n",
    "\n",
    "\n",
    "class HARDataset(Dataset):\n",
    "    def __init__(self, dataset, target):\n",
    "        # (num_size, num_dimensions, series_length)\n",
    "        self.dataset = dataset.permute(0, 2, 1)\n",
    "        self.target = target\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.dataset[index], self.target[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target)\n",
    "    \n",
    "def normalize(data_set):\n",
    "    '''\n",
    "    The function is the same as normalize_per_series, but can be used for multiple variables.\n",
    "    '''\n",
    "    return TimeSeriesScalerMeanVariance().fit_transform(data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(backbone='fcn', random_seed=42, num_classes=0, normalize_way='single', input_size=1, target_points=96, patch_len=8, stride=8, labeled_ratio=0.1, task_name='classification', freq='h', seq_len=96, label_len=48, pred_len=0, seasonal_patterns='Monthly', inverse=False, top_k=3, num_kernels=6, enc_in=7, dec_in=7, c_out=7, d_model=64, n_heads=8, e_layers=3, d_layers=1, d_ff=64, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, use_gpu=True, gpu=1, loss='cross_entropy', optimizer='adam', lr=0.001, weight_decay=0.0, batch_size=8, epoch=15, cuda='cuda:1', save_dir='/SSD/lz/time_series_label_noise/result', save_csv_name='timesnet_ucr_supervised_0801_', classifier='linear', classifier_input=128)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Base setup\n",
    "parser.add_argument('--backbone', type=str, default='fcn', help='encoder backbone, fcn')\n",
    "parser.add_argument('--random_seed', type=int, default=42, help='shuffle seed')\n",
    "\n",
    "# Dataset setup\n",
    "parser.add_argument('--num_classes', type=int, default=0, help='number of class')\n",
    "parser.add_argument('--normalize_way', type=str, default='single', help='single or train_set')\n",
    "# parser.add_argument('--seq_len', type=int, default=46, help='seq_len')\n",
    "parser.add_argument('--input_size', type=int, default=1, help='input_size')\n",
    "\n",
    "# parser.add_argument('--patch_size', type=int, default=8, help='patch_size')\n",
    "# parser.add_argument('--stride', type=int, default=8, help='stride')\n",
    "\n",
    "parser.add_argument('--target_points', type=int, default=96, help='forecast horizon')\n",
    "\n",
    "# Patch\n",
    "parser.add_argument('--patch_len', type=int, default=8, help='patch length')\n",
    "parser.add_argument('--stride', type=int, default=8, help='stride between patch')\n",
    "\n",
    "# Semi training\n",
    "parser.add_argument('--labeled_ratio', type=float, default='0.1', help='0.1, 0.2, 0.4')\n",
    "\n",
    "# basic config\n",
    "parser.add_argument('--task_name', type=str, required=False, default='classification',\n",
    "                    help='task name, options:[long_term_forecast, short_term_forecast, imputation, classification, anomaly_detection]')\n",
    "parser.add_argument('--freq', type=str, default='h',\n",
    "                    help='freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h')\n",
    "\n",
    "# forecasting task\n",
    "parser.add_argument('--seq_len', type=int, default=96, help='input sequence length')\n",
    "parser.add_argument('--label_len', type=int, default=48, help='start token length')\n",
    "parser.add_argument('--pred_len', type=int, default=0, help='prediction sequence length')\n",
    "parser.add_argument('--seasonal_patterns', type=str, default='Monthly', help='subset for M4')\n",
    "parser.add_argument('--inverse', action='store_true', help='inverse output data', default=False)\n",
    "\n",
    "# model define\n",
    "parser.add_argument('--top_k', type=int, default=3, help='for TimesBlock')\n",
    "parser.add_argument('--num_kernels', type=int, default=6, help='for Inception')\n",
    "parser.add_argument('--enc_in', type=int, default=7, help='encoder input size')\n",
    "parser.add_argument('--dec_in', type=int, default=7, help='decoder input size')\n",
    "parser.add_argument('--c_out', type=int, default=7, help='output size')\n",
    "parser.add_argument('--d_model', type=int, default=64, help='dimension of model')   ###\n",
    "parser.add_argument('--n_heads', type=int, default=8, help='num of heads')\n",
    "parser.add_argument('--e_layers', type=int, default=3, help='num of encoder layers')\n",
    "parser.add_argument('--d_layers', type=int, default=1, help='num of decoder layers')\n",
    "parser.add_argument('--d_ff', type=int, default=64, help='dimension of fcn')\n",
    "parser.add_argument('--moving_avg', type=int, default=25, help='window size of moving average')\n",
    "parser.add_argument('--factor', type=int, default=1, help='attn factor')\n",
    "parser.add_argument('--distil', action='store_false',\n",
    "                    help='whether to use distilling in encoder, using this argument means not using distilling',\n",
    "                    default=True)\n",
    "parser.add_argument('--dropout', type=float, default=0.1, help='dropout')\n",
    "parser.add_argument('--embed', type=str, default='timeF',\n",
    "                    help='time features encoding, options:[timeF, fixed, learned]')\n",
    "parser.add_argument('--activation', type=str, default='gelu', help='activation')\n",
    "parser.add_argument('--output_attention', action='store_true', help='whether to output attention in ecoder')\n",
    "\n",
    "# GPU\n",
    "parser.add_argument('--use_gpu', type=bool, default=True, help='use gpu')\n",
    "parser.add_argument('--gpu', type=int, default=1, help='gpu')\n",
    "\n",
    "\n",
    "# training setup\n",
    "parser.add_argument('--loss', type=str, default='cross_entropy', help='loss function')\n",
    "parser.add_argument('--optimizer', type=str, default='adam', help='optimizer')\n",
    "parser.add_argument('--lr', type=float, default=0.001, help='learning rate')\n",
    "parser.add_argument('--weight_decay', type=float, default=0.0, help='weight decay')\n",
    "parser.add_argument('--batch_size', type=int, default=8, help='')\n",
    "parser.add_argument('--epoch', type=int, default=15, help='training epoch')\n",
    "parser.add_argument('--cuda', type=str, default='cuda:1')\n",
    "\n",
    "parser.add_argument('--save_dir', type=str, default='/SSD/lz/time_series_label_noise/result')\n",
    "parser.add_argument('--save_csv_name', type=str, default='timesnet_ucr_supervised_0801_')\n",
    "\n",
    "# classifier setup\n",
    "parser.add_argument('--classifier', type=str, default='linear', help='type of classifier(linear or nonlinear)')\n",
    "parser.add_argument('--classifier_input', type=int, default=128, help='input dim of the classifiers')\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "device = torch.device(args.cuda if torch.cuda.is_available() else \"cpu\")\n",
    "set_seed(args)\n",
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('dataset/UCI-HAR-Dataset/train.csv')\n",
    "test = pd.read_csv('dataset/UCI-HAR-Dataset/test.csv')\n",
    "\n",
    "train = train.drop('subject', axis=1)\n",
    "test = test.drop('subject', axis=1)\n",
    "\n",
    "labelNames = list(np.unique(train['Activity']))\n",
    "labelNames.sort()\n",
    "train['Activity'] = train['Activity'].apply(lambda x: labelNames.index(x))\n",
    "test['Activity'] = test['Activity'].apply(lambda x: labelNames.index(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tBodyAcc-mean()-X</th>\n",
       "      <th>tBodyAcc-mean()-Y</th>\n",
       "      <th>tBodyAcc-mean()-Z</th>\n",
       "      <th>tBodyAcc-std()-X</th>\n",
       "      <th>tBodyAcc-std()-Y</th>\n",
       "      <th>tBodyAcc-std()-Z</th>\n",
       "      <th>tBodyAcc-mad()-X</th>\n",
       "      <th>tBodyAcc-mad()-Y</th>\n",
       "      <th>tBodyAcc-mad()-Z</th>\n",
       "      <th>tBodyAcc-max()-X</th>\n",
       "      <th>...</th>\n",
       "      <th>fBodyBodyGyroJerkMag-skewness()</th>\n",
       "      <th>fBodyBodyGyroJerkMag-kurtosis()</th>\n",
       "      <th>angle(tBodyAccMean,gravity)</th>\n",
       "      <th>angle(tBodyAccJerkMean),gravityMean)</th>\n",
       "      <th>angle(tBodyGyroMean,gravityMean)</th>\n",
       "      <th>angle(tBodyGyroJerkMean,gravityMean)</th>\n",
       "      <th>angle(X,gravityMean)</th>\n",
       "      <th>angle(Y,gravityMean)</th>\n",
       "      <th>angle(Z,gravityMean)</th>\n",
       "      <th>Activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.288585</td>\n",
       "      <td>-0.020294</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.995279</td>\n",
       "      <td>-0.983111</td>\n",
       "      <td>-0.913526</td>\n",
       "      <td>-0.995112</td>\n",
       "      <td>-0.983185</td>\n",
       "      <td>-0.923527</td>\n",
       "      <td>-0.934724</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.298676</td>\n",
       "      <td>-0.710304</td>\n",
       "      <td>-0.112754</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>-0.464761</td>\n",
       "      <td>-0.018446</td>\n",
       "      <td>-0.841247</td>\n",
       "      <td>0.179941</td>\n",
       "      <td>-0.058627</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.278419</td>\n",
       "      <td>-0.016411</td>\n",
       "      <td>-0.123520</td>\n",
       "      <td>-0.998245</td>\n",
       "      <td>-0.975300</td>\n",
       "      <td>-0.960322</td>\n",
       "      <td>-0.998807</td>\n",
       "      <td>-0.974914</td>\n",
       "      <td>-0.957686</td>\n",
       "      <td>-0.943068</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.595051</td>\n",
       "      <td>-0.861499</td>\n",
       "      <td>0.053477</td>\n",
       "      <td>-0.007435</td>\n",
       "      <td>-0.732626</td>\n",
       "      <td>0.703511</td>\n",
       "      <td>-0.844788</td>\n",
       "      <td>0.180289</td>\n",
       "      <td>-0.054317</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.279653</td>\n",
       "      <td>-0.019467</td>\n",
       "      <td>-0.113462</td>\n",
       "      <td>-0.995380</td>\n",
       "      <td>-0.967187</td>\n",
       "      <td>-0.978944</td>\n",
       "      <td>-0.996520</td>\n",
       "      <td>-0.963668</td>\n",
       "      <td>-0.977469</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.390748</td>\n",
       "      <td>-0.760104</td>\n",
       "      <td>-0.118559</td>\n",
       "      <td>0.177899</td>\n",
       "      <td>0.100699</td>\n",
       "      <td>0.808529</td>\n",
       "      <td>-0.848933</td>\n",
       "      <td>0.180637</td>\n",
       "      <td>-0.049118</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.279174</td>\n",
       "      <td>-0.026201</td>\n",
       "      <td>-0.123283</td>\n",
       "      <td>-0.996091</td>\n",
       "      <td>-0.983403</td>\n",
       "      <td>-0.990675</td>\n",
       "      <td>-0.997099</td>\n",
       "      <td>-0.982750</td>\n",
       "      <td>-0.989302</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.117290</td>\n",
       "      <td>-0.482845</td>\n",
       "      <td>-0.036788</td>\n",
       "      <td>-0.012892</td>\n",
       "      <td>0.640011</td>\n",
       "      <td>-0.485366</td>\n",
       "      <td>-0.848649</td>\n",
       "      <td>0.181935</td>\n",
       "      <td>-0.047663</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.276629</td>\n",
       "      <td>-0.016570</td>\n",
       "      <td>-0.115362</td>\n",
       "      <td>-0.998139</td>\n",
       "      <td>-0.980817</td>\n",
       "      <td>-0.990482</td>\n",
       "      <td>-0.998321</td>\n",
       "      <td>-0.979672</td>\n",
       "      <td>-0.990441</td>\n",
       "      <td>-0.942469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.351471</td>\n",
       "      <td>-0.699205</td>\n",
       "      <td>0.123320</td>\n",
       "      <td>0.122542</td>\n",
       "      <td>0.693578</td>\n",
       "      <td>-0.615971</td>\n",
       "      <td>-0.847865</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>-0.043892</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 562 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tBodyAcc-mean()-X  tBodyAcc-mean()-Y  tBodyAcc-mean()-Z  tBodyAcc-std()-X  \\\n",
       "0           0.288585          -0.020294          -0.132905         -0.995279   \n",
       "1           0.278419          -0.016411          -0.123520         -0.998245   \n",
       "2           0.279653          -0.019467          -0.113462         -0.995380   \n",
       "3           0.279174          -0.026201          -0.123283         -0.996091   \n",
       "4           0.276629          -0.016570          -0.115362         -0.998139   \n",
       "\n",
       "   tBodyAcc-std()-Y  tBodyAcc-std()-Z  tBodyAcc-mad()-X  tBodyAcc-mad()-Y  \\\n",
       "0         -0.983111         -0.913526         -0.995112         -0.983185   \n",
       "1         -0.975300         -0.960322         -0.998807         -0.974914   \n",
       "2         -0.967187         -0.978944         -0.996520         -0.963668   \n",
       "3         -0.983403         -0.990675         -0.997099         -0.982750   \n",
       "4         -0.980817         -0.990482         -0.998321         -0.979672   \n",
       "\n",
       "   tBodyAcc-mad()-Z  tBodyAcc-max()-X  ...  fBodyBodyGyroJerkMag-skewness()  \\\n",
       "0         -0.923527         -0.934724  ...                        -0.298676   \n",
       "1         -0.957686         -0.943068  ...                        -0.595051   \n",
       "2         -0.977469         -0.938692  ...                        -0.390748   \n",
       "3         -0.989302         -0.938692  ...                        -0.117290   \n",
       "4         -0.990441         -0.942469  ...                        -0.351471   \n",
       "\n",
       "   fBodyBodyGyroJerkMag-kurtosis()  angle(tBodyAccMean,gravity)  \\\n",
       "0                        -0.710304                    -0.112754   \n",
       "1                        -0.861499                     0.053477   \n",
       "2                        -0.760104                    -0.118559   \n",
       "3                        -0.482845                    -0.036788   \n",
       "4                        -0.699205                     0.123320   \n",
       "\n",
       "   angle(tBodyAccJerkMean),gravityMean)  angle(tBodyGyroMean,gravityMean)  \\\n",
       "0                              0.030400                         -0.464761   \n",
       "1                             -0.007435                         -0.732626   \n",
       "2                              0.177899                          0.100699   \n",
       "3                             -0.012892                          0.640011   \n",
       "4                              0.122542                          0.693578   \n",
       "\n",
       "   angle(tBodyGyroJerkMean,gravityMean)  angle(X,gravityMean)  \\\n",
       "0                             -0.018446             -0.841247   \n",
       "1                              0.703511             -0.844788   \n",
       "2                              0.808529             -0.848933   \n",
       "3                             -0.485366             -0.848649   \n",
       "4                             -0.615971             -0.847865   \n",
       "\n",
       "   angle(Y,gravityMean)  angle(Z,gravityMean)  Activity  \n",
       "0              0.179941             -0.058627         2  \n",
       "1              0.180289             -0.054317         2  \n",
       "2              0.180637             -0.049118         2  \n",
       "3              0.181935             -0.047663         2  \n",
       "4              0.185151             -0.043892         2  \n",
       "\n",
       "[5 rows x 562 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tBodyAcc-mean()-X</th>\n",
       "      <th>tBodyAcc-mean()-Y</th>\n",
       "      <th>tBodyAcc-mean()-Z</th>\n",
       "      <th>tBodyAcc-std()-X</th>\n",
       "      <th>tBodyAcc-std()-Y</th>\n",
       "      <th>tBodyAcc-std()-Z</th>\n",
       "      <th>tBodyAcc-mad()-X</th>\n",
       "      <th>tBodyAcc-mad()-Y</th>\n",
       "      <th>tBodyAcc-mad()-Z</th>\n",
       "      <th>tBodyAcc-max()-X</th>\n",
       "      <th>...</th>\n",
       "      <th>fBodyBodyGyroJerkMag-skewness()</th>\n",
       "      <th>fBodyBodyGyroJerkMag-kurtosis()</th>\n",
       "      <th>angle(tBodyAccMean,gravity)</th>\n",
       "      <th>angle(tBodyAccJerkMean),gravityMean)</th>\n",
       "      <th>angle(tBodyGyroMean,gravityMean)</th>\n",
       "      <th>angle(tBodyGyroJerkMean,gravityMean)</th>\n",
       "      <th>angle(X,gravityMean)</th>\n",
       "      <th>angle(Y,gravityMean)</th>\n",
       "      <th>angle(Z,gravityMean)</th>\n",
       "      <th>Activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.257178</td>\n",
       "      <td>-0.023285</td>\n",
       "      <td>-0.014654</td>\n",
       "      <td>-0.938404</td>\n",
       "      <td>-0.920091</td>\n",
       "      <td>-0.667683</td>\n",
       "      <td>-0.952501</td>\n",
       "      <td>-0.925249</td>\n",
       "      <td>-0.674302</td>\n",
       "      <td>-0.894088</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.330370</td>\n",
       "      <td>-0.705974</td>\n",
       "      <td>0.006462</td>\n",
       "      <td>0.162920</td>\n",
       "      <td>-0.825886</td>\n",
       "      <td>0.271151</td>\n",
       "      <td>-0.720009</td>\n",
       "      <td>0.276801</td>\n",
       "      <td>-0.057978</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.286027</td>\n",
       "      <td>-0.013163</td>\n",
       "      <td>-0.119083</td>\n",
       "      <td>-0.975415</td>\n",
       "      <td>-0.967458</td>\n",
       "      <td>-0.944958</td>\n",
       "      <td>-0.986799</td>\n",
       "      <td>-0.968401</td>\n",
       "      <td>-0.945823</td>\n",
       "      <td>-0.894088</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121845</td>\n",
       "      <td>-0.594944</td>\n",
       "      <td>-0.083495</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>-0.434375</td>\n",
       "      <td>0.920593</td>\n",
       "      <td>-0.698091</td>\n",
       "      <td>0.281343</td>\n",
       "      <td>-0.083898</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.275485</td>\n",
       "      <td>-0.026050</td>\n",
       "      <td>-0.118152</td>\n",
       "      <td>-0.993819</td>\n",
       "      <td>-0.969926</td>\n",
       "      <td>-0.962748</td>\n",
       "      <td>-0.994403</td>\n",
       "      <td>-0.970735</td>\n",
       "      <td>-0.963483</td>\n",
       "      <td>-0.939260</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.190422</td>\n",
       "      <td>-0.640736</td>\n",
       "      <td>-0.034956</td>\n",
       "      <td>0.202302</td>\n",
       "      <td>0.064103</td>\n",
       "      <td>0.145068</td>\n",
       "      <td>-0.702771</td>\n",
       "      <td>0.280083</td>\n",
       "      <td>-0.079346</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.270298</td>\n",
       "      <td>-0.032614</td>\n",
       "      <td>-0.117520</td>\n",
       "      <td>-0.994743</td>\n",
       "      <td>-0.973268</td>\n",
       "      <td>-0.967091</td>\n",
       "      <td>-0.995274</td>\n",
       "      <td>-0.974471</td>\n",
       "      <td>-0.968897</td>\n",
       "      <td>-0.938610</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.344418</td>\n",
       "      <td>-0.736124</td>\n",
       "      <td>-0.017067</td>\n",
       "      <td>0.154438</td>\n",
       "      <td>0.340134</td>\n",
       "      <td>0.296407</td>\n",
       "      <td>-0.698954</td>\n",
       "      <td>0.284114</td>\n",
       "      <td>-0.077108</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.274833</td>\n",
       "      <td>-0.027848</td>\n",
       "      <td>-0.129527</td>\n",
       "      <td>-0.993852</td>\n",
       "      <td>-0.967445</td>\n",
       "      <td>-0.978295</td>\n",
       "      <td>-0.994111</td>\n",
       "      <td>-0.965953</td>\n",
       "      <td>-0.977346</td>\n",
       "      <td>-0.938610</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.534685</td>\n",
       "      <td>-0.846595</td>\n",
       "      <td>-0.002223</td>\n",
       "      <td>-0.040046</td>\n",
       "      <td>0.736715</td>\n",
       "      <td>-0.118545</td>\n",
       "      <td>-0.692245</td>\n",
       "      <td>0.290722</td>\n",
       "      <td>-0.073857</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 562 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tBodyAcc-mean()-X  tBodyAcc-mean()-Y  tBodyAcc-mean()-Z  tBodyAcc-std()-X  \\\n",
       "0           0.257178          -0.023285          -0.014654         -0.938404   \n",
       "1           0.286027          -0.013163          -0.119083         -0.975415   \n",
       "2           0.275485          -0.026050          -0.118152         -0.993819   \n",
       "3           0.270298          -0.032614          -0.117520         -0.994743   \n",
       "4           0.274833          -0.027848          -0.129527         -0.993852   \n",
       "\n",
       "   tBodyAcc-std()-Y  tBodyAcc-std()-Z  tBodyAcc-mad()-X  tBodyAcc-mad()-Y  \\\n",
       "0         -0.920091         -0.667683         -0.952501         -0.925249   \n",
       "1         -0.967458         -0.944958         -0.986799         -0.968401   \n",
       "2         -0.969926         -0.962748         -0.994403         -0.970735   \n",
       "3         -0.973268         -0.967091         -0.995274         -0.974471   \n",
       "4         -0.967445         -0.978295         -0.994111         -0.965953   \n",
       "\n",
       "   tBodyAcc-mad()-Z  tBodyAcc-max()-X  ...  fBodyBodyGyroJerkMag-skewness()  \\\n",
       "0         -0.674302         -0.894088  ...                        -0.330370   \n",
       "1         -0.945823         -0.894088  ...                        -0.121845   \n",
       "2         -0.963483         -0.939260  ...                        -0.190422   \n",
       "3         -0.968897         -0.938610  ...                        -0.344418   \n",
       "4         -0.977346         -0.938610  ...                        -0.534685   \n",
       "\n",
       "   fBodyBodyGyroJerkMag-kurtosis()  angle(tBodyAccMean,gravity)  \\\n",
       "0                        -0.705974                     0.006462   \n",
       "1                        -0.594944                    -0.083495   \n",
       "2                        -0.640736                    -0.034956   \n",
       "3                        -0.736124                    -0.017067   \n",
       "4                        -0.846595                    -0.002223   \n",
       "\n",
       "   angle(tBodyAccJerkMean),gravityMean)  angle(tBodyGyroMean,gravityMean)  \\\n",
       "0                              0.162920                         -0.825886   \n",
       "1                              0.017500                         -0.434375   \n",
       "2                              0.202302                          0.064103   \n",
       "3                              0.154438                          0.340134   \n",
       "4                             -0.040046                          0.736715   \n",
       "\n",
       "   angle(tBodyGyroJerkMean,gravityMean)  angle(X,gravityMean)  \\\n",
       "0                              0.271151             -0.720009   \n",
       "1                              0.920593             -0.698091   \n",
       "2                              0.145068             -0.702771   \n",
       "3                              0.296407             -0.698954   \n",
       "4                             -0.118545             -0.692245   \n",
       "\n",
       "   angle(Y,gravityMean)  angle(Z,gravityMean)  Activity  \n",
       "0              0.276801             -0.057978         2  \n",
       "1              0.281343             -0.083898         2  \n",
       "2              0.280083             -0.079346         2  \n",
       "3              0.284114             -0.077108         2  \n",
       "4              0.290722             -0.073857         2  \n",
       "\n",
       "[5 rows x 562 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.iloc[:, :-1].to_numpy(dtype=np.float32)\n",
    "y_train = train.iloc[:, -1].to_numpy(dtype=np.float32)\n",
    "\n",
    "x_test = test.iloc[:, :-1].to_numpy(dtype=np.float32)\n",
    "y_test = test.iloc[:, -1].to_numpy(dtype=np.float32)\n",
    "\n",
    "num_classes = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[:, :, np.newaxis]\n",
    "x_test = x_test[:, :, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args.batch_size =  8 , x_train.shape =  (7352, 561, 1) , x_test.shape =  (2947, 561, 1)\n"
     ]
    }
   ],
   "source": [
    "args.num_classes = num_classes\n",
    "args.seq_len = x_train.shape[1]\n",
    "args.input_size = x_train.shape[2]\n",
    "\n",
    "args.enc_in = x_train.shape[2]\n",
    "\n",
    "while x_train.shape[0] * 0.6 < args.batch_size:\n",
    "    args.batch_size = args.batch_size // 2\n",
    "\n",
    "print(\"args.batch_size = \", args.batch_size, \", x_train.shape = \", x_train.shape, \", x_test.shape = \", x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Inception_Block_V1(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_kernels=6, init_weight=True):\n",
    "        super(Inception_Block_V1, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.num_kernels = num_kernels\n",
    "        kernels = []\n",
    "        for i in range(self.num_kernels):\n",
    "            kernels.append(nn.Conv2d(in_channels, out_channels, kernel_size=2 * i + 1, padding=i))\n",
    "        self.kernels = nn.ModuleList(kernels)\n",
    "        if init_weight:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res_list = []\n",
    "        for i in range(self.num_kernels):\n",
    "            res_list.append(self.kernels[i](x))\n",
    "        res = torch.stack(res_list, dim=-1).mean(-1)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=25000):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)]\n",
    "\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        padding = 1 if torch.__version__ >= '1.5.0' else 2\n",
    "        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model,\n",
    "                                   kernel_size=3, padding=padding, padding_mode='circular', bias=False)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FixedEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(FixedEmbedding, self).__init__()\n",
    "\n",
    "        w = torch.zeros(c_in, d_model).float()\n",
    "        w.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, c_in).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        w[:, 0::2] = torch.sin(position * div_term)\n",
    "        w[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.emb = nn.Embedding(c_in, d_model)\n",
    "        self.emb.weight = nn.Parameter(w, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.emb(x).detach()\n",
    "\n",
    "\n",
    "class TemporalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='fixed', freq='h'):\n",
    "        super(TemporalEmbedding, self).__init__()\n",
    "\n",
    "        minute_size = 4\n",
    "        hour_size = 24\n",
    "        weekday_size = 7\n",
    "        day_size = 32\n",
    "        month_size = 13\n",
    "\n",
    "        Embed = FixedEmbedding if embed_type == 'fixed' else nn.Embedding\n",
    "        if freq == 't':\n",
    "            self.minute_embed = Embed(minute_size, d_model)\n",
    "        self.hour_embed = Embed(hour_size, d_model)\n",
    "        self.weekday_embed = Embed(weekday_size, d_model)\n",
    "        self.day_embed = Embed(day_size, d_model)\n",
    "        self.month_embed = Embed(month_size, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.long()\n",
    "        minute_x = self.minute_embed(x[:, :, 4]) if hasattr(\n",
    "            self, 'minute_embed') else 0.\n",
    "        hour_x = self.hour_embed(x[:, :, 3])\n",
    "        weekday_x = self.weekday_embed(x[:, :, 2])\n",
    "        day_x = self.day_embed(x[:, :, 1])\n",
    "        month_x = self.month_embed(x[:, :, 0])\n",
    "\n",
    "        return hour_x + weekday_x + day_x + month_x + minute_x\n",
    "\n",
    "\n",
    "class TimeFeatureEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='timeF', freq='h'):\n",
    "        super(TimeFeatureEmbedding, self).__init__()\n",
    "\n",
    "        freq_map = {'h': 4, 't': 5, 's': 6,\n",
    "                    'm': 1, 'a': 1, 'w': 2, 'd': 3, 'b': 3}\n",
    "        d_inp = freq_map[freq]\n",
    "        self.embed = nn.Linear(d_inp, d_model, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)\n",
    "\n",
    "\n",
    "class DataEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
    "        super(DataEmbedding, self).__init__()\n",
    "\n",
    "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
    "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
    "        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n",
    "                                                    freq=freq) if embed_type != 'timeF' else TimeFeatureEmbedding(\n",
    "            d_model=d_model, embed_type=embed_type, freq=freq)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, x_mark):\n",
    "        if x_mark is None:\n",
    "            x = self.value_embedding(x) + self.position_embedding(x)\n",
    "        else:\n",
    "            x = self.value_embedding(\n",
    "                x) + self.temporal_embedding(x_mark) + self.position_embedding(x)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.fft\n",
    "\n",
    "\n",
    "def FFT_for_Period(x, k=2):\n",
    "    # [B, T, C]\n",
    "    xf = torch.fft.rfft(x, dim=1)\n",
    "    # find period by amplitudes\n",
    "    frequency_list = abs(xf).mean(0).mean(-1)\n",
    "    frequency_list[0] = 0\n",
    "    _, top_list = torch.topk(frequency_list, k)\n",
    "    top_list = top_list.detach().cpu().numpy()\n",
    "    period = x.shape[1] // top_list\n",
    "\n",
    "    # print(\"period.shape = \", period.shape, top_list.shape, top_list, period)\n",
    "    return period, abs(xf).mean(-1)[:, top_list]\n",
    "\n",
    "\n",
    "class TimesBlock(nn.Module):\n",
    "    def __init__(self, configs):\n",
    "        super(TimesBlock, self).__init__()\n",
    "        self.seq_len = configs.seq_len\n",
    "        self.pred_len = configs.pred_len\n",
    "        self.k = configs.top_k\n",
    "        # parameter-efficient design\n",
    "        self.conv = nn.Sequential(\n",
    "            Inception_Block_V1(configs.d_model, configs.d_ff,\n",
    "                               num_kernels=configs.num_kernels),\n",
    "            nn.GELU(),\n",
    "            Inception_Block_V1(configs.d_ff, configs.d_model,\n",
    "                               num_kernels=configs.num_kernels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(\"Input shape:\", x.shape)\n",
    "        B, T, N = x.size()\n",
    "        period_list, period_weight = FFT_for_Period(x, self.k)\n",
    "\n",
    "        # print(\"period_list shape = \", period_list.shape, period_list)\n",
    "\n",
    "        # print(\"period_list period_weight shape:\", period_list.shape, period_weight.shape, self.k, self.seq_len, self.pred_len)\n",
    "\n",
    "        res = []\n",
    "        for i in range(self.k):\n",
    "            period = period_list[i]\n",
    "            # padding\n",
    "            if (self.seq_len + self.pred_len) % period != 0:\n",
    "                length = (\n",
    "                                 ((self.seq_len + self.pred_len) // period) + 1) * period\n",
    "\n",
    "                # print(\"length = \", length, self.seq_len, self.pred_len, period)\n",
    "                padding = torch.zeros([x.shape[0], (length - (self.seq_len + self.pred_len)), x.shape[2]]).to(x.device)\n",
    "\n",
    "                # print(\"padding x shape = \", padding.shape, x.shape)\n",
    "                out = torch.cat([x, padding], dim=1)\n",
    "                # print(\"padding out shape = \", out.shape)\n",
    "            else:\n",
    "                length = (self.seq_len + self.pred_len)\n",
    "                out = x\n",
    "\n",
    "            # print(\"out.shape = \", out.shape, length, period, length // period, N )\n",
    "            # reshape\n",
    "            out = out.reshape(B, length // period, period,\n",
    "                              N).permute(0, 3, 1, 2).contiguous()\n",
    "            # 2D conv: from 1d Variation to 2d Variation\n",
    "            out = self.conv(out)\n",
    "            # reshape back\n",
    "            out = out.permute(0, 2, 3, 1).reshape(B, -1, N)\n",
    "            res.append(out[:, :(self.seq_len + self.pred_len), :])\n",
    "        res = torch.stack(res, dim=-1)\n",
    "        # adaptive aggregation\n",
    "        period_weight = F.softmax(period_weight, dim=1)\n",
    "        period_weight = period_weight.unsqueeze(\n",
    "            1).unsqueeze(1).repeat(1, T, N, 1)\n",
    "        res = torch.sum(res * period_weight, -1)\n",
    "        # residual connection\n",
    "        res = res + x\n",
    "        return res\n",
    "\n",
    "\n",
    "class TimesNetModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Paper link: https://openreview.net/pdf?id=ju_Uqw384Oq\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, configs):\n",
    "        super(TimesNetModel, self).__init__()\n",
    "        self.configs = configs\n",
    "        self.model = nn.ModuleList([TimesBlock(configs)\n",
    "                                    for _ in range(configs.e_layers)])\n",
    "        self.enc_embedding = DataEmbedding(configs.enc_in, configs.d_model, configs.embed, configs.freq,\n",
    "                                           configs.dropout)\n",
    "        self.layer = configs.e_layers\n",
    "        self.layer_norm = nn.LayerNorm(configs.d_model)\n",
    "        self.act = F.gelu\n",
    "        self.dropout = nn.Dropout(configs.dropout)\n",
    "        self.projection = nn.Linear(\n",
    "            configs.d_model * configs.seq_len, configs.num_classes)\n",
    "\n",
    "    def classification(self, x_enc, x_mark_enc):\n",
    "        # embedding\n",
    "        enc_out = self.enc_embedding(x_enc, None)  # [B,T,C]\n",
    "        # TimesNet\n",
    "        for i in range(self.layer):\n",
    "            enc_out = self.layer_norm(self.model[i](enc_out))\n",
    "\n",
    "        # Output\n",
    "        # the output transformer encoder/decoder embeddings don't include non-linearity\n",
    "        output = self.act(enc_out)\n",
    "        output = self.dropout(output)\n",
    "        # zero-out padding embeddings\n",
    "        output = output * x_mark_enc.unsqueeze(-1)\n",
    "        # (batch_size, seq_length * d_model)\n",
    "        output = output.reshape(output.shape[0], -1)\n",
    "        output = self.projection(output)  # (batch_size, num_classes)\n",
    "        return output\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc, x_dec=None, x_mark_dec=None, mask=None):\n",
    "        dec_out = self.classification(x_enc, x_mark_enc)\n",
    "        return dec_out  # [B, N]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimesNetModel(\n",
       "  (model): ModuleList(\n",
       "    (0-2): 3 x TimesBlock(\n",
       "      (conv): Sequential(\n",
       "        (0): Inception_Block_V1(\n",
       "          (kernels): ModuleList(\n",
       "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "            (3): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "            (4): Conv2d(64, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4))\n",
       "            (5): Conv2d(64, 64, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5))\n",
       "          )\n",
       "        )\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Inception_Block_V1(\n",
       "          (kernels): ModuleList(\n",
       "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "            (3): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "            (4): Conv2d(64, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4))\n",
       "            (5): Conv2d(64, 64, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (enc_embedding): DataEmbedding(\n",
       "    (value_embedding): TokenEmbedding(\n",
       "      (tokenConv): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n",
       "    )\n",
       "    (position_embedding): PositionalEmbedding()\n",
       "    (temporal_embedding): TimeFeatureEmbedding(\n",
       "      (embed): Linear(in_features=4, out_features=64, bias=False)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (projection): Linear(in_features=35904, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TimesNetModel(configs=args)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.normalize_way == 'single':\n",
    "    x_train = normalize(x_train)\n",
    "    x_test = normalize(x_test)\n",
    "\n",
    "train_set = HARDataset(torch.from_numpy(x_train).type(torch.FloatTensor).to(device).permute(0,2,1),\n",
    "                        torch.from_numpy(y_train).type(torch.FloatTensor).to(device).to(torch.int64))\n",
    "test_set = HARDataset(torch.from_numpy(x_test).type(torch.FloatTensor).to(device).permute(0,2,1),\n",
    "                        torch.from_numpy(y_test).type(torch.FloatTensor).to(device).to(torch.int64))\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=args.batch_size, num_workers=0, drop_last=True, collate_fn=lambda x: collate_fn(x, device, max_len=args.seq_len))\n",
    "test_loader = DataLoader(test_set, batch_size=args.batch_size, num_workers=0, collate_fn=lambda x: collate_fn(x, device, max_len=args.seq_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "model_init_state = model.state_dict()\n",
    "\n",
    "losses = []\n",
    "test_accuracies = []\n",
    "train_time = 0.0\n",
    "end_val_epochs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15: 100%|██████████| 919/919 [02:03<00:00,  7.45batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.9846074786114501 , Train accuracy : 0.7057943344116211\n",
      "Learning rate after epoch 0: 0.0001\n",
      "Epoch 2/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15: 100%|██████████| 919/919 [02:02<00:00,  7.51batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.25057933886027084 , Train accuracy : 0.8994830846786499\n",
      "Learning rate after epoch 1: 0.0001\n",
      "Epoch 3/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15: 100%|██████████| 919/919 [02:01<00:00,  7.56batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.18640059339918777 , Train accuracy : 0.928726851940155\n",
      "Learning rate after epoch 2: 0.0001\n",
      "Epoch 4/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15: 100%|██████████| 919/919 [02:04<00:00,  7.38batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.14358067597732294 , Train accuracy : 0.9461370706558228\n",
      "Learning rate after epoch 3: 0.0001\n",
      "Epoch 5/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15: 100%|██████████| 919/919 [02:01<00:00,  7.54batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.11265489719699853 , Train accuracy : 0.9575625658035278\n",
      "Learning rate after epoch 4: 0.0001\n",
      "Epoch 6/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15: 100%|██████████| 919/919 [02:02<00:00,  7.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0883942835551485 , Train accuracy : 0.9653155207633972\n",
      "Learning rate after epoch 5: 0.0001\n",
      "Epoch 7/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15: 100%|██████████| 919/919 [02:00<00:00,  7.61batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.07297589241011554 , Train accuracy : 0.9710282683372498\n",
      "Learning rate after epoch 6: 0.0001\n",
      "Epoch 8/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15: 100%|██████████| 919/919 [01:58<00:00,  7.73batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.054991808272898804 , Train accuracy : 0.9778291583061218\n",
      "Learning rate after epoch 7: 0.0001\n",
      "Epoch 9/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/15: 100%|██████████| 919/919 [01:57<00:00,  7.85batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.05224139357904802 , Train accuracy : 0.9790533185005188\n",
      "Learning rate after epoch 8: 0.0001\n",
      "Epoch 10/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/15: 100%|██████████| 919/919 [01:58<00:00,  7.76batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.03704871390649645 , Train accuracy : 0.9870783090591431\n",
      "Learning rate after epoch 9: 0.0001\n",
      "Epoch 11/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/15: 100%|██████████| 919/919 [01:59<00:00,  7.68batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.03150289127499051 , Train accuracy : 0.9877583980560303\n",
      "Learning rate after epoch 10: 0.0001\n",
      "Epoch 12/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/15: 100%|██████████| 919/919 [01:59<00:00,  7.71batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.06357702925642289 , Train accuracy : 0.979733407497406\n",
      "Learning rate after epoch 11: 0.0001\n",
      "Epoch 13/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/15: 100%|██████████| 919/919 [02:00<00:00,  7.61batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.048661829652761536 , Train accuracy : 0.981501579284668\n",
      "Learning rate after epoch 12: 0.0001\n",
      "Epoch 14/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/15: 100%|██████████| 919/919 [02:02<00:00,  7.48batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.05766991879470971 , Train accuracy : 0.9793253540992737\n",
      "Learning rate after epoch 13: 1e-05\n",
      "Epoch 15/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/15: 100%|██████████| 919/919 [02:02<00:00,  7.50batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0350611071659892 , Train accuracy : 0.9885745048522949\n",
      "Learning rate after epoch 14: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "model.load_state_dict(model_init_state)\n",
    "# Define optimizer and scheduler\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2)\n",
    "\n",
    "train_loss = []\n",
    "train_accuracy = []\n",
    "num_steps = args.epoch // args.batch_size\n",
    "\n",
    "last_loss = float('inf')\n",
    "stop_count = 0\n",
    "increase_count = 0\n",
    "\n",
    "num_steps = train_set.__len__() // args.batch_size\n",
    "\n",
    "min_val_loss = float('inf')\n",
    "test_accuracy = 0\n",
    "end_val_epoch = 0\n",
    "args.epoch = 30\n",
    "\n",
    "for epoch in range(args.epoch):\n",
    "    print('Epoch {}/{}'.format(epoch + 1, args.epoch))\n",
    "\n",
    "    epoch_train_loss = 0\n",
    "    epoch_train_acc = 0\n",
    "    num_iterations = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    with tqdm(total=len(train_loader), desc=f\"Epoch {epoch+1}/{args.epoch}\", unit=\"batch\") as pbar:\n",
    "        for x, y, padding_x_mask in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            pred = model(x, padding_x_mask)\n",
    "            step_loss = loss(pred, y)\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            step_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate training loss and accuracy\n",
    "            epoch_train_loss += step_loss.item()\n",
    "            epoch_train_acc += torch.sum(torch.argmax(pred.data, axis=1) == y) / len(y)\n",
    "\n",
    "            num_iterations += 1\n",
    "            pbar.update(1)  # Update progress bar for each batch\n",
    "\n",
    "    # Average train loss and accuracy over all steps\n",
    "    epoch_train_loss /= num_steps\n",
    "    epoch_train_acc /= num_steps\n",
    "\n",
    "    # Adjust learning rate based on training loss\n",
    "    scheduler.step(epoch_train_loss)\n",
    "\n",
    "    print(\"Train loss: {} , Train accuracy : {}\".format(epoch_train_loss, epoch_train_acc))\n",
    "    print(\"Learning rate after epoch {}: {}\".format(epoch, optimizer.param_groups[0]['lr']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1557, Test Accuracy: 0.9602, Test F1 Score: 0.9613 Test Precision: 0.9638, Test Recall: 0.9602, Test AUROC: 0.9978\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchmetrics\n",
    "from torchmetrics import Accuracy, F1Score, Precision, Recall, ConfusionMatrix, AUROC\n",
    "from torchmetrics.classification import MulticlassAccuracy, MulticlassF1Score, MulticlassPrecision, MulticlassRecall, MulticlassConfusionMatrix, MulticlassROC\n",
    "\n",
    "# Initialize metrics\n",
    "accuracy_metric = MulticlassAccuracy(num_classes=args.num_classes).to(device)\n",
    "f1_score_metric = MulticlassF1Score(average='macro', num_classes=args.num_classes).to(device)\n",
    "precision_metric = MulticlassPrecision(average='macro', num_classes=args.num_classes).to(device)\n",
    "recall_metric = MulticlassRecall(average='macro', num_classes=args.num_classes).to(device)\n",
    "confusion_matrix_metric = MulticlassConfusionMatrix(num_classes=args.num_classes).to(device)\n",
    "roc_metric = MulticlassROC(num_classes=args.num_classes).to(device)\n",
    "\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "test_loss = 0\n",
    "loss_func = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "with torch.no_grad():  # No need to compute gradients for evaluation\n",
    "    for x, y, padding_x_mask in test_loader:\n",
    "        # Move inputs and targets to the correct device\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        # Forward pass: compute predicted outputs by passing inputs to the model\n",
    "        pred = model(x, padding_x_mask)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = loss_func(pred, y)\n",
    "        test_loss += loss.item()  # Accumulate loss\n",
    "\n",
    "        # Update metrics\n",
    "        accuracy_metric.update(pred, y)\n",
    "        f1_score_metric.update(pred, y)\n",
    "        precision_metric.update(pred, y)\n",
    "        recall_metric.update(pred, y)\n",
    "        confusion_matrix_metric.update(pred, y)\n",
    "        roc_metric.update(pred, y)\n",
    "\n",
    "# Compute average test loss and finalize metrics\n",
    "test_loss /= len(test_loader)\n",
    "test_accuracy = accuracy_metric.compute().item()\n",
    "test_f1_score = f1_score_metric.compute().item()\n",
    "test_precision = precision_metric.compute().item()\n",
    "test_recall = recall_metric.compute().item()\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}, Test F1 Score: {test_f1_score:.4f} Test Precision: {test_precision:.4f}, Test Recall: {test_recall:.4f}, Test AUROC: {test_auroc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "confusion_matrix = confusion_matrix_metric.compute().cpu().numpy()\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_, ax_ = roc_metric.plot(score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
