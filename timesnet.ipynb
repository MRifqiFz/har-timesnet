{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data File\n",
    "\n",
    "INPUT_SIGNAL_TYPES = [\n",
    "    \"body_acc_x_\",\n",
    "    \"body_acc_y_\",\n",
    "    \"body_acc_z_\",\n",
    "    \"body_gyro_x_\",\n",
    "    \"body_gyro_y_\",\n",
    "    \"body_gyro_z_\",\n",
    "    \"total_acc_x_\",\n",
    "    \"total_acc_y_\",\n",
    "    \"total_acc_z_\"\n",
    "]\n",
    "\n",
    "# Output classes to learn how to classify\n",
    "LABELS = [\n",
    "    \"WALKING\",\n",
    "    \"WALKING_UPSTAIRS\",\n",
    "    \"WALKING_DOWNSTAIRS\",\n",
    "    \"SITTING\",\n",
    "    \"STANDING\",\n",
    "    \"LAYING\"\n",
    "]\n",
    "\n",
    "TRAIN = \"train/\"\n",
    "TEST = \"test/\"\n",
    "DATASET_PATH = \"Dataset/UCI HAR Dataset/\"\n",
    "\n",
    "X_train_signals_paths = [\n",
    "    DATASET_PATH + TRAIN + \"Inertial Signals/\" + signal + \"train.txt\" for signal in INPUT_SIGNAL_TYPES\n",
    "]\n",
    "X_test_signals_paths = [\n",
    "    DATASET_PATH + TEST + \"Inertial Signals/\" + signal + \"test.txt\" for signal in INPUT_SIGNAL_TYPES\n",
    "]\n",
    "\n",
    "y_train_path = DATASET_PATH + TRAIN + \"y_train.txt\"\n",
    "y_test_path = DATASET_PATH + TEST + \"y_test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_X(X_signals_paths):\n",
    "    X_signals = []\n",
    "    for signal_type_path in X_signals_paths:\n",
    "        # Load the dataset using np.loadtxt and specify dtype and delimiter\n",
    "        data = np.loadtxt(signal_type_path, dtype=np.float32)\n",
    "        X_signals.append(data)\n",
    "\n",
    "    # Stack and transpose to match the original output format\n",
    "    return np.transpose(np.array(X_signals), (1, 2, 0))\n",
    "\n",
    "def load_y(y_path):\n",
    "    # Load the labels using np.loadtxt and specify dtype\n",
    "    y_ = np.loadtxt(y_path, dtype=np.int32)\n",
    "    y_ = np.reshape(y_, (-1, 1))\n",
    "\n",
    "    # Subtract 1 from each output class for 0-based indexing\n",
    "    return y_ - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = load_X(X_train_signals_paths)\n",
    "X_test = load_X(X_test_signals_paths)\n",
    "\n",
    "y_train = load_y(y_train_path)\n",
    "y_test = load_y(y_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some useful info to get an insight on dataset's shape and normalisation:\n",
      "(X shape, y shape, every X's mean, every X's standard deviation)\n",
      "(2947, 128, 9) (2947, 1) 0.09913992 0.39567086\n",
      "The dataset is therefore properly normalised, as expected, but not yet one-hot encoded.\n"
     ]
    }
   ],
   "source": [
    "training_data_count = len(X_train)  # 7352 training series (with 50% overlap between each serie)\n",
    "test_data_count = len(X_test)  # 2947 testing series\n",
    "n_steps = len(X_train[0])  # 128 timesteps per series\n",
    "n_input = len(X_train[0][0])  # 9 input parameters per timestep\n",
    "\n",
    "# Some debugging info\n",
    "\n",
    "print(\"Some useful info to get an insight on dataset's shape and normalisation:\")\n",
    "print(\"(X shape, y shape, every X's mean, every X's standard deviation)\")\n",
    "print(X_test.shape, y_test.shape, np.mean(X_test), np.std(X_test))\n",
    "print(\"The dataset is therefore properly normalised, as expected, but not yet one-hot encoded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Inception_Block_V1(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_kernels=6, init_weight=True):\n",
    "        super(Inception_Block_V1, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.num_kernels = num_kernels\n",
    "        kernels = []\n",
    "        for i in range(self.num_kernels):\n",
    "            kernels.append(nn.Conv2d(in_channels, out_channels, kernel_size=2 * i + 1, padding=i))\n",
    "        self.kernels = nn.ModuleList(kernels)\n",
    "        if init_weight:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res_list = []\n",
    "        for i in range(self.num_kernels):\n",
    "            res_list.append(self.kernels[i](x))\n",
    "        res = torch.stack(res_list, dim=-1).mean(-1)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=25000):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)]\n",
    "\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        padding = 1 if torch.__version__ >= '1.5.0' else 2\n",
    "        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model,\n",
    "                                   kernel_size=3, padding=padding, padding_mode='circular', bias=False)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FixedEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(FixedEmbedding, self).__init__()\n",
    "\n",
    "        w = torch.zeros(c_in, d_model).float()\n",
    "        w.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, c_in).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        w[:, 0::2] = torch.sin(position * div_term)\n",
    "        w[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.emb = nn.Embedding(c_in, d_model)\n",
    "        self.emb.weight = nn.Parameter(w, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.emb(x).detach()\n",
    "\n",
    "\n",
    "class TemporalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='fixed', freq='h'):\n",
    "        super(TemporalEmbedding, self).__init__()\n",
    "\n",
    "        minute_size = 4\n",
    "        hour_size = 24\n",
    "        weekday_size = 7\n",
    "        day_size = 32\n",
    "        month_size = 13\n",
    "\n",
    "        Embed = FixedEmbedding if embed_type == 'fixed' else nn.Embedding\n",
    "        if freq == 't':\n",
    "            self.minute_embed = Embed(minute_size, d_model)\n",
    "        self.hour_embed = Embed(hour_size, d_model)\n",
    "        self.weekday_embed = Embed(weekday_size, d_model)\n",
    "        self.day_embed = Embed(day_size, d_model)\n",
    "        self.month_embed = Embed(month_size, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.long()\n",
    "        minute_x = self.minute_embed(x[:, :, 4]) if hasattr(\n",
    "            self, 'minute_embed') else 0.\n",
    "        hour_x = self.hour_embed(x[:, :, 3])\n",
    "        weekday_x = self.weekday_embed(x[:, :, 2])\n",
    "        day_x = self.day_embed(x[:, :, 1])\n",
    "        month_x = self.month_embed(x[:, :, 0])\n",
    "\n",
    "        return hour_x + weekday_x + day_x + month_x + minute_x\n",
    "\n",
    "\n",
    "class TimeFeatureEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='timeF', freq='h'):\n",
    "        super(TimeFeatureEmbedding, self).__init__()\n",
    "\n",
    "        freq_map = {'h': 4, 't': 5, 's': 6,\n",
    "                    'm': 1, 'a': 1, 'w': 2, 'd': 3, 'b': 3}\n",
    "        d_inp = freq_map[freq]\n",
    "        self.embed = nn.Linear(d_inp, d_model, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)\n",
    "\n",
    "\n",
    "class DataEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
    "        super(DataEmbedding, self).__init__()\n",
    "\n",
    "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
    "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
    "        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n",
    "                                                    freq=freq) if embed_type != 'timeF' else TimeFeatureEmbedding(\n",
    "            d_model=d_model, embed_type=embed_type, freq=freq)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, x_mark):\n",
    "        if x_mark is None:\n",
    "            x = self.value_embedding(x) + self.position_embedding(x)\n",
    "        else:\n",
    "            x = self.value_embedding(\n",
    "                x) + self.temporal_embedding(x_mark) + self.position_embedding(x)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.fft\n",
    "\n",
    "\n",
    "def FFT_for_Period(x, k=2):\n",
    "    # [B, T, C]\n",
    "    xf = torch.fft.rfft(x, dim=1)\n",
    "    # find period by amplitudes\n",
    "    frequency_list = abs(xf).mean(0).mean(-1)\n",
    "    frequency_list[0] = 0\n",
    "    _, top_list = torch.topk(frequency_list, k)\n",
    "    top_list = top_list.detach().cpu().numpy()\n",
    "    period = x.shape[1] // top_list\n",
    "\n",
    "    # print(\"period.shape = \", period.shape, top_list.shape, top_list, period)\n",
    "    return period, abs(xf).mean(-1)[:, top_list]\n",
    "\n",
    "\n",
    "class TimesBlock(nn.Module):\n",
    "    def __init__(self, configs):\n",
    "        super(TimesBlock, self).__init__()\n",
    "        self.seq_len = configs.seq_len\n",
    "        self.pred_len = configs.pred_len\n",
    "        self.k = configs.top_k\n",
    "        # parameter-efficient design\n",
    "        self.conv = nn.Sequential(\n",
    "            Inception_Block_V1(configs.d_model, configs.d_ff,\n",
    "                               num_kernels=configs.num_kernels),\n",
    "            nn.GELU(),\n",
    "            Inception_Block_V1(configs.d_ff, configs.d_model,\n",
    "                               num_kernels=configs.num_kernels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(\"Input shape:\", x.shape)\n",
    "        B, T, N = x.size()\n",
    "        period_list, period_weight = FFT_for_Period(x, self.k)\n",
    "\n",
    "        # print(\"period_list shape = \", period_list.shape, period_list)\n",
    "\n",
    "        # print(\"period_list period_weight shape:\", period_list.shape, period_weight.shape, self.k, self.seq_len, self.pred_len)\n",
    "\n",
    "        res = []\n",
    "        for i in range(self.k):\n",
    "            period = period_list[i]\n",
    "            # padding\n",
    "            if (self.seq_len + self.pred_len) % period != 0:\n",
    "                length = (\n",
    "                                 ((self.seq_len + self.pred_len) // period) + 1) * period\n",
    "\n",
    "                # print(\"length = \", length, self.seq_len, self.pred_len, period)\n",
    "                padding = torch.zeros([x.shape[0], (length - (self.seq_len + self.pred_len)), x.shape[2]]).to(x.device)\n",
    "\n",
    "                # print(\"padding x shape = \", padding.shape, x.shape)\n",
    "                out = torch.cat([x, padding], dim=1)\n",
    "                # print(\"padding out shape = \", out.shape)\n",
    "            else:\n",
    "                length = (self.seq_len + self.pred_len)\n",
    "                out = x\n",
    "\n",
    "            # print(\"out.shape = \", out.shape, length, period, length // period, N )\n",
    "            # reshape\n",
    "            out = out.reshape(B, length // period, period,\n",
    "                              N).permute(0, 3, 1, 2).contiguous()\n",
    "            # 2D conv: from 1d Variation to 2d Variation\n",
    "            out = self.conv(out)\n",
    "            # reshape back\n",
    "            out = out.permute(0, 2, 3, 1).reshape(B, -1, N)\n",
    "            res.append(out[:, :(self.seq_len + self.pred_len), :])\n",
    "        res = torch.stack(res, dim=-1)\n",
    "        # adaptive aggregation\n",
    "        period_weight = F.softmax(period_weight, dim=1)\n",
    "        period_weight = period_weight.unsqueeze(\n",
    "            1).unsqueeze(1).repeat(1, T, N, 1)\n",
    "        res = torch.sum(res * period_weight, -1)\n",
    "        # residual connection\n",
    "        res = res + x\n",
    "        return res\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \"\"\"\n",
    "    Paper link: https://openreview.net/pdf?id=ju_Uqw384Oq\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, configs):\n",
    "        super(Model, self).__init__()\n",
    "        self.configs = configs\n",
    "        self.task_name = configs.task_name\n",
    "        self.seq_len = configs.seq_len\n",
    "        self.label_len = configs.label_len\n",
    "        self.pred_len = configs.pred_len\n",
    "        self.model = nn.ModuleList([TimesBlock(configs)\n",
    "                                    for _ in range(configs.e_layers)])\n",
    "        self.enc_embedding = DataEmbedding(configs.enc_in, configs.d_model, configs.embed, configs.freq,\n",
    "                                           configs.dropout)\n",
    "        self.layer = configs.e_layers\n",
    "        self.layer_norm = nn.LayerNorm(configs.d_model)\n",
    "        self.act = F.gelu\n",
    "        self.dropout = nn.Dropout(configs.dropout)\n",
    "        self.projection = nn.Linear(\n",
    "            configs.d_model * configs.seq_len, configs.num_classes)\n",
    "\n",
    "    def classification(self, x_enc, x_mark_enc):\n",
    "        # embedding\n",
    "        enc_out = self.enc_embedding(x_enc, None)  # [B,T,C]\n",
    "        # TimesNet\n",
    "        for i in range(self.layer):\n",
    "            enc_out = self.layer_norm(self.model[i](enc_out))\n",
    "\n",
    "        # Output\n",
    "        # the output transformer encoder/decoder embeddings don't include non-linearity\n",
    "        output = self.act(enc_out)\n",
    "        output = self.dropout(output)\n",
    "        # zero-out padding embeddings\n",
    "        output = output * x_mark_enc.unsqueeze(-1)\n",
    "        # (batch_size, seq_length * d_model)\n",
    "        output = output.reshape(output.shape[0], -1)\n",
    "        output = self.projection(output)  # (batch_size, num_classes)\n",
    "        return output\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc, x_dec=None, x_mark_dec=None, mask=None):\n",
    "        dec_out = self.classification(x_enc, x_mark_enc)\n",
    "        return dec_out  # [B, N]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "curPath = os.path.abspath(os.path.dirname(__file__))\n",
    "rootPath = os.path.split(curPath)[0]\n",
    "sys.path.append(rootPath)\n",
    "\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from gpt4ts.gpt4ts_utils import load_UEA, normalize_uea_set, UEADataset, save_cls_new_result, set_seed, fill_nan_value, get_all_datasets, build_loss\n",
    "\n",
    "\n",
    "def collate_fn(data, device, max_len=None):\n",
    "    \"\"\"Build mini-batch tensors from a list of (X, mask) tuples. Mask input. Create\n",
    "    Args:\n",
    "        data: len(batch_size) list of tuples (X, y).\n",
    "            - X: torch tensor of shape (seq_length, feat_dim); variable seq_length.\n",
    "            - y: torch tensor of shape (num_labels,) : class indices or numerical targets\n",
    "                (for classification or regression, respectively). num_labels > 1 for multi-task models\n",
    "        max_len: global fixed sequence length. Used for architectures requiring fixed length input,\n",
    "            where the batch length cannot vary dynamically. Longer sequences are clipped, shorter are padded with 0s\n",
    "    Returns:\n",
    "        X: (batch_size, padded_length, feat_dim) torch tensor of masked features (input)\n",
    "        targets: (batch_size, padded_length, feat_dim) torch tensor of unmasked features (output)\n",
    "        target_masks: (batch_size, padded_length, feat_dim) boolean torch tensor\n",
    "            0 indicates masked values to be predicted, 1 indicates unaffected/\"active\" feature values\n",
    "        padding_masks: (batch_size, padded_length) boolean tensor, 1 means keep vector at this position, 0 means padding\n",
    "    \"\"\"\n",
    "\n",
    "    batch_size = len(data)\n",
    "    features, labels = zip(*data)\n",
    "\n",
    "    # Stack and pad features and masks (convert 2D to 3D tensors, i.e. add batch dimension)\n",
    "    lengths = [X.shape[0] for X in features]  # original sequence length for each time series\n",
    "    if max_len is None:\n",
    "        max_len = max(lengths)\n",
    "\n",
    "    X = torch.zeros(batch_size, max_len, features[0].shape[-1])  # (batch_size, padded_length, feat_dim)\n",
    "    for i in range(batch_size):\n",
    "        end = min(lengths[i], max_len)\n",
    "        X[i, :end, :] = features[i][:end, :]\n",
    "\n",
    "    targets = torch.stack(labels, dim=0)  # (batch_size, num_labels)\n",
    "\n",
    "    padding_masks = padding_mask(torch.tensor(lengths, dtype=torch.int16),\n",
    "                                 max_len=max_len)  # (batch_size, padded_length) boolean tensor, \"1\" means keep\n",
    "\n",
    "    return X.to(device), targets.to(device), padding_masks.to(device)\n",
    "\n",
    "\n",
    "def padding_mask(lengths, max_len=None):\n",
    "    \"\"\"\n",
    "    Used to mask padded positions: creates a (batch_size, max_len) boolean mask from a tensor of sequence lengths,\n",
    "    where 1 means keep element at this position (time step)\n",
    "    \"\"\"\n",
    "    batch_size = lengths.numel()\n",
    "    max_len = max_len or lengths.max_val()  # trick works because of overloading of 'or' operator for non-boolean types\n",
    "    return (torch.arange(0, max_len, device=lengths.device)\n",
    "            .type_as(lengths)\n",
    "            .repeat(batch_size, 1)\n",
    "            .lt(lengths.unsqueeze(1)))\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_gpt4ts(args, val_loader, model, loss):\n",
    "    val_loss = 0\n",
    "    val_accu = 0\n",
    "\n",
    "    sum_len = 0\n",
    "    for data, target, padding_x_mask in val_loader:\n",
    "        '''\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        target = target.to(torch.int64)\n",
    "        '''\n",
    "        with torch.no_grad():\n",
    "            val_pred = model(data, padding_x_mask)\n",
    "            val_loss += loss(val_pred, target).item()\n",
    "            val_accu += torch.sum(torch.argmax(val_pred.data, axis=1) == target)\n",
    "            sum_len += len(target)\n",
    "\n",
    "    return val_loss / sum_len, val_accu / sum_len\n",
    "\n",
    "\n",
    "if __name__ == '__main__':  ##\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Base setup\n",
    "parser.add_argument('--backbone', type=str, default='fcn', help='encoder backbone, fcn')\n",
    "parser.add_argument('--random_seed', type=int, default=42, help='shuffle seed')\n",
    "# UEA, TimesNet: ['EigenWorms', 'LSST', 'StandWalkJump']\n",
    "# Dataset setup\n",
    "parser.add_argument('--dataset', type=str, default='StandWalkJump',\n",
    "                    help='dataset(in ucr)')  # LSST Heartbeat Images  SelfRegulationSCP2\n",
    "# parser.add_argument('--dataroot', type=str, default='../UCRArchive_2018', help='path of UCR folder')\n",
    "# parser.add_argument('--dataroot', type=str, default='/dev_data/lz/time_series_pretrain/datasets/UCRArchive_2018',\n",
    "#                     help='path of UCR folder')\n",
    "# parser.add_argument('--dataroot', type=str, default='/SSD/lz/UCRArchive_2018', help='path of UCR folder')\n",
    "parser.add_argument('--dataroot', type=str, default='/SSD/lz/Multivariate2018_arff', help='path of UEA folder')\n",
    "parser.add_argument('--num_classes', type=int, default=0, help='number of class')\n",
    "parser.add_argument('--normalize_way', type=str, default='single', help='single or train_set')\n",
    "# parser.add_argument('--seq_len', type=int, default=46, help='seq_len')\n",
    "parser.add_argument('--input_size', type=int, default=1, help='input_size')\n",
    "\n",
    "# parser.add_argument('--patch_size', type=int, default=8, help='patch_size')\n",
    "# parser.add_argument('--stride', type=int, default=8, help='stride')\n",
    "\n",
    "parser.add_argument('--target_points', type=int, default=96, help='forecast horizon')\n",
    "\n",
    "# Patch\n",
    "parser.add_argument('--patch_len', type=int, default=8, help='patch length')\n",
    "parser.add_argument('--stride', type=int, default=8, help='stride between patch')\n",
    "\n",
    "# # RevIN\n",
    "# parser.add_argument('--revin', type=int, default=1, help='reversible instance normalization')\n",
    "# # Model args\n",
    "# parser.add_argument('--n_layers', type=int, default=3, help='number of Transformer layers')\n",
    "# parser.add_argument('--n_heads', type=int, default=16, help='number of Transformer heads')\n",
    "# # parser.add_argument('--d_model', type=int, default=128, help='Transformer d_model')\n",
    "# parser.add_argument('--d_ff', type=int, default=256, help='Tranformer MLP dimension')\n",
    "# parser.add_argument('--dropout', type=float, default=0.2, help='Transformer dropout')\n",
    "# parser.add_argument('--head_dropout', type=float, default=0, help='head dropout')\n",
    "\n",
    "# Semi training\n",
    "parser.add_argument('--labeled_ratio', type=float, default='0.1', help='0.1, 0.2, 0.4')\n",
    "\n",
    "# basic config\n",
    "parser.add_argument('--task_name', type=str, required=False, default='classification',\n",
    "                    help='task name, options:[long_term_forecast, short_term_forecast, imputation, classification, anomaly_detection]')\n",
    "parser.add_argument('--freq', type=str, default='h',\n",
    "                    help='freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h')\n",
    "\n",
    "# forecasting task\n",
    "parser.add_argument('--seq_len', type=int, default=96, help='input sequence length')\n",
    "parser.add_argument('--label_len', type=int, default=48, help='start token length')\n",
    "parser.add_argument('--pred_len', type=int, default=0, help='prediction sequence length')\n",
    "parser.add_argument('--seasonal_patterns', type=str, default='Monthly', help='subset for M4')\n",
    "parser.add_argument('--inverse', action='store_true', help='inverse output data', default=False)\n",
    "\n",
    "# model define\n",
    "parser.add_argument('--top_k', type=int, default=3, help='for TimesBlock')\n",
    "parser.add_argument('--num_kernels', type=int, default=6, help='for Inception')\n",
    "parser.add_argument('--enc_in', type=int, default=7, help='encoder input size')\n",
    "parser.add_argument('--dec_in', type=int, default=7, help='decoder input size')\n",
    "parser.add_argument('--c_out', type=int, default=7, help='output size')\n",
    "parser.add_argument('--d_model', type=int, default=64, help='dimension of model')   ###\n",
    "parser.add_argument('--n_heads', type=int, default=8, help='num of heads')\n",
    "parser.add_argument('--e_layers', type=int, default=3, help='num of encoder layers')\n",
    "parser.add_argument('--d_layers', type=int, default=1, help='num of decoder layers')\n",
    "parser.add_argument('--d_ff', type=int, default=64, help='dimension of fcn')\n",
    "parser.add_argument('--moving_avg', type=int, default=25, help='window size of moving average')\n",
    "parser.add_argument('--factor', type=int, default=1, help='attn factor')\n",
    "parser.add_argument('--distil', action='store_false',\n",
    "                    help='whether to use distilling in encoder, using this argument means not using distilling',\n",
    "                    default=True)\n",
    "parser.add_argument('--dropout', type=float, default=0.1, help='dropout')\n",
    "parser.add_argument('--embed', type=str, default='timeF',\n",
    "                    help='time features encoding, options:[timeF, fixed, learned]')\n",
    "parser.add_argument('--activation', type=str, default='gelu', help='activation')\n",
    "parser.add_argument('--output_attention', action='store_true', help='whether to output attention in ecoder')\n",
    "\n",
    "# GPU\n",
    "parser.add_argument('--use_gpu', type=bool, default=True, help='use gpu')\n",
    "parser.add_argument('--gpu', type=int, default=1, help='gpu')\n",
    "\n",
    "\n",
    "# training setup\n",
    "parser.add_argument('--loss', type=str, default='cross_entropy', help='loss function')\n",
    "parser.add_argument('--optimizer', type=str, default='adam', help='optimizer')\n",
    "parser.add_argument('--lr', type=float, default=0.001, help='learning rate')\n",
    "parser.add_argument('--weight_decay', type=float, default=0.0, help='weight decay')\n",
    "parser.add_argument('--batch_size', type=int, default=8, help='')\n",
    "parser.add_argument('--epoch', type=int, default=10, help='training epoch')\n",
    "parser.add_argument('--cuda', type=str, default='cuda:1')\n",
    "\n",
    "parser.add_argument('--save_dir', type=str, default='/SSD/lz/time_series_label_noise/result')\n",
    "parser.add_argument('--save_csv_name', type=str, default='timesnet_UEA_supervised_0731_')\n",
    "\n",
    "# classifier setup\n",
    "parser.add_argument('--classifier', type=str, default='linear', help='type of classifier(linear or nonlinear)')\n",
    "parser.add_argument('--classifier_input', type=int, default=128, help='input dim of the classifiers')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "device = torch.device(args.cuda if torch.cuda.is_available() else \"cpu\")\n",
    "set_seed(args)\n",
    "\n",
    "# sum_dataset, sum_target, num_classes = build_dataset(args)\n",
    "sum_dataset, sum_target, num_classes = load_UEA(args.dataroot, args.dataset)\n",
    "# args.num_classes = num_classes\n",
    "# args.seq_len = sum_dataset.shape[1]\n",
    "\n",
    "args.num_classes = num_classes\n",
    "args.seq_len = sum_dataset.shape[1]\n",
    "args.input_size = sum_dataset.shape[2]\n",
    "\n",
    "args.enc_in = sum_dataset.shape[2]\n",
    "\n",
    "# # get number of patches\n",
    "# num_patch = (max(args.seq_len, args.patch_len) - args.patch_len) // args.stride + 1\n",
    "# print('number of patches:', num_patch)\n",
    "\n",
    "while sum_dataset.shape[0] * 0.6 < args.batch_size:\n",
    "    args.batch_size = args.batch_size // 2\n",
    "\n",
    "print(\"args.batch_size = \", args.batch_size, \", sum_dataset.shape = \", sum_dataset.shape)\n",
    "\n",
    "# get model\n",
    "model = Model(configs=args)\n",
    "\n",
    "\n",
    "# model = gpt4ts(max_seq_len=args.seq_len, num_classes=args.num_classes, var_len=args.input_size, patch_size=args.patch_size, stride=args.stride)\n",
    "model = model.to(device)\n",
    "\n",
    "# model, classifier = build_model(args)\n",
    "# model, classifier = model.to(device), classifier.to(device)\n",
    "loss = build_loss(args).to(device)\n",
    "\n",
    "model_init_state = model.state_dict()\n",
    "# classifier_init_state = classifier.state_dict()\n",
    "\n",
    "if args.optimizer == 'adam':\n",
    "    optimizer = torch.optim.Adam([{'params': model.parameters()}],\n",
    "                                    lr=args.lr, weight_decay=args.weight_decay)\n",
    "elif args.optimizer == 'sgd':\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "\n",
    "train_datasets, train_targets, val_datasets, val_targets, test_datasets, test_targets = get_all_datasets(\n",
    "    sum_dataset, sum_target)\n",
    "\n",
    "losses = []\n",
    "test_accuracies = []\n",
    "train_time = 0.0\n",
    "end_val_epochs = []\n",
    "\n",
    "for i, train_dataset in enumerate(train_datasets):\n",
    "    t = time.time()\n",
    "    model.load_state_dict(model_init_state)\n",
    "    # classifier.load_state_dict(classifier_init_state)\n",
    "    print('{} fold start training and evaluate'.format(i))\n",
    "\n",
    "    train_target = train_targets[i]\n",
    "    val_dataset = val_datasets[i]\n",
    "    val_target = val_targets[i]\n",
    "\n",
    "    test_dataset = test_datasets[i]\n",
    "    test_target = test_targets[i]\n",
    "\n",
    "    train_dataset, val_dataset, test_dataset = fill_nan_value(train_dataset, val_dataset, test_dataset)\n",
    "\n",
    "    if args.normalize_way == 'single':\n",
    "        # TODO normalize per series\n",
    "        train_dataset = normalize_uea_set(train_dataset)\n",
    "        val_dataset = normalize_uea_set(val_dataset)\n",
    "        test_dataset = normalize_uea_set(test_dataset)\n",
    "    # else:\n",
    "    #     train_dataset, val_dataset, test_dataset = normalize_train_val_test(train_dataset, val_dataset,\n",
    "    #                                                                         test_dataset)\n",
    "\n",
    "    train_set = UEADataset(torch.from_numpy(train_dataset).type(torch.FloatTensor).to(device).permute(0,2,1),\n",
    "                            torch.from_numpy(train_target).type(torch.FloatTensor).to(device).to(torch.int64))\n",
    "    val_set = UEADataset(torch.from_numpy(val_dataset).type(torch.FloatTensor).to(device).permute(0,2,1),\n",
    "                            torch.from_numpy(val_target).type(torch.FloatTensor).to(device).to(torch.int64))\n",
    "    test_set = UEADataset(torch.from_numpy(test_dataset).type(torch.FloatTensor).to(device).permute(0,2,1),\n",
    "                            torch.from_numpy(test_target).type(torch.FloatTensor).to(device).to(torch.int64))\n",
    "\n",
    "    # train_set = train_set.permute(0,2,1)\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=args.batch_size, num_workers=0, drop_last=True, collate_fn=lambda x: collate_fn(x, device, max_len=args.seq_len))\n",
    "    val_loader = DataLoader(val_set, batch_size=args.batch_size, num_workers=0, collate_fn=lambda x: collate_fn(x, device, max_len=args.seq_len))\n",
    "    test_loader = DataLoader(test_set, batch_size=args.batch_size, num_workers=0, collate_fn=lambda x: collate_fn(x, device, max_len=args.seq_len))\n",
    "\n",
    "    train_loss = []\n",
    "    train_accuracy = []\n",
    "    num_steps = args.epoch // args.batch_size\n",
    "\n",
    "    last_loss = float('inf')\n",
    "    stop_count = 0\n",
    "    increase_count = 0\n",
    "\n",
    "    num_steps = train_set.__len__() // args.batch_size\n",
    "\n",
    "    min_val_loss = float('inf')\n",
    "    test_accuracy = 0\n",
    "    end_val_epoch = 0\n",
    "\n",
    "    for epoch in range(args.epoch):\n",
    "\n",
    "        if stop_count == 50 or increase_count == 50:\n",
    "            print('model convergent at epoch {}, early stopping'.format(epoch))\n",
    "            break\n",
    "\n",
    "        epoch_train_loss = 0\n",
    "        epoch_train_acc = 0\n",
    "        num_iterations = 0\n",
    "\n",
    "        model.train()\n",
    "        train_embed = []\n",
    "\n",
    "        for x, y, padding_x_mask in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            # print(\"raw x.shape = \", x.shape)\n",
    "            # xb, num_patch = create_patch(xb=x.permute(0,2,1), patch_len=args.patch_len, stride=args.stride)\n",
    "            # print(\"x padding_x_mask.shape = \", x.shape, padding_x_mask.shape, padding_x_mask[0][:10])\n",
    "\n",
    "            # print(\"x.shape = \", x.shape, \", padding_x_mask.shape = \", padding_x_mask.shape)\n",
    "            pred = model(x, padding_x_mask)\n",
    "            step_loss = loss(pred, y)\n",
    "\n",
    "            # step_loss.backward(retain_graph=True)\n",
    "            step_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_train_loss += step_loss.item()\n",
    "            epoch_train_acc += torch.sum(torch.argmax(pred.data, axis=1) == y) / len(y)\n",
    "\n",
    "            num_iterations += 1\n",
    "\n",
    "        epoch_train_loss /= num_steps\n",
    "        epoch_train_acc /= num_steps\n",
    "        # train_embed = np.concatenate(train_embed)\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        val_loss, val_accu = evaluate_gpt4ts(args, val_loader, model, loss)\n",
    "        if min_val_loss > val_loss:\n",
    "            min_val_loss = val_loss\n",
    "            end_val_epoch = epoch\n",
    "            test_loss, test_accuracy = evaluate_gpt4ts(args, test_loader, model, loss)\n",
    "\n",
    "        if abs(last_loss - val_loss) <= 1e-4:\n",
    "            stop_count += 1\n",
    "        else:\n",
    "            stop_count = 0\n",
    "\n",
    "        if val_loss > last_loss:\n",
    "            increase_count += 1\n",
    "        else:\n",
    "            increase_count = 0\n",
    "\n",
    "        last_loss = val_loss\n",
    "\n",
    "        if epoch % 50 == 0:\n",
    "            print(\n",
    "                \"epoch : {}, train loss: {} , train accuracy : {}, \\ntest_accuracy : {}\".format(\n",
    "                    epoch, epoch_train_loss, epoch_train_acc, test_accuracy))\n",
    "\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    end_val_epochs.append(end_val_epoch)\n",
    "    t = time.time() - t\n",
    "    train_time += t\n",
    "\n",
    "    print('{} fold finish training'.format(i))\n",
    "\n",
    "test_accuracies = torch.Tensor(test_accuracies)\n",
    "\n",
    "print(\"Training end: mean_test_acc = \", round(torch.mean(test_accuracies).item(), 4),\n",
    "        \"traning time (seconds) = \",\n",
    "        round(train_time, 4), \", seed = \", args.random_seed)\n",
    "\n",
    "test_accuracies = test_accuracies.cpu().numpy()\n",
    "\n",
    "save_cls_new_result(args, np.mean(test_accuracies), np.max(test_accuracies), np.min(test_accuracies),\n",
    "                    np.std(test_accuracies), train_time)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
