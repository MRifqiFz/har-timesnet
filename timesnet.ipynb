{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import time\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance\n",
    "\n",
    "curPath = os.path.abspath(os.path.dirname('models'))\n",
    "rootPath = os.path.split(curPath)[0]\n",
    "sys.path.append(rootPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_labels(labels):\n",
    "    indicies = np.unique(labels)\n",
    "    num_samples = labels.shape[0]\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        new_label = np.argwhere(labels[i] == indicies)[0][0]\n",
    "        labels[i] = new_label\n",
    "\n",
    "    return labels\n",
    "\n",
    "def collate_fn(data, device, max_len=None):\n",
    "    \"\"\"Build mini-batch tensors from a list of (X, mask) tuples. Mask input. Create\n",
    "    Args:\n",
    "        data: len(batch_size) list of tuples (X, y).\n",
    "            - X: torch tensor of shape (seq_length, feat_dim); variable seq_length.\n",
    "            - y: torch tensor of shape (num_labels,) : class indices or numerical targets\n",
    "                (for classification or regression, respectively). num_labels > 1 for multi-task models\n",
    "        max_len: global fixed sequence length. Used for architectures requiring fixed length input,\n",
    "            where the batch length cannot vary dynamically. Longer sequences are clipped, shorter are padded with 0s\n",
    "    Returns:\n",
    "        X: (batch_size, padded_length, feat_dim) torch tensor of masked features (input)\n",
    "        targets: (batch_size, padded_length, feat_dim) torch tensor of unmasked features (output)\n",
    "        target_masks: (batch_size, padded_length, feat_dim) boolean torch tensor\n",
    "            0 indicates masked values to be predicted, 1 indicates unaffected/\"active\" feature values\n",
    "        padding_masks: (batch_size, padded_length) boolean tensor, 1 means keep vector at this position, 0 means padding\n",
    "    \"\"\"\n",
    "\n",
    "    batch_size = len(data)\n",
    "    features, labels = zip(*data)\n",
    "\n",
    "    # Stack and pad features and masks (convert 2D to 3D tensors, i.e. add batch dimension)\n",
    "    lengths = [X.shape[0] for X in features]  # original sequence length for each time series\n",
    "    if max_len is None:\n",
    "        max_len = max(lengths)\n",
    "\n",
    "    X = torch.zeros(batch_size, max_len, features[0].shape[-1])  # (batch_size, padded_length, feat_dim)\n",
    "    for i in range(batch_size):\n",
    "        end = min(lengths[i], max_len)\n",
    "        X[i, :end, :] = features[i][:end, :]\n",
    "\n",
    "    targets = torch.stack(labels, dim=0)  # (batch_size, num_labels)\n",
    "\n",
    "    padding_masks = padding_mask(torch.tensor(lengths, dtype=torch.int16),\n",
    "                                 max_len=max_len)  # (batch_size, padded_length) boolean tensor, \"1\" means keep\n",
    "\n",
    "    return X.to(device), targets.to(device), padding_masks.to(device)\n",
    "\n",
    "\n",
    "def padding_mask(lengths, max_len=None):\n",
    "    \"\"\"\n",
    "    Used to mask padded positions: creates a (batch_size, max_len) boolean mask from a tensor of sequence lengths,\n",
    "    where 1 means keep element at this position (time step)\n",
    "    \"\"\"\n",
    "    batch_size = lengths.numel()\n",
    "    max_len = max_len or lengths.max_val()  # trick works because of overloading of 'or' operator for non-boolean types\n",
    "    return (torch.arange(0, max_len, device=lengths.device)\n",
    "            .type_as(lengths)\n",
    "            .repeat(batch_size, 1)\n",
    "            .lt(lengths.unsqueeze(1)))\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(args, val_loader, model, loss):\n",
    "    val_loss = 0\n",
    "    val_accu = 0\n",
    "\n",
    "    sum_len = 0\n",
    "    for data, target, padding_x_mask in val_loader:\n",
    "        '''\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        target = target.to(torch.int64)\n",
    "        '''\n",
    "        with torch.no_grad():\n",
    "            val_pred = model(data, padding_x_mask)\n",
    "            val_loss += loss(val_pred, target).item()\n",
    "            val_accu += torch.sum(torch.argmax(val_pred.data, axis=1) == target)\n",
    "            sum_len += len(target)\n",
    "\n",
    "    return val_loss / sum_len, val_accu / sum_len\n",
    "\n",
    "def set_seed(args):\n",
    "    random.seed(args.random_seed)\n",
    "    np.random.seed(args.random_seed)\n",
    "    torch.manual_seed(args.random_seed)\n",
    "    torch.cuda.manual_seed(args.random_seed)\n",
    "    torch.cuda.manual_seed_all(args.random_seed)\n",
    "\n",
    "\n",
    "class HARDataset(Dataset):\n",
    "    def __init__(self, dataset, target):\n",
    "        # (num_size, num_dimensions, series_length)\n",
    "        self.dataset = dataset.permute(0, 2, 1)\n",
    "        self.target = target\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.dataset[index], self.target[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target)\n",
    "    \n",
    "def normalize(data_set):\n",
    "    '''\n",
    "    The function is the same as normalize_per_series, but can be used for multiple variables.\n",
    "    '''\n",
    "    return TimeSeriesScalerMeanVariance().fit_transform(data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(backbone='fcn', random_seed=42, num_classes=0, normalize_way='single', input_size=1, target_points=96, patch_len=8, stride=8, labeled_ratio=0.1, task_name='classification', freq='h', seq_len=96, label_len=48, pred_len=0, seasonal_patterns='Monthly', inverse=False, top_k=3, num_kernels=6, enc_in=7, dec_in=7, c_out=7, d_model=64, n_heads=8, e_layers=3, d_layers=1, d_ff=64, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, use_gpu=True, gpu=1, loss='cross_entropy', optimizer='adam', lr=0.001, weight_decay=0.0, batch_size=8, epoch=15, cuda='cuda:1', save_dir='/SSD/lz/time_series_label_noise/result', save_csv_name='timesnet_ucr_supervised_0801_', classifier='linear', classifier_input=128)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Base setup\n",
    "parser.add_argument('--backbone', type=str, default='fcn', help='encoder backbone, fcn')\n",
    "parser.add_argument('--random_seed', type=int, default=42, help='shuffle seed')\n",
    "\n",
    "# Dataset setup\n",
    "parser.add_argument('--num_classes', type=int, default=0, help='number of class')\n",
    "parser.add_argument('--normalize_way', type=str, default='single', help='single or train_set')\n",
    "# parser.add_argument('--seq_len', type=int, default=46, help='seq_len')\n",
    "parser.add_argument('--input_size', type=int, default=1, help='input_size')\n",
    "\n",
    "# parser.add_argument('--patch_size', type=int, default=8, help='patch_size')\n",
    "# parser.add_argument('--stride', type=int, default=8, help='stride')\n",
    "\n",
    "parser.add_argument('--target_points', type=int, default=96, help='forecast horizon')\n",
    "\n",
    "# Patch\n",
    "parser.add_argument('--patch_len', type=int, default=8, help='patch length')\n",
    "parser.add_argument('--stride', type=int, default=8, help='stride between patch')\n",
    "\n",
    "# Semi training\n",
    "parser.add_argument('--labeled_ratio', type=float, default='0.1', help='0.1, 0.2, 0.4')\n",
    "\n",
    "# basic config\n",
    "parser.add_argument('--task_name', type=str, required=False, default='classification',\n",
    "                    help='task name, options:[long_term_forecast, short_term_forecast, imputation, classification, anomaly_detection]')\n",
    "parser.add_argument('--freq', type=str, default='h',\n",
    "                    help='freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h')\n",
    "\n",
    "# forecasting task\n",
    "parser.add_argument('--seq_len', type=int, default=96, help='input sequence length')\n",
    "parser.add_argument('--label_len', type=int, default=48, help='start token length')\n",
    "parser.add_argument('--pred_len', type=int, default=0, help='prediction sequence length')\n",
    "parser.add_argument('--seasonal_patterns', type=str, default='Monthly', help='subset for M4')\n",
    "parser.add_argument('--inverse', action='store_true', help='inverse output data', default=False)\n",
    "\n",
    "# model define\n",
    "parser.add_argument('--top_k', type=int, default=3, help='for TimesBlock')\n",
    "parser.add_argument('--num_kernels', type=int, default=6, help='for Inception')\n",
    "parser.add_argument('--enc_in', type=int, default=7, help='encoder input size')\n",
    "parser.add_argument('--dec_in', type=int, default=7, help='decoder input size')\n",
    "parser.add_argument('--c_out', type=int, default=7, help='output size')\n",
    "parser.add_argument('--d_model', type=int, default=64, help='dimension of model')   ###\n",
    "parser.add_argument('--n_heads', type=int, default=8, help='num of heads')\n",
    "parser.add_argument('--e_layers', type=int, default=3, help='num of encoder layers')\n",
    "parser.add_argument('--d_layers', type=int, default=1, help='num of decoder layers')\n",
    "parser.add_argument('--d_ff', type=int, default=64, help='dimension of fcn')\n",
    "parser.add_argument('--moving_avg', type=int, default=25, help='window size of moving average')\n",
    "parser.add_argument('--factor', type=int, default=1, help='attn factor')\n",
    "parser.add_argument('--distil', action='store_false',\n",
    "                    help='whether to use distilling in encoder, using this argument means not using distilling',\n",
    "                    default=True)\n",
    "parser.add_argument('--dropout', type=float, default=0.1, help='dropout')\n",
    "parser.add_argument('--embed', type=str, default='timeF',\n",
    "                    help='time features encoding, options:[timeF, fixed, learned]')\n",
    "parser.add_argument('--activation', type=str, default='gelu', help='activation')\n",
    "parser.add_argument('--output_attention', action='store_true', help='whether to output attention in ecoder')\n",
    "\n",
    "# GPU\n",
    "parser.add_argument('--use_gpu', type=bool, default=True, help='use gpu')\n",
    "parser.add_argument('--gpu', type=int, default=1, help='gpu')\n",
    "\n",
    "\n",
    "# training setup\n",
    "parser.add_argument('--loss', type=str, default='cross_entropy', help='loss function')\n",
    "parser.add_argument('--optimizer', type=str, default='adam', help='optimizer')\n",
    "parser.add_argument('--lr', type=float, default=0.001, help='learning rate')\n",
    "parser.add_argument('--weight_decay', type=float, default=0.0, help='weight decay')\n",
    "parser.add_argument('--batch_size', type=int, default=8, help='')\n",
    "parser.add_argument('--epoch', type=int, default=15, help='training epoch')\n",
    "parser.add_argument('--cuda', type=str, default='cuda:1')\n",
    "\n",
    "parser.add_argument('--save_dir', type=str, default='/SSD/lz/time_series_label_noise/result')\n",
    "parser.add_argument('--save_csv_name', type=str, default='timesnet_ucr_supervised_0801_')\n",
    "\n",
    "# classifier setup\n",
    "parser.add_argument('--classifier', type=str, default='linear', help='type of classifier(linear or nonlinear)')\n",
    "parser.add_argument('--classifier_input', type=int, default=128, help='input dim of the classifiers')\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "device = torch.device(args.cuda if torch.cuda.is_available() else \"cpu\")\n",
    "set_seed(args)\n",
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('dataset/train.csv')\n",
    "test = pd.read_csv('dataset/test.csv')\n",
    "\n",
    "train = train.drop('subject', axis=1)\n",
    "test = test.drop('subject', axis=1)\n",
    "\n",
    "labelNames = list(np.unique(train['Activity']))\n",
    "labelNames.sort()\n",
    "train['Activity'] = train['Activity'].apply(lambda x: labelNames.index(x))\n",
    "test['Activity'] = test['Activity'].apply(lambda x: labelNames.index(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tBodyAcc-mean()-X</th>\n",
       "      <th>tBodyAcc-mean()-Y</th>\n",
       "      <th>tBodyAcc-mean()-Z</th>\n",
       "      <th>tBodyAcc-std()-X</th>\n",
       "      <th>tBodyAcc-std()-Y</th>\n",
       "      <th>tBodyAcc-std()-Z</th>\n",
       "      <th>tBodyAcc-mad()-X</th>\n",
       "      <th>tBodyAcc-mad()-Y</th>\n",
       "      <th>tBodyAcc-mad()-Z</th>\n",
       "      <th>tBodyAcc-max()-X</th>\n",
       "      <th>...</th>\n",
       "      <th>fBodyBodyGyroJerkMag-skewness()</th>\n",
       "      <th>fBodyBodyGyroJerkMag-kurtosis()</th>\n",
       "      <th>angle(tBodyAccMean,gravity)</th>\n",
       "      <th>angle(tBodyAccJerkMean),gravityMean)</th>\n",
       "      <th>angle(tBodyGyroMean,gravityMean)</th>\n",
       "      <th>angle(tBodyGyroJerkMean,gravityMean)</th>\n",
       "      <th>angle(X,gravityMean)</th>\n",
       "      <th>angle(Y,gravityMean)</th>\n",
       "      <th>angle(Z,gravityMean)</th>\n",
       "      <th>Activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.288585</td>\n",
       "      <td>-0.020294</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.995279</td>\n",
       "      <td>-0.983111</td>\n",
       "      <td>-0.913526</td>\n",
       "      <td>-0.995112</td>\n",
       "      <td>-0.983185</td>\n",
       "      <td>-0.923527</td>\n",
       "      <td>-0.934724</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.298676</td>\n",
       "      <td>-0.710304</td>\n",
       "      <td>-0.112754</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>-0.464761</td>\n",
       "      <td>-0.018446</td>\n",
       "      <td>-0.841247</td>\n",
       "      <td>0.179941</td>\n",
       "      <td>-0.058627</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.278419</td>\n",
       "      <td>-0.016411</td>\n",
       "      <td>-0.123520</td>\n",
       "      <td>-0.998245</td>\n",
       "      <td>-0.975300</td>\n",
       "      <td>-0.960322</td>\n",
       "      <td>-0.998807</td>\n",
       "      <td>-0.974914</td>\n",
       "      <td>-0.957686</td>\n",
       "      <td>-0.943068</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.595051</td>\n",
       "      <td>-0.861499</td>\n",
       "      <td>0.053477</td>\n",
       "      <td>-0.007435</td>\n",
       "      <td>-0.732626</td>\n",
       "      <td>0.703511</td>\n",
       "      <td>-0.844788</td>\n",
       "      <td>0.180289</td>\n",
       "      <td>-0.054317</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.279653</td>\n",
       "      <td>-0.019467</td>\n",
       "      <td>-0.113462</td>\n",
       "      <td>-0.995380</td>\n",
       "      <td>-0.967187</td>\n",
       "      <td>-0.978944</td>\n",
       "      <td>-0.996520</td>\n",
       "      <td>-0.963668</td>\n",
       "      <td>-0.977469</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.390748</td>\n",
       "      <td>-0.760104</td>\n",
       "      <td>-0.118559</td>\n",
       "      <td>0.177899</td>\n",
       "      <td>0.100699</td>\n",
       "      <td>0.808529</td>\n",
       "      <td>-0.848933</td>\n",
       "      <td>0.180637</td>\n",
       "      <td>-0.049118</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.279174</td>\n",
       "      <td>-0.026201</td>\n",
       "      <td>-0.123283</td>\n",
       "      <td>-0.996091</td>\n",
       "      <td>-0.983403</td>\n",
       "      <td>-0.990675</td>\n",
       "      <td>-0.997099</td>\n",
       "      <td>-0.982750</td>\n",
       "      <td>-0.989302</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.117290</td>\n",
       "      <td>-0.482845</td>\n",
       "      <td>-0.036788</td>\n",
       "      <td>-0.012892</td>\n",
       "      <td>0.640011</td>\n",
       "      <td>-0.485366</td>\n",
       "      <td>-0.848649</td>\n",
       "      <td>0.181935</td>\n",
       "      <td>-0.047663</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.276629</td>\n",
       "      <td>-0.016570</td>\n",
       "      <td>-0.115362</td>\n",
       "      <td>-0.998139</td>\n",
       "      <td>-0.980817</td>\n",
       "      <td>-0.990482</td>\n",
       "      <td>-0.998321</td>\n",
       "      <td>-0.979672</td>\n",
       "      <td>-0.990441</td>\n",
       "      <td>-0.942469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.351471</td>\n",
       "      <td>-0.699205</td>\n",
       "      <td>0.123320</td>\n",
       "      <td>0.122542</td>\n",
       "      <td>0.693578</td>\n",
       "      <td>-0.615971</td>\n",
       "      <td>-0.847865</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>-0.043892</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 562 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tBodyAcc-mean()-X  tBodyAcc-mean()-Y  tBodyAcc-mean()-Z  tBodyAcc-std()-X  \\\n",
       "0           0.288585          -0.020294          -0.132905         -0.995279   \n",
       "1           0.278419          -0.016411          -0.123520         -0.998245   \n",
       "2           0.279653          -0.019467          -0.113462         -0.995380   \n",
       "3           0.279174          -0.026201          -0.123283         -0.996091   \n",
       "4           0.276629          -0.016570          -0.115362         -0.998139   \n",
       "\n",
       "   tBodyAcc-std()-Y  tBodyAcc-std()-Z  tBodyAcc-mad()-X  tBodyAcc-mad()-Y  \\\n",
       "0         -0.983111         -0.913526         -0.995112         -0.983185   \n",
       "1         -0.975300         -0.960322         -0.998807         -0.974914   \n",
       "2         -0.967187         -0.978944         -0.996520         -0.963668   \n",
       "3         -0.983403         -0.990675         -0.997099         -0.982750   \n",
       "4         -0.980817         -0.990482         -0.998321         -0.979672   \n",
       "\n",
       "   tBodyAcc-mad()-Z  tBodyAcc-max()-X  ...  fBodyBodyGyroJerkMag-skewness()  \\\n",
       "0         -0.923527         -0.934724  ...                        -0.298676   \n",
       "1         -0.957686         -0.943068  ...                        -0.595051   \n",
       "2         -0.977469         -0.938692  ...                        -0.390748   \n",
       "3         -0.989302         -0.938692  ...                        -0.117290   \n",
       "4         -0.990441         -0.942469  ...                        -0.351471   \n",
       "\n",
       "   fBodyBodyGyroJerkMag-kurtosis()  angle(tBodyAccMean,gravity)  \\\n",
       "0                        -0.710304                    -0.112754   \n",
       "1                        -0.861499                     0.053477   \n",
       "2                        -0.760104                    -0.118559   \n",
       "3                        -0.482845                    -0.036788   \n",
       "4                        -0.699205                     0.123320   \n",
       "\n",
       "   angle(tBodyAccJerkMean),gravityMean)  angle(tBodyGyroMean,gravityMean)  \\\n",
       "0                              0.030400                         -0.464761   \n",
       "1                             -0.007435                         -0.732626   \n",
       "2                              0.177899                          0.100699   \n",
       "3                             -0.012892                          0.640011   \n",
       "4                              0.122542                          0.693578   \n",
       "\n",
       "   angle(tBodyGyroJerkMean,gravityMean)  angle(X,gravityMean)  \\\n",
       "0                             -0.018446             -0.841247   \n",
       "1                              0.703511             -0.844788   \n",
       "2                              0.808529             -0.848933   \n",
       "3                             -0.485366             -0.848649   \n",
       "4                             -0.615971             -0.847865   \n",
       "\n",
       "   angle(Y,gravityMean)  angle(Z,gravityMean)  Activity  \n",
       "0              0.179941             -0.058627         2  \n",
       "1              0.180289             -0.054317         2  \n",
       "2              0.180637             -0.049118         2  \n",
       "3              0.181935             -0.047663         2  \n",
       "4              0.185151             -0.043892         2  \n",
       "\n",
       "[5 rows x 562 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tBodyAcc-mean()-X</th>\n",
       "      <th>tBodyAcc-mean()-Y</th>\n",
       "      <th>tBodyAcc-mean()-Z</th>\n",
       "      <th>tBodyAcc-std()-X</th>\n",
       "      <th>tBodyAcc-std()-Y</th>\n",
       "      <th>tBodyAcc-std()-Z</th>\n",
       "      <th>tBodyAcc-mad()-X</th>\n",
       "      <th>tBodyAcc-mad()-Y</th>\n",
       "      <th>tBodyAcc-mad()-Z</th>\n",
       "      <th>tBodyAcc-max()-X</th>\n",
       "      <th>...</th>\n",
       "      <th>fBodyBodyGyroJerkMag-skewness()</th>\n",
       "      <th>fBodyBodyGyroJerkMag-kurtosis()</th>\n",
       "      <th>angle(tBodyAccMean,gravity)</th>\n",
       "      <th>angle(tBodyAccJerkMean),gravityMean)</th>\n",
       "      <th>angle(tBodyGyroMean,gravityMean)</th>\n",
       "      <th>angle(tBodyGyroJerkMean,gravityMean)</th>\n",
       "      <th>angle(X,gravityMean)</th>\n",
       "      <th>angle(Y,gravityMean)</th>\n",
       "      <th>angle(Z,gravityMean)</th>\n",
       "      <th>Activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.257178</td>\n",
       "      <td>-0.023285</td>\n",
       "      <td>-0.014654</td>\n",
       "      <td>-0.938404</td>\n",
       "      <td>-0.920091</td>\n",
       "      <td>-0.667683</td>\n",
       "      <td>-0.952501</td>\n",
       "      <td>-0.925249</td>\n",
       "      <td>-0.674302</td>\n",
       "      <td>-0.894088</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.330370</td>\n",
       "      <td>-0.705974</td>\n",
       "      <td>0.006462</td>\n",
       "      <td>0.162920</td>\n",
       "      <td>-0.825886</td>\n",
       "      <td>0.271151</td>\n",
       "      <td>-0.720009</td>\n",
       "      <td>0.276801</td>\n",
       "      <td>-0.057978</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.286027</td>\n",
       "      <td>-0.013163</td>\n",
       "      <td>-0.119083</td>\n",
       "      <td>-0.975415</td>\n",
       "      <td>-0.967458</td>\n",
       "      <td>-0.944958</td>\n",
       "      <td>-0.986799</td>\n",
       "      <td>-0.968401</td>\n",
       "      <td>-0.945823</td>\n",
       "      <td>-0.894088</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121845</td>\n",
       "      <td>-0.594944</td>\n",
       "      <td>-0.083495</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>-0.434375</td>\n",
       "      <td>0.920593</td>\n",
       "      <td>-0.698091</td>\n",
       "      <td>0.281343</td>\n",
       "      <td>-0.083898</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.275485</td>\n",
       "      <td>-0.026050</td>\n",
       "      <td>-0.118152</td>\n",
       "      <td>-0.993819</td>\n",
       "      <td>-0.969926</td>\n",
       "      <td>-0.962748</td>\n",
       "      <td>-0.994403</td>\n",
       "      <td>-0.970735</td>\n",
       "      <td>-0.963483</td>\n",
       "      <td>-0.939260</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.190422</td>\n",
       "      <td>-0.640736</td>\n",
       "      <td>-0.034956</td>\n",
       "      <td>0.202302</td>\n",
       "      <td>0.064103</td>\n",
       "      <td>0.145068</td>\n",
       "      <td>-0.702771</td>\n",
       "      <td>0.280083</td>\n",
       "      <td>-0.079346</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.270298</td>\n",
       "      <td>-0.032614</td>\n",
       "      <td>-0.117520</td>\n",
       "      <td>-0.994743</td>\n",
       "      <td>-0.973268</td>\n",
       "      <td>-0.967091</td>\n",
       "      <td>-0.995274</td>\n",
       "      <td>-0.974471</td>\n",
       "      <td>-0.968897</td>\n",
       "      <td>-0.938610</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.344418</td>\n",
       "      <td>-0.736124</td>\n",
       "      <td>-0.017067</td>\n",
       "      <td>0.154438</td>\n",
       "      <td>0.340134</td>\n",
       "      <td>0.296407</td>\n",
       "      <td>-0.698954</td>\n",
       "      <td>0.284114</td>\n",
       "      <td>-0.077108</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.274833</td>\n",
       "      <td>-0.027848</td>\n",
       "      <td>-0.129527</td>\n",
       "      <td>-0.993852</td>\n",
       "      <td>-0.967445</td>\n",
       "      <td>-0.978295</td>\n",
       "      <td>-0.994111</td>\n",
       "      <td>-0.965953</td>\n",
       "      <td>-0.977346</td>\n",
       "      <td>-0.938610</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.534685</td>\n",
       "      <td>-0.846595</td>\n",
       "      <td>-0.002223</td>\n",
       "      <td>-0.040046</td>\n",
       "      <td>0.736715</td>\n",
       "      <td>-0.118545</td>\n",
       "      <td>-0.692245</td>\n",
       "      <td>0.290722</td>\n",
       "      <td>-0.073857</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 562 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tBodyAcc-mean()-X  tBodyAcc-mean()-Y  tBodyAcc-mean()-Z  tBodyAcc-std()-X  \\\n",
       "0           0.257178          -0.023285          -0.014654         -0.938404   \n",
       "1           0.286027          -0.013163          -0.119083         -0.975415   \n",
       "2           0.275485          -0.026050          -0.118152         -0.993819   \n",
       "3           0.270298          -0.032614          -0.117520         -0.994743   \n",
       "4           0.274833          -0.027848          -0.129527         -0.993852   \n",
       "\n",
       "   tBodyAcc-std()-Y  tBodyAcc-std()-Z  tBodyAcc-mad()-X  tBodyAcc-mad()-Y  \\\n",
       "0         -0.920091         -0.667683         -0.952501         -0.925249   \n",
       "1         -0.967458         -0.944958         -0.986799         -0.968401   \n",
       "2         -0.969926         -0.962748         -0.994403         -0.970735   \n",
       "3         -0.973268         -0.967091         -0.995274         -0.974471   \n",
       "4         -0.967445         -0.978295         -0.994111         -0.965953   \n",
       "\n",
       "   tBodyAcc-mad()-Z  tBodyAcc-max()-X  ...  fBodyBodyGyroJerkMag-skewness()  \\\n",
       "0         -0.674302         -0.894088  ...                        -0.330370   \n",
       "1         -0.945823         -0.894088  ...                        -0.121845   \n",
       "2         -0.963483         -0.939260  ...                        -0.190422   \n",
       "3         -0.968897         -0.938610  ...                        -0.344418   \n",
       "4         -0.977346         -0.938610  ...                        -0.534685   \n",
       "\n",
       "   fBodyBodyGyroJerkMag-kurtosis()  angle(tBodyAccMean,gravity)  \\\n",
       "0                        -0.705974                     0.006462   \n",
       "1                        -0.594944                    -0.083495   \n",
       "2                        -0.640736                    -0.034956   \n",
       "3                        -0.736124                    -0.017067   \n",
       "4                        -0.846595                    -0.002223   \n",
       "\n",
       "   angle(tBodyAccJerkMean),gravityMean)  angle(tBodyGyroMean,gravityMean)  \\\n",
       "0                              0.162920                         -0.825886   \n",
       "1                              0.017500                         -0.434375   \n",
       "2                              0.202302                          0.064103   \n",
       "3                              0.154438                          0.340134   \n",
       "4                             -0.040046                          0.736715   \n",
       "\n",
       "   angle(tBodyGyroJerkMean,gravityMean)  angle(X,gravityMean)  \\\n",
       "0                              0.271151             -0.720009   \n",
       "1                              0.920593             -0.698091   \n",
       "2                              0.145068             -0.702771   \n",
       "3                              0.296407             -0.698954   \n",
       "4                             -0.118545             -0.692245   \n",
       "\n",
       "   angle(Y,gravityMean)  angle(Z,gravityMean)  Activity  \n",
       "0              0.276801             -0.057978         2  \n",
       "1              0.281343             -0.083898         2  \n",
       "2              0.280083             -0.079346         2  \n",
       "3              0.284114             -0.077108         2  \n",
       "4              0.290722             -0.073857         2  \n",
       "\n",
       "[5 rows x 562 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.iloc[:, :-1].to_numpy(dtype=np.float32)\n",
    "y_train = train.iloc[:, -1].to_numpy(dtype=np.float32)\n",
    "\n",
    "x_test = test.iloc[:, :-1].to_numpy(dtype=np.float32)\n",
    "y_test = test.iloc[:, -1].to_numpy(dtype=np.float32)\n",
    "\n",
    "num_classes = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[:, :, np.newaxis]\n",
    "x_test = x_test[:, :, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args.batch_size =  8 , x_train.shape =  (7352, 561, 1) , x_test.shape =  (2947, 561, 1)\n"
     ]
    }
   ],
   "source": [
    "args.num_classes = num_classes\n",
    "args.seq_len = x_train.shape[1]\n",
    "args.input_size = x_train.shape[2]\n",
    "\n",
    "args.enc_in = x_train.shape[2]\n",
    "\n",
    "while x_train.shape[0] * 0.6 < args.batch_size:\n",
    "    args.batch_size = args.batch_size // 2\n",
    "\n",
    "print(\"args.batch_size = \", args.batch_size, \", x_train.shape = \", x_train.shape, \", x_test.shape = \", x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Inception_Block_V1(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_kernels=6, init_weight=True):\n",
    "        super(Inception_Block_V1, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.num_kernels = num_kernels\n",
    "        kernels = []\n",
    "        for i in range(self.num_kernels):\n",
    "            kernels.append(nn.Conv2d(in_channels, out_channels, kernel_size=2 * i + 1, padding=i))\n",
    "        self.kernels = nn.ModuleList(kernels)\n",
    "        if init_weight:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res_list = []\n",
    "        for i in range(self.num_kernels):\n",
    "            res_list.append(self.kernels[i](x))\n",
    "        res = torch.stack(res_list, dim=-1).mean(-1)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=25000):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)]\n",
    "\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        padding = 1 if torch.__version__ >= '1.5.0' else 2\n",
    "        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model,\n",
    "                                   kernel_size=3, padding=padding, padding_mode='circular', bias=False)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FixedEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(FixedEmbedding, self).__init__()\n",
    "\n",
    "        w = torch.zeros(c_in, d_model).float()\n",
    "        w.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, c_in).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        w[:, 0::2] = torch.sin(position * div_term)\n",
    "        w[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.emb = nn.Embedding(c_in, d_model)\n",
    "        self.emb.weight = nn.Parameter(w, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.emb(x).detach()\n",
    "\n",
    "\n",
    "class TemporalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='fixed', freq='h'):\n",
    "        super(TemporalEmbedding, self).__init__()\n",
    "\n",
    "        minute_size = 4\n",
    "        hour_size = 24\n",
    "        weekday_size = 7\n",
    "        day_size = 32\n",
    "        month_size = 13\n",
    "\n",
    "        Embed = FixedEmbedding if embed_type == 'fixed' else nn.Embedding\n",
    "        if freq == 't':\n",
    "            self.minute_embed = Embed(minute_size, d_model)\n",
    "        self.hour_embed = Embed(hour_size, d_model)\n",
    "        self.weekday_embed = Embed(weekday_size, d_model)\n",
    "        self.day_embed = Embed(day_size, d_model)\n",
    "        self.month_embed = Embed(month_size, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.long()\n",
    "        minute_x = self.minute_embed(x[:, :, 4]) if hasattr(\n",
    "            self, 'minute_embed') else 0.\n",
    "        hour_x = self.hour_embed(x[:, :, 3])\n",
    "        weekday_x = self.weekday_embed(x[:, :, 2])\n",
    "        day_x = self.day_embed(x[:, :, 1])\n",
    "        month_x = self.month_embed(x[:, :, 0])\n",
    "\n",
    "        return hour_x + weekday_x + day_x + month_x + minute_x\n",
    "\n",
    "\n",
    "class TimeFeatureEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='timeF', freq='h'):\n",
    "        super(TimeFeatureEmbedding, self).__init__()\n",
    "\n",
    "        freq_map = {'h': 4, 't': 5, 's': 6,\n",
    "                    'm': 1, 'a': 1, 'w': 2, 'd': 3, 'b': 3}\n",
    "        d_inp = freq_map[freq]\n",
    "        self.embed = nn.Linear(d_inp, d_model, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)\n",
    "\n",
    "\n",
    "class DataEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
    "        super(DataEmbedding, self).__init__()\n",
    "\n",
    "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
    "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
    "        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n",
    "                                                    freq=freq) if embed_type != 'timeF' else TimeFeatureEmbedding(\n",
    "            d_model=d_model, embed_type=embed_type, freq=freq)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, x_mark):\n",
    "        if x_mark is None:\n",
    "            x = self.value_embedding(x) + self.position_embedding(x)\n",
    "        else:\n",
    "            x = self.value_embedding(\n",
    "                x) + self.temporal_embedding(x_mark) + self.position_embedding(x)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.fft\n",
    "\n",
    "\n",
    "def FFT_for_Period(x, k=2):\n",
    "    # [B, T, C]\n",
    "    xf = torch.fft.rfft(x, dim=1)\n",
    "    # find period by amplitudes\n",
    "    frequency_list = abs(xf).mean(0).mean(-1)\n",
    "    frequency_list[0] = 0\n",
    "    _, top_list = torch.topk(frequency_list, k)\n",
    "    top_list = top_list.detach().cpu().numpy()\n",
    "    period = x.shape[1] // top_list\n",
    "\n",
    "    # print(\"period.shape = \", period.shape, top_list.shape, top_list, period)\n",
    "    return period, abs(xf).mean(-1)[:, top_list]\n",
    "\n",
    "\n",
    "class TimesBlock(nn.Module):\n",
    "    def __init__(self, configs):\n",
    "        super(TimesBlock, self).__init__()\n",
    "        self.seq_len = configs.seq_len\n",
    "        self.pred_len = configs.pred_len\n",
    "        self.k = configs.top_k\n",
    "        # parameter-efficient design\n",
    "        self.conv = nn.Sequential(\n",
    "            Inception_Block_V1(configs.d_model, configs.d_ff,\n",
    "                               num_kernels=configs.num_kernels),\n",
    "            nn.GELU(),\n",
    "            Inception_Block_V1(configs.d_ff, configs.d_model,\n",
    "                               num_kernels=configs.num_kernels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(\"Input shape:\", x.shape)\n",
    "        B, T, N = x.size()\n",
    "        period_list, period_weight = FFT_for_Period(x, self.k)\n",
    "\n",
    "        # print(\"period_list shape = \", period_list.shape, period_list)\n",
    "\n",
    "        # print(\"period_list period_weight shape:\", period_list.shape, period_weight.shape, self.k, self.seq_len, self.pred_len)\n",
    "\n",
    "        res = []\n",
    "        for i in range(self.k):\n",
    "            period = period_list[i]\n",
    "            # padding\n",
    "            if (self.seq_len + self.pred_len) % period != 0:\n",
    "                length = (\n",
    "                                 ((self.seq_len + self.pred_len) // period) + 1) * period\n",
    "\n",
    "                # print(\"length = \", length, self.seq_len, self.pred_len, period)\n",
    "                padding = torch.zeros([x.shape[0], (length - (self.seq_len + self.pred_len)), x.shape[2]]).to(x.device)\n",
    "\n",
    "                # print(\"padding x shape = \", padding.shape, x.shape)\n",
    "                out = torch.cat([x, padding], dim=1)\n",
    "                # print(\"padding out shape = \", out.shape)\n",
    "            else:\n",
    "                length = (self.seq_len + self.pred_len)\n",
    "                out = x\n",
    "\n",
    "            # print(\"out.shape = \", out.shape, length, period, length // period, N )\n",
    "            # reshape\n",
    "            out = out.reshape(B, length // period, period,\n",
    "                              N).permute(0, 3, 1, 2).contiguous()\n",
    "            # 2D conv: from 1d Variation to 2d Variation\n",
    "            out = self.conv(out)\n",
    "            # reshape back\n",
    "            out = out.permute(0, 2, 3, 1).reshape(B, -1, N)\n",
    "            res.append(out[:, :(self.seq_len + self.pred_len), :])\n",
    "        res = torch.stack(res, dim=-1)\n",
    "        # adaptive aggregation\n",
    "        period_weight = F.softmax(period_weight, dim=1)\n",
    "        period_weight = period_weight.unsqueeze(\n",
    "            1).unsqueeze(1).repeat(1, T, N, 1)\n",
    "        res = torch.sum(res * period_weight, -1)\n",
    "        # residual connection\n",
    "        res = res + x\n",
    "        return res\n",
    "\n",
    "\n",
    "class TimesNetModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Paper link: https://openreview.net/pdf?id=ju_Uqw384Oq\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, configs):\n",
    "        super(TimesNetModel, self).__init__()\n",
    "        self.configs = configs\n",
    "        self.model = nn.ModuleList([TimesBlock(configs)\n",
    "                                    for _ in range(configs.e_layers)])\n",
    "        self.enc_embedding = DataEmbedding(configs.enc_in, configs.d_model, configs.embed, configs.freq,\n",
    "                                           configs.dropout)\n",
    "        self.layer = configs.e_layers\n",
    "        self.layer_norm = nn.LayerNorm(configs.d_model)\n",
    "        self.act = F.gelu\n",
    "        self.dropout = nn.Dropout(configs.dropout)\n",
    "        self.projection = nn.Linear(\n",
    "            configs.d_model * configs.seq_len, configs.num_classes)\n",
    "\n",
    "    def classification(self, x_enc, x_mark_enc):\n",
    "        # embedding\n",
    "        enc_out = self.enc_embedding(x_enc, None)  # [B,T,C]\n",
    "        # TimesNet\n",
    "        for i in range(self.layer):\n",
    "            enc_out = self.layer_norm(self.model[i](enc_out))\n",
    "\n",
    "        # Output\n",
    "        # the output transformer encoder/decoder embeddings don't include non-linearity\n",
    "        output = self.act(enc_out)\n",
    "        output = self.dropout(output)\n",
    "        # zero-out padding embeddings\n",
    "        output = output * x_mark_enc.unsqueeze(-1)\n",
    "        # (batch_size, seq_length * d_model)\n",
    "        output = output.reshape(output.shape[0], -1)\n",
    "        output = self.projection(output)  # (batch_size, num_classes)\n",
    "        return output\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc, x_dec=None, x_mark_dec=None, mask=None):\n",
    "        dec_out = self.classification(x_enc, x_mark_enc)\n",
    "        return dec_out  # [B, N]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimesNetModel(\n",
       "  (model): ModuleList(\n",
       "    (0-2): 3 x TimesBlock(\n",
       "      (conv): Sequential(\n",
       "        (0): Inception_Block_V1(\n",
       "          (kernels): ModuleList(\n",
       "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "            (3): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "            (4): Conv2d(64, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4))\n",
       "            (5): Conv2d(64, 64, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5))\n",
       "          )\n",
       "        )\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Inception_Block_V1(\n",
       "          (kernels): ModuleList(\n",
       "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "            (3): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "            (4): Conv2d(64, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4))\n",
       "            (5): Conv2d(64, 64, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (enc_embedding): DataEmbedding(\n",
       "    (value_embedding): TokenEmbedding(\n",
       "      (tokenConv): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n",
       "    )\n",
       "    (position_embedding): PositionalEmbedding()\n",
       "    (temporal_embedding): TimeFeatureEmbedding(\n",
       "      (embed): Linear(in_features=4, out_features=64, bias=False)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (projection): Linear(in_features=35904, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TimesNetModel(configs=args)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.normalize_way == 'single':\n",
    "    x_train = normalize(x_train)\n",
    "    x_test = normalize(x_test)\n",
    "\n",
    "train_set = HARDataset(torch.from_numpy(x_train).type(torch.FloatTensor).to(device).permute(0,2,1),\n",
    "                        torch.from_numpy(y_train).type(torch.FloatTensor).to(device).to(torch.int64))\n",
    "test_set = HARDataset(torch.from_numpy(x_test).type(torch.FloatTensor).to(device).permute(0,2,1),\n",
    "                        torch.from_numpy(y_test).type(torch.FloatTensor).to(device).to(torch.int64))\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=args.batch_size, num_workers=0, drop_last=True, collate_fn=lambda x: collate_fn(x, device, max_len=args.seq_len))\n",
    "test_loader = DataLoader(test_set, batch_size=args.batch_size, num_workers=0, collate_fn=lambda x: collate_fn(x, device, max_len=args.seq_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "model_init_state = model.state_dict()\n",
    "\n",
    "if args.optimizer == 'adam':\n",
    "    optimizer = torch.optim.Adam([{'params': model.parameters()}],\n",
    "                                    lr=args.lr, weight_decay=args.weight_decay)\n",
    "elif args.optimizer == 'sgd':\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "\n",
    "losses = []\n",
    "test_accuracies = []\n",
    "train_time = 0.0\n",
    "end_val_epochs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Program Files\\Anaconda\\envs\\py310\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15: 100%|██████████| 919/919 [01:57<00:00,  7.80batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 27.233834809398747 , Train accuracy : 0.1328890025615692\n",
      "Learning rate after epoch 0: 0.01\n",
      "Epoch 2/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15: 100%|██████████| 919/919 [01:54<00:00,  8.05batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 11.207597706548071 , Train accuracy : 0.1380576640367508\n",
      "Learning rate after epoch 1: 0.01\n",
      "Epoch 3/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15: 100%|██████████| 919/919 [01:54<00:00,  8.01batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 30.650414207608353 , Train accuracy : 0.1373775750398636\n",
      "Learning rate after epoch 2: 0.01\n",
      "Epoch 4/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15: 100%|██████████| 919/919 [01:57<00:00,  7.81batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.8983251967419736 , Train accuracy : 0.33093035221099854\n",
      "Learning rate after epoch 3: 0.01\n",
      "Epoch 5/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15: 100%|██████████| 919/919 [01:58<00:00,  7.76batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 24.822907256924655 , Train accuracy : 0.4443688690662384\n",
      "Learning rate after epoch 4: 0.01\n",
      "Epoch 6/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15:  33%|███▎      | 305/919 [00:39<01:19,  7.76batch/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 46\u001b[0m\n\u001b[0;32m     43\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Accumulate training loss and accuracy\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m epoch_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mstep_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m epoch_train_acc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(torch\u001b[38;5;241m.\u001b[39margmax(pred\u001b[38;5;241m.\u001b[39mdata, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m y) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(y)\n\u001b[0;32m     49\u001b[0m num_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "model.load_state_dict(model_init_state)\n",
    "# Define optimizer and scheduler\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2)\n",
    "\n",
    "train_loss = []\n",
    "train_accuracy = []\n",
    "num_steps = args.epoch // args.batch_size\n",
    "\n",
    "last_loss = float('inf')\n",
    "stop_count = 0\n",
    "increase_count = 0\n",
    "\n",
    "num_steps = train_set.__len__() // args.batch_size\n",
    "\n",
    "min_val_loss = float('inf')\n",
    "test_accuracy = 0\n",
    "end_val_epoch = 0\n",
    "\n",
    "for epoch in range(args.epoch):\n",
    "    print('Epoch {}/{}'.format(epoch + 1, args.epoch))\n",
    "\n",
    "    epoch_train_loss = 0\n",
    "    epoch_train_acc = 0\n",
    "    num_iterations = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    with tqdm(total=len(train_loader), desc=f\"Epoch {epoch+1}/{args.epoch}\", unit=\"batch\") as pbar:\n",
    "        for x, y, padding_x_mask in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            pred = model(x, padding_x_mask)\n",
    "            step_loss = loss(pred, y)\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            step_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate training loss and accuracy\n",
    "            epoch_train_loss += step_loss.item()\n",
    "            epoch_train_acc += torch.sum(torch.argmax(pred.data, axis=1) == y) / len(y)\n",
    "\n",
    "            num_iterations += 1\n",
    "            pbar.update(1)  # Update progress bar for each batch\n",
    "\n",
    "    # Average train loss and accuracy over all steps\n",
    "    epoch_train_loss /= num_steps\n",
    "    epoch_train_acc /= num_steps\n",
    "\n",
    "    # Adjust learning rate based on training loss\n",
    "    scheduler.step(epoch_train_loss)\n",
    "\n",
    "    print(\"Train loss: {} , Train accuracy : {}\".format(epoch_train_loss, epoch_train_acc))\n",
    "    print(\"Learning rate after epoch {}: {}\".format(epoch, optimizer.param_groups[0]['lr']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.7468, Test Accuracy: 0.6763\n",
      "Final Test Loss: 0.7468, Final Test Accuracy: 0.6763\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchmetrics\n",
    "from torchmetrics import Accuracy, F1Score, Precision, Recall, ConfusionMatrix, AUROC\n",
    "\n",
    "# Initialize metrics\n",
    "accuracy_metric = Accuracy().to(device)\n",
    "f1_score_metric = F1Score(average='macro', num_classes=args.num_classes).to(device)\n",
    "precision_metric = Precision(average='macro', num_classes=args.num_classes).to(device)\n",
    "recall_metric = Recall(average='macro', num_classes=args.num_classes).to(device)\n",
    "confusion_matrix_metric = ConfusionMatrix(num_classes=args.num_classes).to(device)\n",
    "auroc_metric = AUROC(num_classes=args.num_classes).to(device)\n",
    "\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "test_loss = 0\n",
    "\n",
    "with torch.no_grad():  # No need to compute gradients for evaluation\n",
    "    for x, y, padding_x_mask in test_loader:\n",
    "        # Move inputs and targets to the correct device\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        # Forward pass: compute predicted outputs by passing inputs to the model\n",
    "        pred = model(x, padding_x_mask)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = loss(pred, y)\n",
    "        test_loss += loss.item()  # Accumulate loss\n",
    "\n",
    "        # Update metrics\n",
    "        accuracy_metric.update(pred, y)\n",
    "        f1_score_metric.update(pred, y)\n",
    "        precision_metric.update(pred, y)\n",
    "        recall_metric.update(pred, y)\n",
    "        confusion_matrix_metric.update(pred, y)\n",
    "        auroc_metric.update(pred, y)\n",
    "\n",
    "# Compute average test loss and finalize metrics\n",
    "test_loss /= len(test_loader)\n",
    "test_accuracy = accuracy_metric.compute().item()\n",
    "test_f1_score = f1_score_metric.compute().item()\n",
    "test_precision = precision_metric.compute().item()\n",
    "test_recall = recall_metric.compute().item()\n",
    "test_confusion_matrix = confusion_matrix_metric.compute().cpu().numpy()\n",
    "test_auroc = auroc_metric.compute().item()\n",
    "\n",
    "# Reset metrics for future evaluations\n",
    "accuracy_metric.reset()\n",
    "f1_score_metric.reset()\n",
    "precision_metric.reset()\n",
    "recall_metric.reset()\n",
    "confusion_matrix_metric.reset()\n",
    "auroc_metric.reset()\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}, Test F1 Score: {test_f1_score:.4f} Test Precision: {test_precision:.4f}, Test Recall: {test_recall:.4f}, Test Confusion Matrix: {test_confusion_matrix}, Test AUROC: {test_auroc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
