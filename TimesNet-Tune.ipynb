{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.fft\n",
    "import ray\n",
    "import random\n",
    "from ray import tune, train\n",
    "from ray.train import Checkpoint\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance\n",
    "from tqdm import tqdm\n",
    "from torchmetrics.classification import (\n",
    "    MulticlassAccuracy, MulticlassF1Score, MulticlassPrecision, MulticlassRecall,\n",
    "    MulticlassConfusionMatrix, MulticlassROC\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_labels(labels):\n",
    "    indicies = np.unique(labels)\n",
    "    num_samples = labels.shape[0]\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        new_label = np.argwhere(labels[i] == indicies)[0][0]\n",
    "        labels[i] = new_label\n",
    "\n",
    "    return labels\n",
    "\n",
    "def collate_fn(data, device, max_len=None):\n",
    "    \"\"\"Build mini-batch tensors from a list of (X, mask) tuples. Mask input. Create\n",
    "    Args:\n",
    "        data: len(batch_size) list of tuples (X, y).\n",
    "            - X: torch tensor of shape (seq_length, feat_dim); variable seq_length.\n",
    "            - y: torch tensor of shape (num_labels,) : class indices or numerical targets\n",
    "                (for classification or regression, respectively). num_labels > 1 for multi-task models\n",
    "        max_len: global fixed sequence length. Used for architectures requiring fixed length input,\n",
    "            where the batch length cannot vary dynamically. Longer sequences are clipped, shorter are padded with 0s\n",
    "    Returns:\n",
    "        X: (batch_size, padded_length, feat_dim) torch tensor of masked features (input)\n",
    "        targets: (batch_size, padded_length, feat_dim) torch tensor of unmasked features (output)\n",
    "        target_masks: (batch_size, padded_length, feat_dim) boolean torch tensor\n",
    "            0 indicates masked values to be predicted, 1 indicates unaffected/\"active\" feature values\n",
    "        padding_masks: (batch_size, padded_length) boolean tensor, 1 means keep vector at this position, 0 means padding\n",
    "    \"\"\"\n",
    "\n",
    "    batch_size = len(data)\n",
    "    features, labels = zip(*data)\n",
    "\n",
    "    # Stack and pad features and masks (convert 2D to 3D tensors, i.e. add batch dimension)\n",
    "    lengths = [X.shape[0] for X in features]  # original sequence length for each time series\n",
    "    if max_len is None:\n",
    "        max_len = max(lengths)\n",
    "\n",
    "    X = torch.zeros(batch_size, max_len, features[0].shape[-1])  # (batch_size, padded_length, feat_dim)\n",
    "    for i in range(batch_size):\n",
    "        end = min(lengths[i], max_len)\n",
    "        X[i, :end, :] = features[i][:end, :]\n",
    "\n",
    "    targets = torch.stack(labels, dim=0)  # (batch_size, num_labels)\n",
    "\n",
    "    padding_masks = padding_mask(torch.tensor(lengths, dtype=torch.int16),\n",
    "                                 max_len=max_len)  # (batch_size, padded_length) boolean tensor, \"1\" means keep\n",
    "\n",
    "    return X.to(device), targets.to(device), padding_masks.to(device)\n",
    "\n",
    "\n",
    "def padding_mask(lengths, max_len=None):\n",
    "    \"\"\"\n",
    "    Used to mask padded positions: creates a (batch_size, max_len) boolean mask from a tensor of sequence lengths,\n",
    "    where 1 means keep element at this position (time step)\n",
    "    \"\"\"\n",
    "    batch_size = lengths.numel()\n",
    "    max_len = max_len or lengths.max_val()  # trick works because of overloading of 'or' operator for non-boolean types\n",
    "    return (torch.arange(0, max_len, device=lengths.device)\n",
    "            .type_as(lengths)\n",
    "            .repeat(batch_size, 1)\n",
    "            .lt(lengths.unsqueeze(1)))\n",
    "\n",
    "def set_seed(args):\n",
    "    random.seed(args.random_seed)\n",
    "    np.random.seed(args.random_seed)\n",
    "    torch.manual_seed(args.random_seed)\n",
    "    torch.cuda.manual_seed(args.random_seed)\n",
    "    torch.cuda.manual_seed_all(args.random_seed)\n",
    "\n",
    "\n",
    "class HARDataset(Dataset):\n",
    "    def __init__(self, dataset, target):\n",
    "        # (num_size, num_dimensions, series_length)\n",
    "        self.dataset = dataset.permute(0, 2, 1)\n",
    "        self.target = target\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.dataset[index], self.target[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target)\n",
    "    \n",
    "def normalize(data_set):\n",
    "    '''\n",
    "    The function is the same as normalize_per_series, but can be used for multiple variables.\n",
    "    '''\n",
    "    return TimeSeriesScalerMeanVariance().fit_transform(data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arg_parse():  \n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Base setup\n",
    "    parser.add_argument('--random_seed', type=int, default=42, help='shuffle seed')\n",
    "\n",
    "    # Dataset setup\n",
    "    parser.add_argument('--dataset', type=str, default='UCI-HAR', help='dataset name [UCI-HAR, mHealth, PAMAP2]')\n",
    "    parser.add_argument('--num_classes', type=int, default=0, help='number of class')\n",
    "    parser.add_argument('--normalize_way', type=str, default='single', help='single or train_set')\n",
    "    parser.add_argument('--input_size', type=int, default=1, help='input_size')\n",
    "\n",
    "    # basic config\n",
    "    parser.add_argument('--freq', type=str, default='h',\n",
    "                        help='freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h')\n",
    "\n",
    "    # forecasting task\n",
    "    parser.add_argument('--seq_len', type=int, default=96, help='input sequence length')\n",
    "    parser.add_argument('--pred_len', type=int, default=0, help='prediction sequence length')\n",
    "\n",
    "    # model define\n",
    "    parser.add_argument('--top_k', type=int, default=3, help='for TimesBlock')\n",
    "    parser.add_argument('--num_kernels', type=int, default=6, help='for Inception')\n",
    "    parser.add_argument('--enc_in', type=int, default=7, help='encoder input size')\n",
    "    parser.add_argument('--c_out', type=int, default=7, help='output size')\n",
    "    parser.add_argument('--d_model', type=int, default=64, help='dimension of model')   ###\n",
    "    parser.add_argument('--n_heads', type=int, default=8, help='num of heads')\n",
    "    parser.add_argument('--e_layers', type=int, default=3, help='num of encoder layers')\n",
    "    parser.add_argument('--d_ff', type=int, default=64, help='dimension of fcn')\n",
    "    parser.add_argument('--dropout', type=float, default=0.1, help='dropout')\n",
    "    parser.add_argument('--embed', type=str, default='timeF', help='time features encoding, options:[timeF, fixed, learned]')\n",
    "    parser.add_argument('--att_loc', type=str, default='none', help='attention location, options:[block, model, none]')\n",
    "\n",
    "    # GPU\n",
    "    parser.add_argument('--gpu', type=int, default=1, help='gpu')\n",
    "\n",
    "\n",
    "    # training setup\n",
    "    parser.add_argument('--optimizer', type=str, default='adam', help='optimizer')\n",
    "    parser.add_argument('--lr', type=float, default=0.001, help='learning rate')\n",
    "    parser.add_argument('--weight_decay', type=float, default=0.0, help='weight decay')\n",
    "    parser.add_argument('--batch_size', type=int, default=8, help='')\n",
    "    parser.add_argument('--epoch', type=int, default=50, help='training epoch')\n",
    "    parser.add_argument('--device', type=str, default='cuda', help='device')\n",
    "\n",
    "\n",
    "    args = parser.parse_args(args=[])\n",
    "\n",
    "    args.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    set_seed(args)\n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_UCI(args):\n",
    "    train = pd.read_csv('/home/rifki/research/Kuliah/har-timesnet/dataset/UCI-HAR-Dataset/train.csv')\n",
    "    test = pd.read_csv('/home/rifki/research/Kuliah/har-timesnet/dataset/UCI-HAR-Dataset/test.csv')\n",
    "\n",
    "    train = train.drop('subject', axis=1)\n",
    "    test = test.drop('subject', axis=1)\n",
    "\n",
    "    labelNames = list(np.unique(train['Activity']))\n",
    "    labelNames.sort()\n",
    "    train['Activity'] = train['Activity'].apply(lambda x: labelNames.index(x))\n",
    "    test['Activity'] = test['Activity'].apply(lambda x: labelNames.index(x))\n",
    "    # Existing training and test data\n",
    "    x_train = train.iloc[:, :-1].to_numpy(dtype=np.float32)\n",
    "    y_train = train.iloc[:, -1].to_numpy(dtype=np.float32)\n",
    "\n",
    "    x_test = test.iloc[:, :-1].to_numpy(dtype=np.float32)\n",
    "    y_test = test.iloc[:, -1].to_numpy(dtype=np.float32)\n",
    "\n",
    "    # Define the number of classes\n",
    "    num_classes = len(np.unique(y_train))\n",
    "\n",
    "    x_train = x_train[:, :, np.newaxis]\n",
    "    x_test = x_test[:, :, np.newaxis]\n",
    "\n",
    "    args.num_classes = num_classes\n",
    "    args.seq_len = x_train.shape[1]\n",
    "    args.input_size = x_train.shape[2]\n",
    "\n",
    "    args.enc_in = x_train.shape[2]\n",
    "\n",
    "    while x_train.shape[0] * 0.6 < args.batch_size:\n",
    "        args.batch_size = args.batch_size // 2\n",
    "\n",
    "    if args.normalize_way == 'single':\n",
    "        x_train = normalize(x_train)\n",
    "        x_test = normalize(x_test)\n",
    "\n",
    "    # Convert numpy arrays to tensors and create the datasets\n",
    "    train_set = HARDataset(torch.from_numpy(x_train).type(torch.FloatTensor).to(args.device).permute(0,2,1), torch.from_numpy(y_train).type(torch.FloatTensor).to(args.device).to(torch.int64))\n",
    "    test_set = HARDataset(torch.from_numpy(x_test).type(torch.FloatTensor).to(args.device).permute(0,2,1), torch.from_numpy(y_test).type(torch.FloatTensor).to(args.device).to(torch.int64))\n",
    "\n",
    "    # Create DataLoaders for training, validation, and testing sets\n",
    "    train_loader = DataLoader(train_set, batch_size=args.batch_size, num_workers=0, drop_last=True, \n",
    "                            collate_fn=lambda x: collate_fn(x, args.device, max_len=args.seq_len))\n",
    "    test_loader = DataLoader(test_set, batch_size=args.batch_size, num_workers=0, \n",
    "                            collate_fn=lambda x: collate_fn(x, args.device, max_len=args.seq_len))\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Inception_Block_V1(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_kernels=6, init_weight=True):\n",
    "        super(Inception_Block_V1, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.num_kernels = num_kernels\n",
    "        kernels = []\n",
    "        for i in range(self.num_kernels):\n",
    "            kernels.append(nn.Conv2d(in_channels, out_channels, kernel_size=2 * i + 1, padding=i))\n",
    "        self.kernels = nn.ModuleList(kernels)\n",
    "        if init_weight:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res_list = []\n",
    "        for i in range(self.num_kernels):\n",
    "            res_list.append(self.kernels[i](x))\n",
    "        res = torch.stack(res_list, dim=-1).mean(-1)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=25000):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)]\n",
    "\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        padding = 1 if torch.__version__ >= '1.5.0' else 2\n",
    "        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model,\n",
    "                                   kernel_size=3, padding=padding, padding_mode='circular', bias=False)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FixedEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(FixedEmbedding, self).__init__()\n",
    "\n",
    "        w = torch.zeros(c_in, d_model).float()\n",
    "        w.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, c_in).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        w[:, 0::2] = torch.sin(position * div_term)\n",
    "        w[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.emb = nn.Embedding(c_in, d_model)\n",
    "        self.emb.weight = nn.Parameter(w, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.emb(x).detach()\n",
    "\n",
    "\n",
    "class TemporalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='fixed', freq='h'):\n",
    "        super(TemporalEmbedding, self).__init__()\n",
    "\n",
    "        minute_size = 4\n",
    "        hour_size = 24\n",
    "        weekday_size = 7\n",
    "        day_size = 32\n",
    "        month_size = 13\n",
    "\n",
    "        Embed = FixedEmbedding if embed_type == 'fixed' else nn.Embedding\n",
    "        if freq == 't':\n",
    "            self.minute_embed = Embed(minute_size, d_model)\n",
    "        self.hour_embed = Embed(hour_size, d_model)\n",
    "        self.weekday_embed = Embed(weekday_size, d_model)\n",
    "        self.day_embed = Embed(day_size, d_model)\n",
    "        self.month_embed = Embed(month_size, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.long()\n",
    "        minute_x = self.minute_embed(x[:, :, 4]) if hasattr(\n",
    "            self, 'minute_embed') else 0.\n",
    "        hour_x = self.hour_embed(x[:, :, 3])\n",
    "        weekday_x = self.weekday_embed(x[:, :, 2])\n",
    "        day_x = self.day_embed(x[:, :, 1])\n",
    "        month_x = self.month_embed(x[:, :, 0])\n",
    "\n",
    "        return hour_x + weekday_x + day_x + month_x + minute_x\n",
    "\n",
    "\n",
    "class TimeFeatureEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='timeF', freq='h'):\n",
    "        super(TimeFeatureEmbedding, self).__init__()\n",
    "\n",
    "        freq_map = {'h': 4, 't': 5, 's': 6,\n",
    "                    'm': 1, 'a': 1, 'w': 2, 'd': 3, 'b': 3}\n",
    "        d_inp = freq_map[freq]\n",
    "        self.embed = nn.Linear(d_inp, d_model, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)\n",
    "\n",
    "\n",
    "class DataEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
    "        super(DataEmbedding, self).__init__()\n",
    "\n",
    "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
    "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
    "        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n",
    "                                                    freq=freq) if embed_type != 'timeF' else TimeFeatureEmbedding(\n",
    "            d_model=d_model, embed_type=embed_type, freq=freq)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, x_mark):\n",
    "        if x_mark is None:\n",
    "            x = self.value_embedding(x) + self.position_embedding(x)\n",
    "        else:\n",
    "            x = self.value_embedding(\n",
    "                x) + self.temporal_embedding(x_mark) + self.position_embedding(x)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FFT_for_Period(x, k=2):\n",
    "    # [B, T, C]\n",
    "    xf = torch.fft.rfft(x, dim=1)\n",
    "    # find period by amplitudes\n",
    "    frequency_list = abs(xf).mean(0).mean(-1)\n",
    "    frequency_list[0] = 0\n",
    "    _, top_list = torch.topk(frequency_list, k)\n",
    "    top_list = top_list.detach().cpu().numpy()\n",
    "    period = x.shape[1] // top_list\n",
    "\n",
    "    # print(\"period.shape = \", period.shape, top_list.shape, top_list, period)\n",
    "    return period, abs(xf).mean(-1)[:, top_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TimesBlock + Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimesBlockAtt(nn.Module):\n",
    "    def __init__(self, configs):\n",
    "        super(TimesBlockAtt, self).__init__()\n",
    "        self.seq_len = configs.seq_len\n",
    "        self.pred_len = configs.pred_len\n",
    "        self.k = configs.top_k\n",
    "        self.d_model = configs.d_model\n",
    "        self.num_heads = configs.n_heads\n",
    "\n",
    "        # Parameter-efficient design\n",
    "        self.conv = nn.Sequential(\n",
    "            Inception_Block_V1(configs.d_model, configs.d_ff,\n",
    "                               num_kernels=configs.num_kernels),\n",
    "            nn.GELU(),\n",
    "            Inception_Block_V1(configs.d_ff, configs.d_model,\n",
    "                               num_kernels=configs.num_kernels)\n",
    "        )\n",
    "\n",
    "        # Self-attention layer\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=self.d_model, num_heads=self.num_heads, dropout=configs.dropout)\n",
    "        self.layer_norm = nn.LayerNorm(self.d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, N = x.size()\n",
    "        period_list, period_weight = FFT_for_Period(x, self.k)\n",
    "\n",
    "        res = []\n",
    "        for i in range(self.k):\n",
    "            period = period_list[i]\n",
    "            # Padding\n",
    "            if (self.seq_len + self.pred_len) % period != 0:\n",
    "                length = (\n",
    "                    ((self.seq_len + self.pred_len) // period) + 1) * period\n",
    "                padding = torch.zeros([x.shape[0], (length - (self.seq_len + self.pred_len)), x.shape[2]]).to(x.device)\n",
    "                out = torch.cat([x, padding], dim=1)\n",
    "            else:\n",
    "                length = (self.seq_len + self.pred_len)\n",
    "                out = x\n",
    "\n",
    "            # Reshape\n",
    "            out = out.reshape(B, length // period, period,\n",
    "                      N).permute(0, 3, 1, 2).contiguous()\n",
    "            out = self.conv(out)\n",
    "\n",
    "            # Reshape back\n",
    "            out = out.permute(0, 2, 3, 1).reshape(B, -1, N)\n",
    "            res.append(out[:, :(self.seq_len + self.pred_len), :])\n",
    "\n",
    "        res = torch.stack(res, dim=-1)\n",
    "\n",
    "        # Adaptive aggregation\n",
    "        period_weight = F.softmax(period_weight, dim=1)\n",
    "        period_weight = period_weight.unsqueeze(1).unsqueeze(1).repeat(1, T, N, 1)\n",
    "        res = torch.sum(res * period_weight, -1)\n",
    "\n",
    "        # Self-attention\n",
    "        res = res.permute(1, 0, 2)  # Prepare for attention [T, B, N]\n",
    "        attn_out, _ = self.attention(res, res, res)\n",
    "        res = self.layer_norm(res + attn_out)  # Residual connection + LayerNorm\n",
    "        res = res.permute(1, 0, 2)  # Back to [B, T, N]\n",
    "\n",
    "        # Residual connection\n",
    "        res = res + x\n",
    "        return res\n",
    "\n",
    "\n",
    "class TimesNetAttBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Paper link: https://openreview.net/pdf?id=ju_Uqw384Oq\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, configs):\n",
    "        super(TimesNetAttBlock, self).__init__()\n",
    "        self.configs = configs\n",
    "        self.model = nn.ModuleList([TimesBlockAtt(configs) for _ in range(configs.e_layers)])\n",
    "        self.enc_embedding = DataEmbedding(configs.enc_in, configs.d_model, configs.embed, configs.freq, configs.dropout)\n",
    "        self.layer = configs.e_layers\n",
    "        self.layer_norm = nn.LayerNorm(configs.d_model)\n",
    "        self.act = nn.GELU()\n",
    "        self.dropout = nn.Dropout(configs.dropout)\n",
    "\n",
    "        # Output projection layer\n",
    "        self.projection = nn.Linear(configs.d_model * configs.seq_len, configs.num_classes)\n",
    "\n",
    "    def classification(self, x_enc, x_mark_enc):\n",
    "        # Embedding\n",
    "        enc_out = self.enc_embedding(x_enc, None)  # [B, T, C]\n",
    "\n",
    "        # TimesNet Blocks\n",
    "        for i in range(self.layer):\n",
    "            enc_out = self.layer_norm(self.model[i](enc_out))\n",
    "\n",
    "        # Output processing\n",
    "        output = self.act(enc_out)\n",
    "        output = self.dropout(output)\n",
    "        output = output * x_mark_enc.unsqueeze(-1)\n",
    "        output = output.reshape(output.shape[0], -1)\n",
    "        output = self.projection(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc, x_dec=None, x_mark_dec=None, mask=None):\n",
    "        dec_out = self.classification(x_enc, x_mark_enc)\n",
    "        return dec_out  # [B, N]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TimesNet + Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimesBlockBase(nn.Module):\n",
    "    def __init__(self, configs):\n",
    "        super(TimesBlockBase, self).__init__()\n",
    "        self.seq_len = configs.seq_len\n",
    "        self.pred_len = configs.pred_len\n",
    "        self.k = configs.top_k\n",
    "        # parameter-efficient design\n",
    "        self.conv = nn.Sequential(\n",
    "            Inception_Block_V1(configs.d_model, configs.d_ff,\n",
    "                               num_kernels=configs.num_kernels),\n",
    "            nn.GELU(),\n",
    "            Inception_Block_V1(configs.d_ff, configs.d_model,\n",
    "                               num_kernels=configs.num_kernels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(\"Input shape:\", x.shape)\n",
    "        B, T, N = x.size()\n",
    "        period_list, period_weight = FFT_for_Period(x, self.k)\n",
    "\n",
    "        res = []\n",
    "        for i in range(self.k):\n",
    "            period = period_list[i]\n",
    "            # padding\n",
    "            if (self.seq_len + self.pred_len) % period != 0:\n",
    "                length = (((self.seq_len + self.pred_len) // period) + 1) * period\n",
    "\n",
    "                # print(\"length = \", length, self.seq_len, self.pred_len, period)\n",
    "                padding = torch.zeros([x.shape[0], (length - (self.seq_len + self.pred_len)), x.shape[2]]).to(x.device)\n",
    "\n",
    "                # print(\"padding x shape = \", padding.shape, x.shape)\n",
    "                out = torch.cat([x, padding], dim=1)\n",
    "                # print(\"padding out shape = \", out.shape)\n",
    "            else:\n",
    "                length = (self.seq_len + self.pred_len)\n",
    "                out = x\n",
    "\n",
    "            # print(\"out.shape = \", out.shape, length, period, length // period, N )\n",
    "            # reshape\n",
    "            out = out.reshape(B, length // period, period,\n",
    "                              N).permute(0, 3, 1, 2).contiguous()\n",
    "            # 2D conv: from 1d Variation to 2d Variation\n",
    "            out = self.conv(out)\n",
    "            # reshape back\n",
    "            out = out.permute(0, 2, 3, 1).reshape(B, -1, N)\n",
    "            res.append(out[:, :(self.seq_len + self.pred_len), :])\n",
    "        res = torch.stack(res, dim=-1)\n",
    "        # adaptive aggregation\n",
    "        period_weight = F.softmax(period_weight, dim=1)\n",
    "        period_weight = period_weight.unsqueeze(\n",
    "            1).unsqueeze(1).repeat(1, T, N, 1)\n",
    "        res = torch.sum(res * period_weight, -1)\n",
    "        # residual connection\n",
    "        res = res + x\n",
    "        return res\n",
    "\n",
    "\n",
    "class TimesNetAttModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Paper link: https://openreview.net/pdf?id=ju_Uqw384Oq\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, configs):\n",
    "        super(TimesNetAttModel, self).__init__()\n",
    "        self.configs = configs\n",
    "        self.model = nn.ModuleList([TimesBlockBase(configs) for _ in range(configs.e_layers)])\n",
    "        self.enc_embedding = DataEmbedding(configs.enc_in, configs.d_model, configs.embed, configs.freq, configs.dropout)\n",
    "        self.layer = configs.e_layers\n",
    "        self.layer_norm = nn.LayerNorm(configs.d_model)\n",
    "        self.act = nn.GELU()\n",
    "        self.dropout = nn.Dropout(configs.dropout)\n",
    "\n",
    "        # Define self-attention layer\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=configs.d_model, num_heads=configs.n_heads, dropout=configs.dropout)\n",
    "\n",
    "        self.projection = nn.Linear(configs.d_model * configs.seq_len, configs.num_classes)\n",
    "\n",
    "\n",
    "    def classification(self, x_enc, x_mark_enc):\n",
    "        # Embedding\n",
    "        enc_out = self.enc_embedding(x_enc, None)  # [B, T, C]\n",
    "\n",
    "        # TimesNet Blocks\n",
    "        for i in range(self.layer):\n",
    "            enc_out = self.layer_norm(self.model[i](enc_out))\n",
    "\n",
    "        # Prepare for attention: [T, B, C]\n",
    "        enc_out = enc_out.permute(1, 0, 2)\n",
    "\n",
    "        # Apply self-attention\n",
    "        attn_out, _ = self.attention(enc_out, enc_out, enc_out)\n",
    "\n",
    "        # Residual connection and layer normalization\n",
    "        enc_out = self.layer_norm(enc_out + attn_out)\n",
    "\n",
    "        # Reshape back: [B, T, C]\n",
    "        enc_out = enc_out.permute(1, 0, 2)\n",
    "\n",
    "        # Output processing remains the same\n",
    "        output = self.act(enc_out)\n",
    "        output = self.dropout(output)\n",
    "        output = output * x_mark_enc.unsqueeze(-1)\n",
    "        output = output.reshape(output.shape[0], -1)\n",
    "        output = self.projection(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc, x_dec=None, x_mark_dec=None, mask=None):\n",
    "        dec_out = self.classification(x_enc, x_mark_enc)\n",
    "        return dec_out  # [B, N]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimesBlock(nn.Module):\n",
    "    def __init__(self, configs):\n",
    "        super(TimesBlock, self).__init__()\n",
    "        self.seq_len = configs.seq_len\n",
    "        self.pred_len = configs.pred_len\n",
    "        self.k = configs.top_k\n",
    "        self.d_model = configs.d_model\n",
    "        self.num_heads = configs.n_heads\n",
    "        self.att_loc  = configs.att_loc\n",
    "\n",
    "        # Parameter-efficient design\n",
    "        self.conv = nn.Sequential(\n",
    "            Inception_Block_V1(configs.d_model, configs.d_ff,\n",
    "                               num_kernels=configs.num_kernels),\n",
    "            nn.GELU(),\n",
    "            Inception_Block_V1(configs.d_ff, configs.d_model,\n",
    "                               num_kernels=configs.num_kernels)\n",
    "        )\n",
    "\n",
    "        # Self-attention layer\n",
    "        if self.att_loc == 'block':\n",
    "            self.attention = nn.MultiheadAttention(embed_dim=self.d_model, num_heads=self.num_heads, dropout=configs.dropout)\n",
    "            self.layer_norm = nn.LayerNorm(self.d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, N = x.size()\n",
    "        period_list, period_weight = FFT_for_Period(x, self.k)\n",
    "\n",
    "        res = []\n",
    "        for i in range(self.k):\n",
    "            period = period_list[i]\n",
    "            # Padding\n",
    "            if (self.seq_len + self.pred_len) % period != 0:\n",
    "                length = (((self.seq_len + self.pred_len) // period) + 1) * period\n",
    "\n",
    "                padding = torch.zeros([x.shape[0], (length - (self.seq_len + self.pred_len)), x.shape[2]]).to(x.device)\n",
    "\n",
    "                out = torch.cat([x, padding], dim=1)\n",
    "            else:\n",
    "                length = (self.seq_len + self.pred_len)\n",
    "                out = x\n",
    "\n",
    "            # Reshape\n",
    "            out = out.reshape(B, length // period, period,\n",
    "                              N).permute(0, 3, 1, 2).contiguous()\n",
    "            out = self.conv(out)\n",
    "\n",
    "            # Reshape back\n",
    "            out = out.permute(0, 2, 3, 1).reshape(B, -1, N)\n",
    "            res.append(out[:, :(self.seq_len + self.pred_len), :])\n",
    "\n",
    "        res = torch.stack(res, dim=-1)\n",
    "\n",
    "        # Adaptive aggregation\n",
    "        period_weight = F.softmax(period_weight, dim=1)\n",
    "        period_weight = period_weight.unsqueeze(1).unsqueeze(1).repeat(1, T, N, 1)\n",
    "        res = torch.sum(res * period_weight, -1)\n",
    "\n",
    "        # Self-attention\n",
    "\n",
    "        if self.att_loc == 'block':\n",
    "            res = res.permute(1, 0, 2)  # Prepare for attention [T, B, N]\n",
    "            attn_out, _ = self.attention(res, res, res)\n",
    "            res = self.layer_norm(res + attn_out)  # Residual connection + LayerNorm\n",
    "            res = res.permute(1, 0, 2)  # Back to [B, T, N]\n",
    "\n",
    "        # Residual connection\n",
    "        res = res + x\n",
    "        return res\n",
    "\n",
    "\n",
    "class TimesNetModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Paper link: https://openreview.net/pdf?id=ju_Uqw384Oq\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, configs):\n",
    "        super(TimesNetModel, self).__init__()\n",
    "        self.configs = configs\n",
    "        self.model = nn.ModuleList([TimesBlock(configs) for _ in range(configs.e_layers)])\n",
    "        self.enc_embedding = DataEmbedding(configs.enc_in, configs.d_model, configs.embed, configs.freq, configs.dropout)\n",
    "        self.layer = configs.e_layers\n",
    "        self.layer_norm = nn.LayerNorm(configs.d_model)\n",
    "        self.act = nn.GELU()\n",
    "        self.dropout = nn.Dropout(configs.dropout)\n",
    "        self.att_loc = configs.att_loc\n",
    "    \n",
    "        # Define self-attention layer\n",
    "        if self.att_loc == 'model':\n",
    "            self.attention = nn.MultiheadAttention(embed_dim=configs.d_model, num_heads=configs.n_heads, dropout=configs.dropout)\n",
    "\n",
    "        self.projection = nn.Linear(configs.d_model * configs.seq_len, configs.num_classes)\n",
    "\n",
    "\n",
    "    def classification(self, x_enc, x_mark_enc):\n",
    "        # Embedding\n",
    "        enc_out = self.enc_embedding(x_enc, None)  # [B, T, C]\n",
    "\n",
    "        # TimesNet Blocks\n",
    "        for i in range(self.layer):\n",
    "            enc_out = self.layer_norm(self.model[i](enc_out))\n",
    "\n",
    "        \n",
    "        if self.att_loc == 'model':\n",
    "            # Prepare for attention: [T, B, C]\n",
    "            enc_out = enc_out.permute(1, 0, 2)\n",
    "\n",
    "            # Apply self-attention\n",
    "            attn_out, _ = self.attention(enc_out, enc_out, enc_out)\n",
    "\n",
    "            # Residual connection and layer normalization\n",
    "            enc_out = self.layer_norm(enc_out + attn_out)\n",
    "\n",
    "            # Reshape back: [B, T, C]\n",
    "            enc_out = enc_out.permute(1, 0, 2)\n",
    "\n",
    "        # Output processing remains the same\n",
    "        output = self.act(enc_out)\n",
    "        output = self.dropout(output)\n",
    "        output = output * x_mark_enc.unsqueeze(-1)\n",
    "        output = output.reshape(output.shape[0], -1)\n",
    "        output = self.projection(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc, x_dec=None, x_mark_dec=None, mask=None):\n",
    "        dec_out = self.classification(x_enc, x_mark_enc)\n",
    "        return dec_out  # [B, N]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(configs):\n",
    "    args = arg_parse()\n",
    "    # Initialize the model\n",
    "    for key, value in configs.items():\n",
    "        setattr(args, key, value)\n",
    "\n",
    "    # Load the dataset\n",
    "    train_loader, _ = load_UCI(args)\n",
    "\n",
    "    if args.att_loc == 'block':\n",
    "        model = TimesNetAttBlock(args)\n",
    "    else:\n",
    "        model = TimesNetAttModel(args)\n",
    "\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "    # Initialize accuracy metric\n",
    "    accuracy_metric = MulticlassAccuracy(num_classes=args.num_classes).to(device)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(args.epoch):\n",
    "        print(f\"Epoch {epoch + 1}/{args.epoch}\")\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        accuracy_metric.reset()\n",
    "        \n",
    "        for inputs, labels, padding_x_mask in tqdm(train_loader, disable=True):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs, padding_x_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate loss\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Update accuracy metric\n",
    "            accuracy_metric.update(outputs, labels)\n",
    "\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = accuracy_metric.compute().item()\n",
    "        print(f\"Training loss: {avg_train_loss:.4f}, Training accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # Report the loss and accuracy to Ray Tune\n",
    "        # Save the model and optimizer state\n",
    "        temp_checkpoint_dir = \"models/\"\n",
    "        if not os.path.exists(temp_checkpoint_dir):\n",
    "            os.makedirs(temp_checkpoint_dir)\n",
    "        \n",
    "        torch.save(\n",
    "            (model.state_dict(), optimizer.state_dict()), temp_checkpoint_dir + \"checkpoint.pt\"\n",
    "        )\n",
    "        checkpoint = Checkpoint.from_directory(temp_checkpoint_dir)\n",
    "        \n",
    "        train.report(\n",
    "            {\"loss\": avg_train_loss, \"accuracy\": train_accuracy},\n",
    "            checkpoint=checkpoint,\n",
    "        )\n",
    "    print(\"Finished Training\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchmetrics.classification import (\n",
    "    MulticlassAccuracy, MulticlassF1Score, MulticlassPrecision, MulticlassRecall,\n",
    "    MulticlassConfusionMatrix, MulticlassROC\n",
    ")\n",
    "import os\n",
    "\n",
    "def test_best_model(model, configs):\n",
    "    args = arg_parse()\n",
    "\n",
    "    for key, value in configs.items():\n",
    "        setattr(args, key, value)\n",
    "\n",
    "    _, test_loader = load_UCI(args)\n",
    "\n",
    "    # Initialize metrics\n",
    "    accuracy_metric = MulticlassAccuracy(num_classes=args.num_classes).to(args.device)\n",
    "    f1_score_metric = MulticlassF1Score(average='macro', num_classes=args.num_classes).to(args.device)\n",
    "    precision_metric = MulticlassPrecision(average='macro', num_classes=args.num_classes).to(args.device)\n",
    "    recall_metric = MulticlassRecall(average='macro', num_classes=args.num_classes).to(args.device)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Loss function\n",
    "    loss_func = torch.nn.CrossEntropyLoss().to(args.device)\n",
    "\n",
    "    # No need to compute gradients for evaluation\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y, padding_x_mask in test_loader:\n",
    "            x, y = x.to(args.device), y.to(args.device)\n",
    "            # Forward pass\n",
    "            pred = model(x, padding_x_mask)\n",
    "            loss = loss_func(pred, y)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Update metrics\n",
    "            accuracy_metric.update(pred, y)\n",
    "            f1_score_metric.update(pred, y)\n",
    "            precision_metric.update(pred, y)\n",
    "            recall_metric.update(pred, y)\n",
    "\n",
    "            # Calculate correct predictions for accuracy\n",
    "            _, predicted = torch.max(pred, 1)\n",
    "            total += y.size(0)\n",
    "            correct += (predicted == y).sum().item()\n",
    "\n",
    "    # Compute average test loss and finalize metrics\n",
    "    test_loss /= len(test_loader)\n",
    "    test_accuracy = accuracy_metric.compute().item()\n",
    "    test_f1_score = f1_score_metric.compute().item()\n",
    "    test_precision = precision_metric.compute().item()\n",
    "    test_recall = recall_metric.compute().item()\n",
    "\n",
    "    # Print test results\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}, \"\n",
    "          f\"Test F1 Score: {test_f1_score:.4f}, Test Precision: {test_precision:.4f}, \"\n",
    "          f\"Test Recall: {test_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-12-04 16:07:28</td></tr>\n",
       "<tr><td>Running for: </td><td>00:01:05.97        </td></tr>\n",
       "<tr><td>Memory:      </td><td>7.2/15.9 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 64.000: None | Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None<br>Logical resource usage: 6.0/8 CPUs, 1.0/2 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                                                                                                                         </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_b4dc3_00000</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-12-04_16-06-21_490553_2937416/artifacts/2024-12-04_16-06-22/train_model_2024-12-04_16-06-21/driver_artifacts/train_model_b4dc3_00000_0_att_loc=model,batch_size=64,d_model=32,dropout=0.2226,e_layers=2,lr=0.0000,n_heads=4,num_kernels=2,seq_l_2024-12-04_16-06-22/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc                </th><th>att_loc  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  d_model</th><th style=\"text-align: right;\">  dropout</th><th style=\"text-align: right;\">  e_layers</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  n_heads</th><th style=\"text-align: right;\">  num_kernels</th><th style=\"text-align: right;\">  seq_len</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_b4dc3_00001</td><td>RUNNING </td><td>10.34.1.111:2938305</td><td>model    </td><td style=\"text-align: right;\">         192</td><td style=\"text-align: right;\">       64</td><td style=\"text-align: right;\"> 0.133095</td><td style=\"text-align: right;\">         4</td><td style=\"text-align: right;\">2.25219e-05</td><td style=\"text-align: right;\">        4</td><td style=\"text-align: right;\">            6</td><td style=\"text-align: right;\">       64</td></tr>\n",
       "<tr><td>train_model_b4dc3_00000</td><td>ERROR   </td><td>10.34.1.111:2938015</td><td>model    </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">       32</td><td style=\"text-align: right;\"> 0.222562</td><td style=\"text-align: right;\">         2</td><td style=\"text-align: right;\">2.3518e-05 </td><td style=\"text-align: right;\">        4</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">      128</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_model pid=2938015)\u001b[0m Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 16:06:36,213\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_b4dc3_00000\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rifki/anaconda3/envs/timeseries/lib/python3.9/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/rifki/anaconda3/envs/timeseries/lib/python3.9/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/rifki/anaconda3/envs/timeseries/lib/python3.9/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/rifki/anaconda3/envs/timeseries/lib/python3.9/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/rifki/anaconda3/envs/timeseries/lib/python3.9/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=2938015, ip=10.34.1.111, actor_id=c249f4b9a5e7832a7193891c01000000, repr=train_model)\n",
      "  File \"/home/rifki/anaconda3/envs/timeseries/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/rifki/anaconda3/envs/timeseries/lib/python3.9/site-packages/ray/air/_internal/util.py\", line 104, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rifki/anaconda3/envs/timeseries/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"/home/rifki/anaconda3/envs/timeseries/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 250, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/rifki/anaconda3/envs/timeseries/lib/python3.9/site-packages/ray/tune/trainable/util.py\", line 130, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_2937416/1949481067.py\", line 69, in train_model\n",
      "AttributeError: module 'ray.tune' has no attribute 'Checkpoint'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_model pid=2938015)\u001b[0m Training loss: 1.3567, Training accuracy: 0.4500\n",
      "\u001b[36m(train_model pid=2938305)\u001b[0m Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 16:07:28,644\tWARNING tune.py:219 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2024-12-04 16:07:28,770\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/rifki/ray_results/train_model_2024-12-04_16-06-21' in 0.1243s.\n",
      "2024-12-04 16:07:38,776\tERROR tune.py:1037 -- Trials did not complete: [train_model_b4dc3_00000]\n",
      "2024-12-04 16:07:38,777\tINFO tune.py:1041 -- Total run time: 76.01 seconds (65.84 seconds for the tuning loop).\n",
      "2024-12-04 16:07:38,777\tWARNING tune.py:1056 -- Experiment has been interrupted, but the most recent state was saved.\n",
      "Resume experiment with: Tuner.restore(path=\"/home/rifki/ray_results/train_model_2024-12-04_16-06-21\", trainable=...)\n"
     ]
    }
   ],
   "source": [
    "search_space = {\n",
    "    'lr': tune.loguniform(1e-5, 1e-2),\n",
    "    'batch_size': tune.choice([64, 128, 192, 256]),\n",
    "    'n_heads': tune.choice([4, 8, 16]),\n",
    "    'd_model': tune.choice([32, 64, 96]),\n",
    "    'num_kernels': tune.choice([2, 4, 6]),\n",
    "    'e_layers': tune.choice([2, 3, 4]),\n",
    "    'seq_len': tune.choice([64, 128, 192]),\n",
    "    'dropout': tune.uniform(0.0, 0.5),\n",
    "    'att_loc': tune.choice(['block', 'model']),\n",
    "    'num_classes': 6 \n",
    "}\n",
    "\n",
    "# Ray Tune's scheduler\n",
    "scheduler = ASHAScheduler(\n",
    "        max_t=100,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2\n",
    ")\n",
    "\n",
    "# Ray Tune's execution\n",
    "tuner = tune.Tuner(\n",
    "    tune.with_resources(\n",
    "        tune.with_parameters(train_model),\n",
    "        resources={\"cpu\": 6, \"gpu\": 1}\n",
    "    ),\n",
    "    tune_config=tune.TuneConfig(\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        scheduler=scheduler,\n",
    "        num_samples=20,\n",
    "        max_concurrent_trials=1\n",
    "    ),\n",
    "    param_space=search_space,\n",
    ")\n",
    "\n",
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config: {'lr': 0.0007060636809167652, 'batch_size': 128, 'n_heads': 8, 'd_model': 32, 'num_kernels': 8, 'e_layers': 2, 'seq_len': 64, 'dropout': 0.22736732797949116, 'att_loc': 'model', 'num_classes': 6}\n",
      "Best trial final validation loss: 0.01353292826452321\n",
      "Best trial final validation accuracy: 0.9953708052635193\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Result' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 9\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial final validation loss: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m      5\u001b[0m     best_result\u001b[38;5;241m.\u001b[39mmetrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial final validation accuracy: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m      7\u001b[0m     best_result\u001b[38;5;241m.\u001b[39mmetrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[0;32m----> 9\u001b[0m \u001b[43mtest_best_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_result\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 23\u001b[0m, in \u001b[0;36mtest_best_model\u001b[0;34m(model, configs)\u001b[0m\n\u001b[1;32m     20\u001b[0m recall_metric \u001b[38;5;241m=\u001b[39m MulticlassRecall(average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m, num_classes\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mnum_classes)\u001b[38;5;241m.\u001b[39mto(args\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Set the model to evaluation mode\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m()\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Loss function\u001b[39;00m\n\u001b[1;32m     26\u001b[0m loss_func \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\u001b[38;5;241m.\u001b[39mto(args\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Result' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "best_result = results.get_best_result(\"loss\", \"min\")\n",
    "\n",
    "print(\"Best trial config: {}\".format(best_result.config))\n",
    "print(\"Best trial final training loss: {}\".format(\n",
    "    best_result.metrics[\"loss\"]))\n",
    "print(\"Best trial final training accuracy: {}\".format(\n",
    "    best_result.metrics[\"accuracy\"]))\n",
    "\n",
    "test_best_model(best_result, best_result.config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timeseries",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
